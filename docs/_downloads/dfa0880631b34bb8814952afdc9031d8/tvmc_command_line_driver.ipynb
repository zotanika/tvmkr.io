{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Getting Started with TVM command line driver - TVMC\n**Authors**:\n`Leandro Nunes <https://github.com/leandron>`_,\n`Matthew Barrett <https://github.com/mbaret>`_\n\nThis tutorial is an introduction to working with TVMC, the TVM command\nline driver. TVMC is a tool that exposes TVM features such as\nauto-tuning, compiling, profiling and execution of models, via a\ncommand line interface.\n\nIn this tutorial we are going to use TVMC to compile, run and tune a\nResNet-50 on a x86 CPU.\n\nWe are going to start by downloading ResNet 50 V2. Then, we are going\nto use TVMC to compile this model into a TVM module, and use the\ncompiled module to generate predictions. Finally, we are going to experiment\nwith the auto-tuning options, that can be used to help the compiler to\nimprove network performance.\n\nThe final goal is to give an overview of TVMC's capabilities and also\nsome guidance on where to look for more information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using TVMC\n\nTVMC is a Python application, part of the TVM Python package.\nWhen you install TVM using a Python package, you will get TVMC as\nas a command line application called ``tvmc``.\n\nAlternatively, if you have TVM as a Python module on your\n``$PYTHONPATH``,you can access the command line driver functionality\nvia the executable python module, ``python -m tvm.driver.tvmc``.\n\nFor simplicity, this tutorial will mention TVMC command line using\n``tvmc <options>``, but the same results can be obtained with\n``python -m tvm.driver.tvmc <options>``.\n\nYou can check the help page using:\n\n.. code-block:: bash\n\n  tvmc --help\n\n\nAs you can see in the help page, the main features are\naccessible via the subcommands ``tune``, ``compile`` and ``run``.\nTo read about specific options under a given subcommand, use\n``tvmc <subcommand> --help``.\n\nIn the following sections we will use TVMC to tune, compile and\nrun a model. But first, we need a model.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtaining the model\n\nWe are going to use ResNet-50 V2 as an example to experiment with TVMC.\nThe version below is in ONNX format. To download the file, you can use\nthe command below:\n\n.. code-block:: bash\n\n  wget https://github.com/onnx/models/raw/master/vision/classification/resnet/model/resnet50-v2-7.onnx\n\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Supported model formats\n\n  TVMC supports models created with Keras, ONNX, TensorFlow, TFLite\n  and Torch. Use the option``--model-format`` if you need to\n  explicitly provide the model format you are using. See ``tvmc\n  compile --help`` for more information.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compiling the model\n\nThe next step once we've downloaded ResNet-50, is to compile it,\nTo accomplish that, we are going to use ``tvmc compile``. The\noutput we get from the compilation process is a TAR package,\nthat can be used to run our model on the target device.\n\n.. code-block:: bash\n\n  tvmc compile \\\n    --target \"llvm\" \\\n    --output compiled_module.tar \\\n    resnet50-v2-7.onnx\n\nOnce compilation finishes, the output ``compiled_module.tar`` will be created. This\ncan be directly loaded by your application and run via the TVM runtime APIs.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Defining the correct target\n\n  Specifying the correct target (option ``--target``) can have a huge\n  impact on the performance of the compiled module, as it can take\n  advantage of hardware features available on the target. For more\n  information, please refer to `Auto-tuning a convolutional network\n  for x86 CPU <https://tvm.apache.org/docs/tutorials/autotvm/tune_relay_x86.html#define-network>`_.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next step, we are going to use the compiled module, providing it\nwith some inputs, to generate some predictions.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input pre-processing\n\nIn order to generate predictions, we will need two things:\n\n- the compiled module, which we just produced;\n- a valid input to the model\n\nEach model is particular when it comes to expected tensor shapes, formats and data\ntypes. For this reason, most models require some pre and\npost processing, to ensure the input(s) is valid and to interpret the output(s).\n\nIn TVMC, we adopted NumPy's ``.npz`` format for both input and output data.\nThis is a well-supported NumPy format to serialize multiple arrays into a file.\n\nWe will use the usual cat image, similar to other TVM tutorials:\n\n<img src=\"https://s3.amazonaws.com/model-server/inputs/kitten.jpg\" height=\"224px\" width=\"224px\" align=\"center\">\n\nFor our ResNet 50 V2 model, the input is expected to be in ImageNet format.\nHere is an example of a script to pre-process an image for ResNet 50 V2.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tvm.contrib.download import download_testdata\nfrom PIL import Image\nimport numpy as np\n\nimg_url = \"https://s3.amazonaws.com/model-server/inputs/kitten.jpg\"\nimg_path = download_testdata(img_url, \"imagenet_cat.png\", module=\"data\")\n\n# Resize it to 224x224\nresized_image = Image.open(img_path).resize((224, 224))\nimg_data = np.asarray(resized_image).astype(\"float32\")\n\n# ONNX expects NCHW input, so convert the array\nimg_data = np.transpose(img_data, (2, 0, 1))\n\n# Normalize according to ImageNet\nimagenet_mean = np.array([0.485, 0.456, 0.406])\nimagenet_stddev = np.array([0.229, 0.224, 0.225])\nnorm_img_data = np.zeros(img_data.shape).astype(\"float32\")\nfor i in range(img_data.shape[0]):\n    norm_img_data[i, :, :] = (img_data[i, :, :] / 255 - imagenet_mean[i]) / imagenet_stddev[i]\n\n# Add batch dimension\nimg_data = np.expand_dims(norm_img_data, axis=0)\n\n# Save to .npz (outputs imagenet_cat.npz)\nnp.savez(\"imagenet_cat\", data=img_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the compiled module\n\nWith both the compiled module and input file in hand, we can run it by\ninvoking ``tvmc run``.\n\n.. code-block:: bash\n\n   tvmc run \\\n     --inputs imagenet_cat.npz \\\n     --output predictions.npz \\\n     compiled_module.tar\n\nWhen running the above command, a new file ``predictions.npz`` should\nbe produced. It contains the output tensors.\n\nIn this example, we are running the model on the same machine that we used\nfor compilation. In some cases we might want to run it remotely via\nan RPC Tracker. To read more about these options please check ``tvmc\nrun --help``.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output post-processing\n\nAs previously mentioned, each model will have its own particular way\nof providing output tensors.\n\nIn our case, we need to run some post-processing to render the\noutputs from ResNet 50 V2 into a more human-readable form.\n\nThe script below shows an example of the post-processing to extract\nlabels from the output of our compiled module.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path\nimport numpy as np\n\nfrom scipy.special import softmax\n\nfrom tvm.contrib.download import download_testdata\n\n# Download a list of labels\nlabels_url = \"https://s3.amazonaws.com/onnx-model-zoo/synset.txt\"\nlabels_path = download_testdata(labels_url, \"synset.txt\", module=\"data\")\n\nwith open(labels_path, \"r\") as f:\n    labels = [l.rstrip() for l in f]\n\noutput_file = \"predictions.npz\"\n\n# Open the output and read the output tensor\nif os.path.exists(output_file):\n    with np.load(output_file) as data:\n        scores = softmax(data[\"output_0\"])\n        scores = np.squeeze(scores)\n        ranks = np.argsort(scores)[::-1]\n\n        for rank in ranks[0:5]:\n            print(\"class='%s' with probability=%f\" % (labels[rank], scores[rank]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When running the script, a list of predictions should be printed similar\nthe the example below.\n\n.. code-block:: bash\n\n  $ python post_processing.py\n  class=n02123045 tabby, tabby cat ; probability=446.000000\n  class=n02123159 tiger cat ; probability=675.000000\n  class=n02124075 Egyptian cat ; probability=836.000000\n  class=n02129604 tiger, Panthera tigris ; probability=917.000000\n  class=n04040759 radiator ; probability=213.000000\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tuning the model\n\nIn some cases, we might not get the expected performance when running\ninferences using our compiled module. In cases like this, we can make use\nof the auto-tuner, to find a better configuration for our model and\nget a boost in performance.\n\nTuning in TVM refers to the process by which a model is optimized\nto run faster on a given target. This differs from training or\nfine-tuning in that it does not affect the accuracy of the model,\nbut only the runtime performance.\n\nAs part of the tuning process, TVM will try running many different\noperator implementation variants to see which perform best. The\nresults of these runs are stored in a tuning records file, which is\nultimately the output of the ``tune`` subcommand.\n\nIn the simplest form, tuning requires you to provide three things:\n\n- the target specification of the device you intend to run this model on;\n- the path to an output file in which the tuning records will be stored, and finally,\n- a path to the model to be tuned.\n\n\nThe example below demonstrates how that works in practice:\n\n.. code-block:: bash\n\n  tvmc tune \\\n    --target \"llvm\" \\\n    --output autotuner_records.json \\\n    resnet50-v2-7.onnx\n\n\nTuning sessions can take a long time, so ``tvmc tune`` offers many options to\ncustomize your tuning process, in terms of number of repetitions (``--repeat`` and\n``--number``, for example), the tuning algorithm to be use, and so on.\nCheck ``tvmc tune --help`` for more information.\n\nAs an output of the tuning process above, we obtained the tuning records stored\nin ``autotuner_records.json``. This file can be used in two ways:\n\n- as an input to further tuning (via ``tvmc tune --tuning-records``), or\n- as an input to the compiler\n\nThe compiler will use the results to generate high performance code for the model\non your specified target. To do that we can use ``tvmc compile --tuning-records``.\nCheck ``tvmc compile --help`` for more information.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Remarks\n\nIn this tutorial, we presented TVMC, a command line driver for TVM.\nWe demonstrated how to compile, run and tune a model, as well\nas discussed the need for pre and post processing of inputs and outputs.\n\nHere we presented a simple example using ResNet 50 V2 locally. However, TVMC\nsupports many more features including cross-compilation, remote execution and\nprofiling/benchmarking.\n\nTo see what other options are available, please have a look at ``tvmc --help``.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}