





<!DOCTYPE html>
<html class="writer-html5" lang="kr" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Relay에 연산자 추가하기 &mdash; tvm 0.8.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/tlcpack_theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-rendered-html.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Relay에 컴파일러 패스 추가하기" href="relay_add_pass.html" />
    <link rel="prev" title="Developer How-To Guide" href="how_to.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.8.dev0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">입문</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">설치</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute/index.html">TVM에 기여하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/index.html">구현과 탑재</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="how_to.html">Developer How-To Guide</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Relay에 연산자 추가하기</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#registering-an-operator">연산자 등록하기</a></li>
<li class="toctree-l3"><a class="reference internal" href="#creating-a-call-node">Creating a Call Node</a></li>
<li class="toctree-l3"><a class="reference internal" href="#including-a-python-api-hook">Including a Python API Hook</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gradient-operators">Gradient Operators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#adding-a-gradient-in-python">파이썬으로 기울기(Gradient) 추가하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="#adding-a-gradient-in-c">Adding a Gradient in C++</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="relay_add_pass.html">Relay에 컴파일러 패스 추가하기</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay_bring_your_own_codegen.html">당신의 codegen을 TVM에 도입하기</a></li>
<li class="toctree-l2"><a class="reference internal" href="codebase_walkthrough.html">예제로 TVM 코드베이스 익히기</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">튜토리얼</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html">Get Started Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html#compile-deep-learning-models">Compile Deep Learning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html#tensor-expression-and-schedules">Tensor Expression and Schedules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html#optimize-tensor-operators">Optimize Tensor Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html#autotvm-template-based-auto-tuning">AutoTVM : Template-based Auto Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html#autoscheduler-template-free-auto-scheduling">AutoScheduler : Template-free Auto Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html#developer-tutorials">Developer Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html#topi-tvm-operator-inventory">TOPI: TVM Operator Inventory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html#micro-tvm">Micro TVM</a></li>
</ul>
<p class="caption"><span class="caption-text">참고 자료</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../langref/index.html">언어 레퍼런스</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/index.html">파이썬 API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/links.html">다른 API 참조를 위한 링크</a></li>
</ul>
<p class="caption"><span class="caption-text">심층 해설</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">디자인과 아키텍쳐</a></li>
</ul>
<p class="caption"><span class="caption-text">기타</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vta/index.html">VTA: 딥러닝 가속기 스택</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">자주 묻는 질문(FAQ)</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">인덱스</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of content
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="how_to.html">Developer How-To Guide</a> <span class="br-arrow">></span></li>
        
      <li>Relay에 연산자 추가하기</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/dev/relay_add_op.rst.txt" rel="nofollow"> <img src="../_static//img/source.svg" alt="viewsource"/></a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="adding-an-operator-to-relay">
<span id="relay-add-op"></span><h1>Relay에 연산자 추가하기<a class="headerlink" href="#adding-an-operator-to-relay" title="Permalink to this headline">¶</a></h1>
<p>Relay IR 내에서 TVM 연산자를 사용하려면, 해당 연산자들이 Relay 타입 체계에 통합될 수 있도록 Relay에 등록될 필요가 있습니다.</p>
<p>연산자 등록은 세 단계가 필요합니다.</p>
<ul class="simple">
<li><p>연산자의 항 수(arity)와 타입 정보를 등록하기 위해 <code class="docutils literal notranslate"><span class="pre">RELAY_REGISTER_OP</span></code> C++ 매크로 사용하기</p></li>
<li><p>연산자에 대한 콜 노드를 산출하는 C++ 함수를 정의하고 해당 함수를 후킹(hook)하는 파이썬 API 등록하기</p></li>
<li><p>상기 파이썬 API 후크(hook)를 보다 깔끔한 인터페이스로 래핑하기</p></li>
</ul>
<p>처음 두 단계의 예시는 <code class="docutils literal notranslate"><span class="pre">src/relay/op/tensor/binary.cc</span></code> 파일에서, 마지막 단계 예시는 <code class="docutils literal notranslate"><span class="pre">python/tvm/relay/op/tensor.py</span></code> 파일에서 각각 참고할 수 있습니다.</p>
<div class="section" id="registering-an-operator">
<h2>연산자 등록하기<a class="headerlink" href="#registering-an-operator" title="Permalink to this headline">¶</a></h2>
<p>TVM은 이미 연산자 레지스트리를 보유하고 있으나, 추가적인 타입 정보 없이는 Relay가 TVM 연산자를 적절히 활용하지 못합니다.</p>
<p>To allow for flexibility in registering operators and greater
expressivity and granularity in expressing types in Relay, operators
are typed using relations between input and output types. These relations
are represented as functions that take in a list of input types and
output types (any of these types may be incomplete) and return a list
of input and output types that satisfies the relation. Essentially, a
relation for an operator can enforce all the necessary typing rules
(namely by inspecting the input types) in addition to computing the
output type.</p>
<p>For example, see <code class="docutils literal notranslate"><span class="pre">src/relay/op/type_relations.h</span></code> and their
implementations. E.g., <code class="docutils literal notranslate"><span class="pre">BroadcastRel</span></code> takes two input types and an
output type, checks that they are all tensor types with the same underlying
data type, and finally ensures that the shape of the output type is the
broadcast of the input types' shapes.</p>
<p>It may be necessary to add another type relation to <code class="docutils literal notranslate"><span class="pre">type_relations.h</span></code>
if the existing ones do not capture the behavior of the desired operator.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">RELAY_REGISTER_OP</span></code> macro in C++ allows a developer
to specify the following information about an operator in Relay:</p>
<ul class="simple">
<li><p>항 수(인자의 수)</p></li>
<li><p>위치규정 인자의 명칭과 서술</p></li>
<li><p>Support level (1 indicates an internal intrinsic; higher numbers indicate less integral or externally supported operators)</p></li>
<li><p>A type relation for the operator</p></li>
</ul>
<p>The below example is from <code class="docutils literal notranslate"><span class="pre">binary.cc</span></code> and uses a broadcasting
add for tensors:</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">RELAY_REGISTER_OP</span><span class="p">(</span><span class="s">&quot;add&quot;</span><span class="p">)</span>
    <span class="p">.</span><span class="n">set_num_inputs</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">&quot;lhs&quot;</span><span class="p">,</span> <span class="s">&quot;Tensor&quot;</span><span class="p">,</span> <span class="s">&quot;The left hand side tensor.&quot;</span><span class="p">)</span>
    <span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">&quot;rhs&quot;</span><span class="p">,</span> <span class="s">&quot;Tensor&quot;</span><span class="p">,</span> <span class="s">&quot;The right hand side tensor.&quot;</span><span class="p">)</span>
    <span class="p">.</span><span class="n">set_support_level</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">.</span><span class="n">add_type_rel</span><span class="p">(</span><span class="s">&quot;Broadcast&quot;</span><span class="p">,</span> <span class="n">BroadcastRel</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="creating-a-call-node">
<h2>Creating a Call Node<a class="headerlink" href="#creating-a-call-node" title="Permalink to this headline">¶</a></h2>
<p>This step requires simply writing a function that takes
the arguments to the operator (as Relay expressions) and
returning a call node to the operator (i.e., the node that
should be placed into the Relay AST where the call to the
operator is intended).</p>
<p>At present call attributes and type arguments (the last two fields)
are not supported, so it suffices to use <code class="docutils literal notranslate"><span class="pre">Op::Get</span></code> to fetch
the operator's information from the operator registry and pass in
the arguments to the call node, as below.</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">TVM_REGISTER_GLOBAL</span><span class="p">(</span><span class="s">&quot;relay.op._make.add&quot;</span><span class="p">)</span>
    <span class="p">.</span><span class="n">set_body_typed</span><span class="o">&lt;</span><span class="n">Expr</span><span class="p">(</span><span class="n">Expr</span><span class="p">,</span> <span class="n">Expr</span><span class="p">)</span><span class="o">&gt;</span><span class="p">([](</span><span class="n">Expr</span> <span class="n">lhs</span><span class="p">,</span> <span class="n">Expr</span> <span class="n">rhs</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">static</span> <span class="k">const</span> <span class="n">Op</span><span class="o">&amp;</span> <span class="n">op</span> <span class="o">=</span> <span class="n">Op</span><span class="o">::</span><span class="n">Get</span><span class="p">(</span><span class="s">&quot;add&quot;</span><span class="p">);</span>
      <span class="k">return</span> <span class="nf">Call</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="p">{</span><span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span><span class="p">},</span> <span class="n">Attrs</span><span class="p">(),</span> <span class="p">{});</span>
    <span class="p">});</span>
</pre></div>
</div>
</div>
<div class="section" id="including-a-python-api-hook">
<h2>Including a Python API Hook<a class="headerlink" href="#including-a-python-api-hook" title="Permalink to this headline">¶</a></h2>
<p>It is generally the convention in Relay, that functions exported
through <code class="docutils literal notranslate"><span class="pre">TVM_REGISTER_GLOBAL</span></code> should be wrapped in a separate
Python function rather than called directly in Python. In the case
of the functions that produce calls to operators, it may be convenient
to bundle them, as in <code class="docutils literal notranslate"><span class="pre">python/tvm/relay/op/tensor.py</span></code>, where
elementwise operators on tensors are all provided. For example,
the following is how the add function from the previous section is
exposed in Python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Elementwise addition.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lhs : relay.Expr</span>
<span class="sd">        The left hand side input data</span>
<span class="sd">    rhs : relay.Expr</span>
<span class="sd">        The right hand side input data</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : relay.Expr</span>
<span class="sd">        The computed result.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_make</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that these Python wrappers might also be good opportunities to
provide an easier interface to the operator. For example, the
<code class="docutils literal notranslate"><span class="pre">concat</span></code> operator is registered as taking only one operator,
namely a tuple with the tensors to be concatenated, but the Python
wrapper takes the tensors as arguments and combines them into a tuple
before producing the call node:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">concat</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Concatenate the input tensors along the zero axis.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    args: list of Tensor</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tensor: The concatenated tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tup</span> <span class="o">=</span> <span class="n">Tuple</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">_make</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">tup</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="gradient-operators">
<h2>Gradient Operators<a class="headerlink" href="#gradient-operators" title="Permalink to this headline">¶</a></h2>
<p>Gradient operators are important for writing differentiable programs in
Relay. While it is the case that Relay's autodiff algorithm can differentiate
first-class language constructs, operators are opaque. Because Relay can't
look into the implementation, an explicit differentiation rule must be
provided.</p>
<p>Both Python and C++ can be used to write gradient operators, but we focus our
examples on Python, as it is more commonly used.</p>
<div class="section" id="adding-a-gradient-in-python">
<h3>파이썬으로 기울기(Gradient) 추가하기<a class="headerlink" href="#adding-a-gradient-in-python" title="Permalink to this headline">¶</a></h3>
<p>파이썬 기울기 연산자의 모음은 <code class="docutils literal notranslate"><span class="pre">python/tvm/relay/op/_tensor_grad.py</span></code> 에서 찾아볼 수 있습니다. 대표적인 두 가지 예제로서 <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> 와 <code class="docutils literal notranslate"><span class="pre">multiply</span></code> 를 대상으로 다뤄보겠습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@register_gradient</span><span class="p">(</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sigmoid_grad</span><span class="p">(</span><span class="n">orig</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns [grad * sigmoid(x) * (1 - sigmoid(x))].&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">grad</span> <span class="o">*</span> <span class="n">orig</span> <span class="o">*</span> <span class="p">(</span><span class="n">ones_like</span><span class="p">(</span><span class="n">orig</span><span class="p">)</span> <span class="o">-</span> <span class="n">orig</span><span class="p">)]</span>
</pre></div>
</div>
<p>The inputs here are the original operator <code class="docutils literal notranslate"><span class="pre">orig</span></code> and a gradient <code class="docutils literal notranslate"><span class="pre">grad</span></code> to
accumulate into. What we return is a list, where the element at the i'th
index is the derivative of the operator with respect to the operator's i'th
input. In general, the gradient will return a list with as many elements as
there are inputs to the base operator.</p>
<p>Before we further analyze this definition, first we should recall the
derivative of the sigmoid function: <span class="math notranslate nohighlight">\(\frac{\partial \sigma}{\partial x}
= \sigma(x)(1 - \sigma(x))\)</span>. The definition above looks similar to the
mathematical definition, but there is one important addition, which we
describe below.</p>
<p>The term <code class="docutils literal notranslate"><span class="pre">orig</span> <span class="pre">*</span> <span class="pre">(ones_like(orig)</span> <span class="pre">-</span> <span class="pre">orig)</span></code> directly matches the derivative,
because <code class="docutils literal notranslate"><span class="pre">orig</span></code> here is the sigmoid function, but we're not just interested
in how to compute the gradient of this function. We're interested in
composing this gradient with other gradients, so we can accumulate the
gradient across an entire program. This is where the <code class="docutils literal notranslate"><span class="pre">grad</span></code> term comes in.
In the expression <code class="docutils literal notranslate"><span class="pre">grad</span> <span class="pre">*</span> <span class="pre">orig</span> <span class="pre">*</span> <span class="pre">(ones_like(orig)</span> <span class="pre">-</span> <span class="pre">orig)</span></code>, multiplying by
<code class="docutils literal notranslate"><span class="pre">grad</span></code> specifies how to compose the derivative with the gradient thus far.</p>
<p>Now, we consider <code class="docutils literal notranslate"><span class="pre">multiply</span></code>, a slightly more interesting example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@register_gradient</span><span class="p">(</span><span class="s2">&quot;multiply&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_grad</span><span class="p">(</span><span class="n">orig</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns [grad * y, grad * x]&quot;&quot;&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">orig</span><span class="o">.</span><span class="n">args</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">collapse_sum_like</span><span class="p">(</span><span class="n">grad</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span>
            <span class="n">collapse_sum_like</span><span class="p">(</span><span class="n">grad</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)]</span>
</pre></div>
</div>
<p>In this example, there are two elements in the returned list, because
<code class="docutils literal notranslate"><span class="pre">multiply</span></code> is a binary operator. And to recall, if <span class="math notranslate nohighlight">\(f(x, y) = xy\)</span>, the
partial derivatives are <span class="math notranslate nohighlight">\(\frac{\partial f}{\partial x} = y\)</span> and
<span class="math notranslate nohighlight">\(\frac{\partial f}{\partial y} = x\)</span>.</p>
<p>There is one required step for <code class="docutils literal notranslate"><span class="pre">multiply</span></code> that is not required for
<code class="docutils literal notranslate"><span class="pre">sigmoid</span></code>, because <code class="docutils literal notranslate"><span class="pre">multiply</span></code> has broadcasting semantics. Since the shape
of <code class="docutils literal notranslate"><span class="pre">grad</span></code> might not match the shape of the inputs, we use
<code class="docutils literal notranslate"><span class="pre">collapse_sum_like</span></code> to take the contents of the <code class="docutils literal notranslate"><span class="pre">grad</span> <span class="pre">*</span> <span class="pre">&lt;var&gt;</span></code> terms and
make the shape match the shape of the input we're differentiating with
respect to.</p>
</div>
<div class="section" id="adding-a-gradient-in-c">
<h3>Adding a Gradient in C++<a class="headerlink" href="#adding-a-gradient-in-c" title="Permalink to this headline">¶</a></h3>
<p>Adding a gradient in C++ is similar to adding one in Python, but the
interface for registering is slightly different.</p>
<p>First, make sure <code class="docutils literal notranslate"><span class="pre">src/relay/pass/pattern_utils.h</span></code> is included. It provides
helper functions for creating nodes in the Relay AST. Then, define the
gradient in a similar fashion as in the Python example:</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">tvm</span><span class="o">::</span><span class="n">Array</span><span class="o">&lt;</span><span class="n">Expr</span><span class="o">&gt;</span> <span class="n">MultiplyGrad</span><span class="p">(</span><span class="k">const</span> <span class="n">Expr</span><span class="o">&amp;</span> <span class="n">orig_call</span><span class="p">,</span> <span class="k">const</span> <span class="n">Expr</span><span class="o">&amp;</span> <span class="n">output_grad</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">const</span> <span class="n">Call</span><span class="o">&amp;</span> <span class="n">call</span> <span class="o">=</span> <span class="n">orig_call</span><span class="p">.</span><span class="n">Downcast</span><span class="o">&lt;</span><span class="n">Call</span><span class="o">&gt;</span><span class="p">();</span>
    <span class="k">return</span> <span class="p">{</span> <span class="n">CollapseSumLike</span><span class="p">(</span><span class="n">Multiply</span><span class="p">(</span><span class="n">output_grad</span><span class="p">,</span> <span class="n">call</span><span class="p">.</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">call</span><span class="p">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
             <span class="n">CollapseSumLike</span><span class="p">(</span><span class="n">Multiply</span><span class="p">(</span><span class="n">output_grad</span><span class="p">,</span> <span class="n">call</span><span class="p">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">call</span><span class="p">.</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="p">};</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Notice that in C++ we can't use the same operator overloading that we have in
Python, and we need to downcast, so the implementation is more verbose. Even
so, we can easily verify that this definition mirrors the earlier example in
Python.</p>
<p>Now, instead of using a Python decorator, we need to tack a <code class="docutils literal notranslate"><span class="pre">set_attr</span></code> call
for &quot;FPrimalGradient&quot; onto the end of the base operator's registration, in
order to register the gradient.</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">RELAY_REGISTER_OP</span><span class="p">(</span><span class="s">&quot;multiply&quot;</span><span class="p">)</span>
    <span class="c1">// ...</span>
    <span class="c1">// Set other attributes</span>
    <span class="c1">// ...</span>
    <span class="p">.</span><span class="n">set_attr</span><span class="o">&lt;</span><span class="n">FPrimalGradient</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;FPrimalGradient&quot;</span><span class="p">,</span> <span class="n">MultiplyGrad</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>A TVM operator can be registered in Relay using a relation to express the appropriate type information.</p></li>
<li><p>Using an operator in Relay requires a function to produce a call node for the operator.</p></li>
<li><p>It is best to have a simple Python wrapper for producing the call node.</p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="relay_add_pass.html" class="btn btn-neutral float-right" title="Relay에 컴파일러 패스 추가하기" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="how_to.html" class="btn btn-neutral float-left" title="Developer How-To Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../_static//img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <ul class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <li class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2020 Apache Software Foundation | All right reserved</h5>
        </li>
      </ul>

    </div>

    <ul>
      <li class="footernote">Copyright © 2020 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</li>
    </ul>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>