





<!DOCTYPE html>
<html class="writer-html5" lang="kr" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tvm.topi &mdash; tvm 0.8.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-rendered-html.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="vta" href="vta/index.html" />
    <link rel="prev" title="tvm.contrib.graph_runtime" href="graph_runtime.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.8.dev0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">입문</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">설치</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">TVM에 기여하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy/index.html">구현과 탑재</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to.html">Developer How-To Guide</a></li>
</ul>
<p class="caption"><span class="caption-text">튜토리얼</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html">Get Started Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#compile-deep-learning-models">Compile Deep Learning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#tensor-expression-and-schedules">Tensor Expression and Schedules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#optimize-tensor-operators">Optimize Tensor Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#autotvm-template-based-auto-tuning">AutoTVM : Template-based Auto Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#autoscheduler-template-free-auto-scheduling">AutoScheduler : Template-free Auto Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#developer-tutorials">Developer Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#topi-tvm-operator-inventory">TOPI: TVM Operator Inventory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html#micro-tvm">Micro TVM</a></li>
</ul>
<p class="caption"><span class="caption-text">참고 자료</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../langref/index.html">언어 레퍼런스</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">파이썬 API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="runtime.html">tvm.runtime</a></li>
<li class="toctree-l2"><a class="reference internal" href="ndarray.html">tvm.runtime.ndarray</a></li>
<li class="toctree-l2"><a class="reference internal" href="error.html">tvm.error</a></li>
<li class="toctree-l2"><a class="reference internal" href="ir.html">tvm.ir</a></li>
<li class="toctree-l2"><a class="reference internal" href="ir.html#module-tvm.transform">tvm.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="target.html">tvm.target</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir.html">tvm.tir</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir.html#module-tvm.tir.transform">tvm.tir.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir.html#module-tvm.tir.analysis">tvm.tir.analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="tir.html#module-tvm.tir.stmt_functor">tvm.tir.stmt_functor</a></li>
<li class="toctree-l2"><a class="reference internal" href="te.html">tvm.te</a></li>
<li class="toctree-l2"><a class="reference internal" href="te.html#module-tvm.te.hybrid">tvm.te.hybrid</a></li>
<li class="toctree-l2"><a class="reference internal" href="driver.html">tvm.driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/index.html">tvm.relay</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/frontend.html">tvm.relay.frontend</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/nn.html">tvm.relay.nn</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/vision.html">tvm.relay.vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/image.html">tvm.relay.image</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/transform.html">tvm.relay.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/analysis.html">tvm.relay.analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/backend.html">tvm.relay.backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/dataflow_pattern.html">tvm.relay.dataflow_pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay/testing.html">tvm.relay.testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="autotvm.html">tvm.autotvm</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_scheduler.html">tvm.auto_scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="rpc.html">tvm.rpc</a></li>
<li class="toctree-l2"><a class="reference internal" href="micro.html">tvm.micro</a></li>
<li class="toctree-l2"><a class="reference internal" href="contrib.html">tvm.contrib</a></li>
<li class="toctree-l2"><a class="reference internal" href="graph_runtime.html">tvm.contrib.graph_runtime</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">tvm.topi</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-tvm.topi.nn">tvm.topi.nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-tvm.topi.image">tvm.topi.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-tvm.topi.sparse">tvm.topi.sparse</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="vta/index.html">vta</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../links.html">다른 API 참조를 위한 링크</a></li>
</ul>
<p class="caption"><span class="caption-text">심층 해설</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index.html">디자인과 아키텍쳐</a></li>
</ul>
<p class="caption"><span class="caption-text">기타</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../vta/index.html">VTA: 딥러닝 가속기 스택</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">자주 묻는 질문(FAQ)</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">인덱스</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of content
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="index.html">파이썬 API</a> <span class="br-arrow">></span></li>
        
      <li>tvm.topi</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/api/python/topi.rst.txt" rel="nofollow"> <img src="../../_static//img/source.svg" alt="viewsource"/></a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-tvm.topi">
<span id="tvm-topi"></span><h1>tvm.topi<a class="headerlink" href="#module-tvm.topi" title="Permalink to this headline">¶</a></h1>
<p>TVM Operator Inventory.</p>
<p>TOPI is the operator collection library for TVM, to provide sugars
for constructing compute declaration as well as optimized schedules.</p>
<p>Some of the schedule function may have been specially optimized for a
specific workload.</p>
<p><strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">AssertStmt</span></code>(condition, message, body[, span])</p></td>
<td><p>AssertStmt node.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Cast</span></code>(dtype, value[, span])</p></td>
<td><p>Cast expression.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Evaluate</span></code>(value[, span])</p></td>
<td><p>Evaluate node.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">StringImm</span></code>(value[, span])</p></td>
<td><p>String constant.</p></td>
</tr>
</tbody>
</table>
<p><strong>Functions:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">abs</span></code>(x)</p></td>
<td><p>Take absolute value of the input of x, element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">acos</span></code>(x)</p></td>
<td><p>Take arc cos of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">acosh</span></code>(x)</p></td>
<td><p>Take arc cosh of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code>(lhs, rhs)</p></td>
<td><p>Addition with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">adv_index</span></code>(data, indices)</p></td>
<td><p>Numpy style indexing with tensors.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">all</span></code>(data[, axis, keepdims])</p></td>
<td><p>Logical AND of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">any</span></code>(data[, axis, keepdims])</p></td>
<td><p>Logical OR of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">arange</span></code>(start[, stop, step, dtype])</p></td>
<td><p>Creates a tensor with evenly spaced values within a given interval.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">argmax</span></code>(data[, axis, keepdims])</p></td>
<td><p>Returns the indices of the maximum values along an axis.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">argmin</span></code>(data[, axis, keepdims])</p></td>
<td><p>Returns the indices of the minimum values along an axis.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">argsort</span></code>(data[, valid_count, axis, ...])</p></td>
<td><p>Performs sorting along the given axis and returns an array of indices having the same shape as an input array that index data in sorted order.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">argwhere</span></code>(output_shape, condition)</p></td>
<td><p>Find the indices of elements of a tensor that are non-zero.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">asin</span></code>(x)</p></td>
<td><p>Take arc sin of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">asinh</span></code>(x)</p></td>
<td><p>Take arc sinh of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">atan</span></code>(x)</p></td>
<td><p>Take atan of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">atanh</span></code>(x)</p></td>
<td><p>Take atanh of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_and</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise bitwise and of data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_not</span></code>(data)</p></td>
<td><p>Compute element-wise bitwise not of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_or</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise bitwise or of data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_xor</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise bitwise xor of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">broadcast_to</span></code>(data, shape)</p></td>
<td><p>Broadcast the src to the target shape</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code>(x, dtype[, span])</p></td>
<td><p>Cast input to specified data type.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">ceil</span></code>(x)</p></td>
<td><p>Take ceil of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip</span></code>(x, a_min, a_max)</p></td>
<td><p>Clip (limit) the values in an array.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">concatenate</span></code>(a_tuple[, axis])</p></td>
<td><p>Join a sequence of arrays along an existing axis.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">const_vector</span></code>(vector[, name])</p></td>
<td><p>convert a const numpy 1-dimensional vector to tvm tensor</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cos</span></code>(x)</p></td>
<td><p>Take cos of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cosh</span></code>(x)</p></td>
<td><p>Take cosh of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">decl_buffer</span></code>(shape[, dtype, name, data, ...])</p></td>
<td><p>Declare a new symbolic buffer.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">divide</span></code>(lhs, rhs)</p></td>
<td><p>Division with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">elemwise_sum</span></code>(xs)</p></td>
<td><p>Perform element-wise sum on inputs</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">equal</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs==rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">erf</span></code>(x)</p></td>
<td><p>Take gauss error function of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">exp</span></code>(x)</p></td>
<td><p>Take exponential of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">expand_dims</span></code>(a, axis[, num_newaxis])</p></td>
<td><p>Expand the shape of an array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">expand_like</span></code>(a, shape_like, axis)</p></td>
<td><p>Expand an input array with the shape of second array.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">extern</span></code>(shape, inputs, fcompute[, name, ...])</p></td>
<td><p>Compute several tensors via an extern function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fast_erf</span></code>(x)</p></td>
<td><p>Take gauss error function of input x using fast_erf implementation.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fast_exp</span></code>(x)</p></td>
<td><p>Take exponential of input x using fast_exp implementation</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fast_tanh</span></code>(x)</p></td>
<td><p>Take tanhonential of input x using fast_tanh implementation</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fixed_point_multiply</span></code>(x, multiplier, shift)</p></td>
<td><p>Fixed point multiplication between data and a fixed point constant expressed as multiplier * 2^(-shift), where multiplier is a Q-number with 31 fractional bits</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">flip</span></code>(a[, axis])</p></td>
<td><p>Flip/reverse elements of an array in a particular axis.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor</span></code>(x)</p></td>
<td><p>Take floor of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor_divide</span></code>(lhs, rhs)</p></td>
<td><p>Floor division with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor_mod</span></code>(lhs, rhs)</p></td>
<td><p>Floor modulus with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">full</span></code>(shape, dtype, fill_value)</p></td>
<td><p>Fill tensor with fill_value</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">full_like</span></code>(x, fill_value)</p></td>
<td><p>Construct a tensor with same shape as input tensor,</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">gather</span></code>(data, axis, indices)</p></td>
<td><p>Gather values along given axis from given indices.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">gather_nd</span></code>(a, indices)</p></td>
<td><p>Gather elements from a n-dimension array..</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_const_tuple</span></code>(in_tuple)</p></td>
<td><p>Verifies input tuple is IntImm or Var, returns tuple of int or Var.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">greater</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs&gt;rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">greater_equal</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs&gt;=rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_argwhere_1d</span></code>(output_shape, condition)</p></td>
<td><p>Find the indices of elements of a 1-D tensor that are non-zero.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_argwhere_2d</span></code>(output_shape, condition)</p></td>
<td><p>Find the indices of elements of a 2-D tensor that are non-zero.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_argwhere_3d</span></code>(output_shape, condition)</p></td>
<td><p>Find the indices of elements of a 3-D tensor that are non-zero.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_argwhere_4d</span></code>(output_shape, condition)</p></td>
<td><p>Find the indices of elements of a 4-D tensor that are non-zero.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_argwhere_5d</span></code>(output_shape, condition)</p></td>
<td><p>Find the indices of elements of a 5-D tensor that are non-zero.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">identity</span></code>(x)</p></td>
<td><p>Take identity of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">isfinite</span></code>(x)</p></td>
<td><p>Check if value of x is finite, element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">isinf</span></code>(x)</p></td>
<td><p>Check if value of x is infinite, element-wise.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">isnan</span></code>(x)</p></td>
<td><p>Check if value of x is NaN, element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">layout_transform</span></code>(array, src_layout, dst_layout)</p></td>
<td><p>Transform the layout according to src_layout and dst_layout</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">left_shift</span></code>(lhs, rhs)</p></td>
<td><p>Left shift with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">less</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs&lt;rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">less_equal</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs&lt;=rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">log</span></code>(x)</p></td>
<td><p>Take logarithm of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">log10</span></code>(x)</p></td>
<td><p>Take logarithm to the base 10 of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">log2</span></code>(x)</p></td>
<td><p>Take logarithm to the base 2 of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_and</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise logical and of data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_not</span></code>(data)</p></td>
<td><p>Compute element-wise logical not of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_or</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise logical or of data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_xor</span></code>(lhs, rhs)</p></td>
<td><p>Compute element-wise logical xor of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_idx</span></code>(b, e, s, z, i)</p></td>
<td><p>Return the array position in the selection that corresponds to an array position in the full array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">matmul</span></code>(a, b[, transp_a, transp_b])</p></td>
<td><p>Creates an operation that calculates a matrix multiplication (row-major notation): A(i, k) * B(k, j) if trans_a == trans_b, the usual transposed combinations, otherwise</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">matrix_set_diag</span></code>(data, diagonal[, k, align])</p></td>
<td><p>Returns a tensor with the diagonals of input tensor replaced with the provided diagonal values.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">max</span></code>(data[, axis, keepdims])</p></td>
<td><p>Maximum of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">maximum</span></code>(lhs, rhs)</p></td>
<td><p>Take element-wise maximum of two tensors with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">meshgrid</span></code>(a_tuple, indexing)</p></td>
<td><p>Create coordinate matrices from coordinate vectors.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">min</span></code>(data[, axis, keepdims])</p></td>
<td><p>Minimum of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">minimum</span></code>(lhs, rhs)</p></td>
<td><p>Take element-wise maximum of two tensors with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">mod</span></code>(lhs, rhs)</p></td>
<td><p>Modulus with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">multiply</span></code>(lhs, rhs)</p></td>
<td><p>Multiplication with auto-broadcasting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">ndarray_size</span></code>(array[, dtype])</p></td>
<td><p>Get the number of elements of input array</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">negative</span></code>(x)</p></td>
<td><p>Take negation of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">not_equal</span></code>(lhs, rhs)</p></td>
<td><p>Compute (lhs!=rhs) with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">one_hot</span></code>(indices, on_value, off_value, depth, ...)</p></td>
<td><p>Returns a one-hot tensor where the locations repsented by indices take value on_value, other locations take value off_value.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">power</span></code>(lhs, rhs)</p></td>
<td><p>Power with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">prod</span></code>(data[, axis, keepdims])</p></td>
<td><p>Product of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">reinterpret</span></code>(x, dtype)</p></td>
<td><p>Reinterpret input to specified data type.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">repeat</span></code>(a, repeats, axis)</p></td>
<td><p>Repeats elements of an array.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">reshape</span></code>(a, newshape)</p></td>
<td><p>Reshape the array</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">reverse_sequence</span></code>(a, seq_lengths[, seq_axis, ...])</p></td>
<td><p>Reverse the tensor for variable length slices.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">right_shift</span></code>(lhs, rhs)</p></td>
<td><p>Right shift with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">round</span></code>(x)</p></td>
<td><p>Round elements of x to nearest integer.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">rsqrt</span></code>(x)</p></td>
<td><p>Take inverse square root of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">scatter</span></code>(data, indices, updates[, axis])</p></td>
<td><p>Update data at positions defined by indices with values in updates</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">scatter_add</span></code>(data, indices, updates[, axis])</p></td>
<td><p>Update data by adding values in updates at positions defined by indices</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">scatter_nd</span></code>(data, indices, shape)</p></td>
<td><p>Scatter elements from a n-dimension array.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sequence_mask</span></code>(data, valid_length[, ...])</p></td>
<td><p>Sets all elements outside the expected length of the sequence to a constant value.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">shape</span></code>(array[, dtype])</p></td>
<td><p>Get the shape of input array</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sigmoid</span></code>(x)</p></td>
<td><p>Take sigmoid tanh of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sign</span></code>(x)</p></td>
<td><p>Returns -1, 0, 1 based on sign of x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sin</span></code>(x)</p></td>
<td><p>Take sin of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sinh</span></code>(x)</p></td>
<td><p>Take sinh of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sort</span></code>(data[, axis, is_ascend])</p></td>
<td><p>Performs sorting along the given axis and returns an array in sorted order.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse_to_dense</span></code>(sparse_indices, ...[, ...])</p></td>
<td><p>Converts a sparse representation into a dense tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">split</span></code>(ary, indices_or_sections[, axis])</p></td>
<td><p>Split an array into multiple sub-arrays.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sqrt</span></code>(x)</p></td>
<td><p>Take square root of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">squeeze</span></code>(a[, axis])</p></td>
<td><p>Remove single-dimensional entries from the shape of an array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">stack</span></code>(a, axis)</p></td>
<td><p>Repeats the whole array multiple times.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">strided_set</span></code>(a, v, begin, end[, strides])</p></td>
<td><p>Set slice of an array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">strided_slice</span></code>(a, begin, end[, strides, ...])</p></td>
<td><p>Slice of an array.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">subtract</span></code>(lhs, rhs)</p></td>
<td><p>Subtraction with auto-broadcasting</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sum</span></code>(data[, axis, keepdims])</p></td>
<td><p>Sum of array elements over a given axis or a list of axes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">take</span></code>(a, indices[, axis, mode])</p></td>
<td><p>Take elements from an array along an axis.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">take_legalize</span></code>(attrs, inputs, types)</p></td>
<td><p>Legalizes dyn.topk op.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tan</span></code>(x)</p></td>
<td><p>Take tan of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tanh</span></code>(x)</p></td>
<td><p>Take hyperbolic tanh of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensordot</span></code>(a, b, axes)</p></td>
<td><p>A generalization of matrix multiplication to tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tile</span></code>(a, reps)</p></td>
<td><p>Repeats the whole array multiple times.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">topk</span></code>(data[, k, axis, ret_type, is_ascend, dtype])</p></td>
<td><p>Get the top k elements in an input tensor along the given axis.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">transpose</span></code>(a[, axes])</p></td>
<td><p>Permute the dimensions of an array.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">trunc</span></code>(x)</p></td>
<td><p>Take truncated value of the input of x, element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">unravel_index</span></code>(indices, shape)</p></td>
<td><p>Convert a flat index or array of flat indices into a tuple of coordinate arrays.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">where</span></code>(condition, x, y)</p></td>
<td><p>Get the elements, either from x or y, depending on the condition.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">within_index</span></code>(b, e, s, i)</p></td>
<td><p>Return a boolean value that indicates if i is within the given index.</p></td>
</tr>
</tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">InvalidShapeError</span></code></p></td>
<td><p>Invalid shape for a topi function.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt id="tvm.topi.AssertStmt">
<em class="property">class </em><code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">AssertStmt</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">condition</span></em>, <em class="sig-param"><span class="n">message</span></em>, <em class="sig-param"><span class="n">body</span></em>, <em class="sig-param"><span class="n">span</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.AssertStmt" title="Permalink to this definition">¶</a></dt>
<dd><p>AssertStmt node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>condition</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) -- The assert condition.</p></li>
<li><p><strong>message</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) -- The error message.</p></li>
<li><p><strong>body</strong> (<a class="reference internal" href="tir.html#tvm.tir.Stmt" title="tvm.tir.Stmt"><em>Stmt</em></a>) -- The body statement.</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) -- The location of this itervar in the source code.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="tvm.topi.Cast">
<em class="property">class </em><code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">Cast</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dtype</span></em>, <em class="sig-param"><span class="n">value</span></em>, <em class="sig-param"><span class="n">span</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.Cast" title="Permalink to this definition">¶</a></dt>
<dd><p>Cast expression.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The data type</p></li>
<li><p><strong>value</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) -- The value of the function.</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) -- The location of this itervar in the source code.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="tvm.topi.Evaluate">
<em class="property">class </em><code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">Evaluate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">value</span></em>, <em class="sig-param"><span class="n">span</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.Evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<a class="reference internal" href="ir.html#tvm.ir.PrimExpr" title="tvm.ir.PrimExpr"><em>PrimExpr</em></a>) -- The expression to be evalued.</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) -- The location of this itervar in the source code.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="tvm.topi.StringImm">
<em class="property">class </em><code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">StringImm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">value</span></em>, <em class="sig-param"><span class="n">span</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.StringImm" title="Permalink to this definition">¶</a></dt>
<dd><p>String constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The value of the function.</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) -- The location of this itervar in the source code.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.abs">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">abs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.abs" title="Permalink to this definition">¶</a></dt>
<dd><p>Take absolute value of the input of x, element-wise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.acos">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">acos</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.acos" title="Permalink to this definition">¶</a></dt>
<dd><p>Take arc cos of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.acosh">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">acosh</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.acosh" title="Permalink to this definition">¶</a></dt>
<dd><p>Take arc cosh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.add">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">add</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.add" title="Permalink to this definition">¶</a></dt>
<dd><p>Addition with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.adv_index">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">adv_index</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">indices</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.adv_index" title="Permalink to this definition">¶</a></dt>
<dd><p>Numpy style indexing with tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input data.</p></li>
<li><p><strong>indices</strong> (<em>A list of tvm.te.Tensor</em>) -- Tensor index.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- Output tensor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.all">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">all</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">keepdims</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.all" title="Permalink to this definition">¶</a></dt>
<dd><p>Logical AND of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input tvm boolean tensor</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>tuple of int</em>) -- Axis or axes along which a logical AND is performed.
The default, axis=None, will perform logical AND over all elements of the input array.
If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.any">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">any</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">keepdims</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.any" title="Permalink to this definition">¶</a></dt>
<dd><p>Logical OR of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input tvm boolean tensor</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>tuple of int</em>) -- Axis or axes along which a logical OR is performed.
The default, axis=None, will perform logical OR over all elements of the input array.
If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.arange">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">arange</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">start</span></em>, <em class="sig-param"><span class="n">stop</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">step</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">dtype</span><span class="o">=</span><span class="default_value">'float32'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.arange" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a tensor with evenly spaced values within a given interval.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start</strong> (<em>tvm.Expr</em><em>, </em><em>optional</em>) -- Start of interval. The interval includes this value. The default start
value is 0.</p></li>
<li><p><strong>stop</strong> (<em>tvm.Expr</em>) -- Stop of interval. The interval does not include this value.</p></li>
<li><p><strong>step</strong> (<em>tvm.Expr</em><em>, </em><em>optional</em>) -- Spacing between values. The default step size is 1.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The target data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- The resulting tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.argmax">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">argmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">keepdims</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.argmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the indices of the maximum values along an axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>tuple of int</em>) -- Axis or axes along which a argmax operation is performed.
The default, axis=None, will find the indices of the maximum element of the elements of
the input array. If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.argmin">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">argmin</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">keepdims</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.argmin" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the indices of the minimum values along an axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>tuple of int</em>) -- Axis or axes along which a argmin operation is performed.
The default, axis=None, will find the indices of minimum element all of the elements of
the input array. If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.argsort">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">argsort</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">valid_count</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">is_ascend</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">dtype</span><span class="o">=</span><span class="default_value">'float32'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.argsort" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs sorting along the given axis and returns an array
of indices having the same shape as an input array that index
data in sorted order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input tensor.</p></li>
<li><p><strong>valid_count</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) -- 1-D tensor for valid number of boxes.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- Axis along which to sort the input tensor.
By default the flattened array is used.</p></li>
<li><p><strong>is_ascend</strong> (<em>boolean</em><em>, </em><em>optional</em>) -- Whether to sort in ascending or descending order.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- DType of the output indices.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> -- Sorted index tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># An example to use argsort</span>
<span class="n">dshape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dshape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">is_ascend</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">argsort</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">is_ascend</span><span class="o">=</span><span class="n">is_ascend</span><span class="p">)</span>
<span class="n">np_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">dshape</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">generic</span><span class="o">.</span><span class="n">schedule_argsort</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">out</span><span class="p">],</span> <span class="s2">&quot;llvm&quot;</span><span class="p">)</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="n">tvm_data</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np_data</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>
<span class="n">tvm_out</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dshape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
<span class="n">f</span><span class="p">(</span><span class="n">tvm_data</span><span class="p">,</span> <span class="n">tvm_out</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.argwhere">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">argwhere</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output_shape</span></em>, <em class="sig-param"><span class="n">condition</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.argwhere" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the indices of elements of a tensor that are non-zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>condition</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Tensor with boolean values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> -- Indices of non-zero elements.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.asin">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">asin</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.asin" title="Permalink to this definition">¶</a></dt>
<dd><p>Take arc sin of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.asinh">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">asinh</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.asinh" title="Permalink to this definition">¶</a></dt>
<dd><p>Take arc sinh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.atan">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">atan</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.atan" title="Permalink to this definition">¶</a></dt>
<dd><p>Take atan of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.atanh">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">atanh</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.atanh" title="Permalink to this definition">¶</a></dt>
<dd><p>Take atanh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.bitwise_and">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">bitwise_and</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.bitwise_and" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute element-wise bitwise and of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.bitwise_not">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">bitwise_not</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.bitwise_not" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute element-wise bitwise not of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if the operand are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.bitwise_or">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">bitwise_or</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.bitwise_or" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute element-wise bitwise or of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.bitwise_xor">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">bitwise_xor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.bitwise_xor" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute element-wise bitwise xor of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.broadcast_to">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">broadcast_to</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">shape</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.broadcast_to" title="Permalink to this definition">¶</a></dt>
<dd><p>Broadcast the src to the target shape</p>
<p>We follows the numpy broadcasting rule.
See also <a class="reference external" href="https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input data</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- The target shape to be broadcasted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.cast">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">dtype</span></em>, <em class="sig-param"><span class="n">span</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.cast" title="Permalink to this definition">¶</a></dt>
<dd><p>Cast input to specified data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- Input argument.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Data type.</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) -- The location of the cast in the source.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.ceil">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">ceil</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.ceil" title="Permalink to this definition">¶</a></dt>
<dd><p>Take ceil of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.clip">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">clip</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">a_min</span></em>, <em class="sig-param"><span class="n">a_max</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.clip" title="Permalink to this definition">¶</a></dt>
<dd><p>Clip (limit) the values in an array. Given an interval, values
outside the interval are clipped to the interval edges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p></li>
<li><p><strong>a_min</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- Minimum value.</p></li>
<li><p><strong>a_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- Maximum value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.concatenate">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">concatenate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a_tuple</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.concatenate" title="Permalink to this definition">¶</a></dt>
<dd><p>Join a sequence of arrays along an existing axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_tuple</strong> (<em>tuple of tvm.te.Tensor</em>) -- The arrays to concatenate</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- The axis along which the arrays will be joined. Default is 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.const_vector">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">const_vector</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vector</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">'const_vector'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.const_vector" title="Permalink to this definition">¶</a></dt>
<dd><p>convert a const numpy 1-dimensional vector to tvm tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vector</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.19)"><em>numpy.ndarray</em></a>) -- Const input array</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The name of output op</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>tensor</strong> -- The created tensor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.cos">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">cos</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.cos" title="Permalink to this definition">¶</a></dt>
<dd><p>Take cos of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.cosh">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">cosh</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.cosh" title="Permalink to this definition">¶</a></dt>
<dd><p>Take cosh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.decl_buffer">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">decl_buffer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">shape</span></em>, <em class="sig-param"><span class="n">dtype</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">'buffer'</span></em>, <em class="sig-param"><span class="n">data</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">strides</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">elem_offset</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scope</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">data_alignment</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">offset_factor</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">buffer_type</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">span</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.decl_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Declare a new symbolic buffer.</p>
<p>Normally buffer is created automatically during lower and build.
This is only needed if user want to specify their own buffer layout.</p>
<p>See the note below for detailed discussion on usage of buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>tuple of Expr</em>) -- The shape of the buffer.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The data type of the buffer.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The name of the buffer.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="tir.html#tvm.tir.Var" title="tvm.tir.Var"><em>Var</em></a><em>, </em><em>optional</em>) -- The data pointer in the buffer.</p></li>
<li><p><strong>strides</strong> (<em>array of Expr</em>) -- The stride of the buffer.</p></li>
<li><p><strong>elem_offset</strong> (<em>Expr</em><em>, </em><em>optional</em>) -- The beginning offset of the array to data.
In terms of number of elements of dtype.</p></li>
<li><p><strong>scope</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The storage scope of the buffer, if not global.
If scope equals empty string, it means it is global memory.</p></li>
<li><p><strong>data_alignment</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- The alignment of data pointer in bytes.
If -1 is passed, the alignment will be set to TVM's internal default.</p></li>
<li><p><strong>offset_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- The factor of elem_offset field, when set,
elem_offset is required to be multiple of offset_factor.
If 0 is pssed, the alignment will be set to 1.
if non-zero is passed, we will created a Var for elem_offset if elem_offset is not None.</p></li>
<li><p><strong>buffer_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em><em>, </em><em>{&quot;&quot;</em><em>, </em><em>&quot;auto_broadcast&quot;}</em>) -- auto_broadcast buffer allows one to implement broadcast computation
without considering whether dimension size equals to one.
TVM maps buffer[i][j][k] -&gt; buffer[i][0][k] if dimension j's shape equals 1.</p></li>
<li><p><strong>span</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="ir.html#tvm.ir.Span" title="tvm.ir.Span"><em>Span</em></a><em>]</em>) -- The location of the decl_buffer creation in the source.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>buffer</strong> -- The created buffer</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer">Buffer</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>Here's an example of how broadcast buffer can be used to define a symbolic broadcast operation,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">m0</span><span class="p">,</span> <span class="n">m1</span><span class="p">,</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;m0&quot;</span><span class="p">),</span> <span class="n">te</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;m1&quot;</span><span class="p">),</span> <span class="n">te</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;m2&quot;</span><span class="p">)</span>
<span class="n">n0</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;n0&quot;</span><span class="p">),</span> <span class="n">te</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;n1&quot;</span><span class="p">),</span> <span class="n">te</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;n2&quot;</span><span class="p">)</span>
<span class="n">o0</span><span class="p">,</span> <span class="n">o1</span><span class="p">,</span> <span class="n">o2</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;o0&quot;</span><span class="p">),</span> <span class="n">te</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;o1&quot;</span><span class="p">),</span> <span class="n">te</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;o2&quot;</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="n">m0</span><span class="p">,</span> <span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="n">n0</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">((</span><span class="n">o0</span><span class="p">,</span> <span class="n">o1</span><span class="p">,</span> <span class="n">o2</span><span class="p">),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>
<span class="n">Ab</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">decl_buffer</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Ab&quot;</span><span class="p">,</span> <span class="n">buffer_type</span><span class="o">=</span><span class="s2">&quot;auto_broadcast&quot;</span><span class="p">)</span>
<span class="n">Bb</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">decl_buffer</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">B</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Bb&quot;</span><span class="p">,</span> <span class="n">buffer_type</span><span class="o">=</span><span class="s2">&quot;auto_broadcast&quot;</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">create_schedule</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
<span class="n">fadd</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">],</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;llvm&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;bcast_add&#39;</span><span class="p">,</span> <span class="n">binds</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">:</span><span class="n">Ab</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span><span class="n">Bb</span><span class="p">})</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
<span class="n">fadd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="n">tvm</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">a</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span> <span class="o">+</span> <span class="n">b</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Buffer data structure reflects the DLTensor structure in dlpack.
While DLTensor data structure is very general, it is usually helpful
to create function that only handles specific case of data structure
and make compiled function benefit from it.</p>
<p>If user pass strides and elem_offset is passed as None
when constructing the function, then the function will be specialized
for the DLTensor that is compact and aligned.
If user pass a fully generic symbolic array to the strides,
then the resulting function becomes fully generic.</p>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.divide">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">divide</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.divide" title="Permalink to this definition">¶</a></dt>
<dd><p>Division with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.elemwise_sum">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">elemwise_sum</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">xs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.elemwise_sum" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform element-wise sum on inputs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>xs</strong> (<em>list of tvm.te.Tensor</em>) -- Input arguments.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.equal">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">equal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.equal" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute (lhs==rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.erf">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">erf</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.erf" title="Permalink to this definition">¶</a></dt>
<dd><p>Take gauss error function of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.exp">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">exp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Take exponential of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.expand_dims">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">expand_dims</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">axis</span></em>, <em class="sig-param"><span class="n">num_newaxis</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.expand_dims" title="Permalink to this definition">¶</a></dt>
<dd><p>Expand the shape of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be expanded.</p></li>
<li><p><strong>num_newaxis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- Number of newaxis to be inserted on axis</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.expand_like">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">expand_like</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">shape_like</span></em>, <em class="sig-param"><span class="n">axis</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.expand_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Expand an input array with the shape of second array.
This operation can always be composed of unsqueezing and
expanding dims on those unsqueezed axes.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">12.</span>  <span class="mf">19.</span>  <span class="mf">27.</span><span class="p">]</span>
<span class="nb">input</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,)</span>

<span class="n">new_shape_array</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">3</span><span class="p">]]]</span>
<span class="n">new_shape_array</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">expand_like</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">new_shape_array</span><span class="p">)</span> <span class="o">=</span>
                <span class="p">[[[</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">],[</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">],[</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mi">19</span><span class="p">,</span><span class="mi">19</span><span class="p">],[</span><span class="mi">19</span><span class="p">,</span><span class="mi">19</span><span class="p">],[</span><span class="mi">19</span><span class="p">,</span><span class="mi">19</span><span class="p">]],</span>
                <span class="p">[[</span><span class="mi">27</span><span class="p">,</span><span class="mi">27</span><span class="p">],[</span><span class="mi">27</span><span class="p">,</span><span class="mi">27</span><span class="p">],[</span><span class="mi">27</span><span class="p">,</span><span class="mi">27</span><span class="p">]]]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be expanded.</p></li>
<li><p><strong>shape_like</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to with target shape.</p></li>
<li><p><strong>axis</strong> (<em>list of int</em>) -- axis to be expanded on</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.extern">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">extern</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">shape</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">fcompute</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">'extern'</span></em>, <em class="sig-param"><span class="n">dtype</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">in_buffers</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">out_buffers</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tag</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">attrs</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.extern" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute several tensors via an extern function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em> or </em><em>list of tuples.</em>) -- The shape of the outputs.</p></li>
<li><p><strong>inputs</strong> (<em>list of Tensor</em>) -- The inputs</p></li>
<li><p><strong>fcompute</strong> (<em>lambda function of inputs</em><em>, </em><em>outputs-&gt; stmt</em>) -- <p>Specifies the IR statement to do the computation.
See the following note for function signature of fcompute</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Parameters</strong></p>
<ul>
<li><p><strong>ins</strong> (list of <a class="reference internal" href="tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Buffer</span></code></a>) - Placeholder for each inputs</p></li>
<li><p><strong>outs</strong> (list of <a class="reference internal" href="tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Buffer</span></code></a>) - Placeholder for each outputs</p></li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><p><strong>stmt</strong> (<a class="reference internal" href="tir.html#tvm.tir.Stmt" title="tvm.tir.Stmt"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Stmt</span></code></a>) - The statement that carries out array computation.</p></li>
</ul>
</div>
</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The name hint of the tensor</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em> or </em><em>list of str</em><em>, </em><em>optional</em>) -- The data types of outputs,
by default dtype will be same as inputs.</p></li>
<li><p><strong>in_buffers</strong> (<a class="reference internal" href="tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer"><em>Buffer</em></a><em> or </em><em>list of Buffer</em><em>, </em><em>optional</em>) -- Input buffers.</p></li>
<li><p><strong>out_buffers</strong> (<a class="reference internal" href="tir.html#tvm.tir.Buffer" title="tvm.tir.Buffer"><em>Buffer</em></a><em> or </em><em>list of Buffers</em><em>, </em><em>optional</em>) -- Output buffers.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>tag: str, optional</dt><dd><p>Additonal tag information about the compute.</p>
</dd>
<dt>attrs: dict, optional</dt><dd><p>The additional auxiliary attributes about the compute.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>tensor</strong> -- The created tensor or tuple of tensors it it contains multiple outputs.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">Tensor</a> or list of Tensors</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>In the code below, C is generated by calling external PackedFunc
<cite>tvm.contrib.cblas.matmul</cite></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">l</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;A&quot;</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="n">l</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;B&quot;</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">extern</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span>
               <span class="k">lambda</span> <span class="n">ins</span><span class="p">,</span> <span class="n">outs</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">call_packed</span><span class="p">(</span>
                  <span class="s2">&quot;tvm.contrib.cblas.matmul&quot;</span><span class="p">,</span>
                    <span class="n">ins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ins</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">outs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.fast_erf">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">fast_erf</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.fast_erf" title="Permalink to this definition">¶</a></dt>
<dd><p>Take gauss error function of input x using fast_erf implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.fast_exp">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">fast_exp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.fast_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Take exponential of input x using fast_exp implementation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.fast_tanh">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">fast_tanh</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.fast_tanh" title="Permalink to this definition">¶</a></dt>
<dd><p>Take tanhonential of input x using fast_tanh implementation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.fixed_point_multiply">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">fixed_point_multiply</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">multiplier</span></em>, <em class="sig-param"><span class="n">shift</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.fixed_point_multiply" title="Permalink to this definition">¶</a></dt>
<dd><p>Fixed point multiplication between data and a fixed point
constant expressed as multiplier * 2^(-shift), where multiplier
is a Q-number with 31 fractional bits</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- Input argument.</p></li>
<li><p><strong>multiplier</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Multiplier of a fixed floating point number described as multiplier*2^(-shift).</p></li>
<li><p><strong>shift</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Shift of a fixed floating point number described as multiplier*2^(-shift).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.flip">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">flip</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.flip" title="Permalink to this definition">¶</a></dt>
<dd><p>Flip/reverse elements of an array in a particular axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be expanded.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- The axis along which the tensors will be reveresed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.floor">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">floor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.floor" title="Permalink to this definition">¶</a></dt>
<dd><p>Take floor of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.floor_divide">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">floor_divide</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.floor_divide" title="Permalink to this definition">¶</a></dt>
<dd><p>Floor division with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.floor_mod">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">floor_mod</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.floor_mod" title="Permalink to this definition">¶</a></dt>
<dd><p>Floor modulus with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.full">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">full</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">shape</span></em>, <em class="sig-param"><span class="n">dtype</span></em>, <em class="sig-param"><span class="n">fill_value</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.full" title="Permalink to this definition">¶</a></dt>
<dd><p>Fill tensor with fill_value</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- Input tensor shape.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Data type</p></li>
<li><p><strong>fill_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- Value to be filled</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.full_like">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">full_like</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">fill_value</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.full_like" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Construct a tensor with same shape as input tensor,</dt><dd><p>then fill tensor with fill_value.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p></li>
<li><p><strong>fill_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- Value to be filled</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.gather">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">gather</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">axis</span></em>, <em class="sig-param"><span class="n">indices</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.gather" title="Permalink to this definition">¶</a></dt>
<dd><p>Gather values along given axis from given indices.</p>
<p>E.g. for a 3D tensor, output is computed as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if axis == 0</span>
<span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if axis == 1</span>
<span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span>  <span class="c1"># if axis == 2</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">indices</span></code> must have same shape as <code class="docutils literal notranslate"><span class="pre">data</span></code>, except at dimension <code class="docutils literal notranslate"><span class="pre">axis</span></code>
which must just be not null. Output will have same shape as <code class="docutils literal notranslate"><span class="pre">indices</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input data to the operator.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- The axis along which to index.</p></li>
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The indices of the values to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.gather_nd">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">gather_nd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">indices</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.gather_nd" title="Permalink to this definition">¶</a></dt>
<dd><p>Gather elements from a n-dimension array..</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The source array.</p></li>
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The indices of the values to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.get_const_tuple">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">get_const_tuple</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">in_tuple</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.get_const_tuple" title="Permalink to this definition">¶</a></dt>
<dd><p>Verifies input tuple is IntImm or Var, returns tuple of int or Var.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>in_tuple</strong> (<em>tuple of Expr</em>) -- The input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out_tuple</strong> -- The output.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple of int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.greater">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">greater</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.greater" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute (lhs&gt;rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.greater_equal">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">greater_equal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.greater_equal" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute (lhs&gt;=rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.hybrid_argwhere_1d">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">hybrid_argwhere_1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output_shape</span></em>, <em class="sig-param"><span class="n">condition</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.hybrid_argwhere_1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the indices of elements of a 1-D tensor that are non-zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>condition</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 1-D tensor with boolean values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> -- Indices of non-zero elements.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.hybrid_argwhere_2d">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">hybrid_argwhere_2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output_shape</span></em>, <em class="sig-param"><span class="n">condition</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.hybrid_argwhere_2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the indices of elements of a 2-D tensor that are non-zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>condition</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D tensor with boolean values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> -- Indices of non-zero elements.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.hybrid_argwhere_3d">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">hybrid_argwhere_3d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output_shape</span></em>, <em class="sig-param"><span class="n">condition</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.hybrid_argwhere_3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the indices of elements of a 3-D tensor that are non-zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>condition</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D tensor with boolean values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> -- Indices of non-zero elements.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.hybrid_argwhere_4d">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">hybrid_argwhere_4d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output_shape</span></em>, <em class="sig-param"><span class="n">condition</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.hybrid_argwhere_4d" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the indices of elements of a 4-D tensor that are non-zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>condition</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D tensor with boolean values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> -- Indices of non-zero elements.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.hybrid_argwhere_5d">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">hybrid_argwhere_5d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output_shape</span></em>, <em class="sig-param"><span class="n">condition</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.hybrid_argwhere_5d" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the indices of elements of a 5-D tensor that are non-zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>condition</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 5-D tensor with boolean values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> -- Indices of non-zero elements.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.identity">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">identity</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.identity" title="Permalink to this definition">¶</a></dt>
<dd><p>Take identity of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.isfinite">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">isfinite</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.isfinite" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if value of x is finite, element-wise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.isinf">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">isinf</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.isinf" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if value of x is infinite, element-wise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.isnan">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">isnan</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.isnan" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if value of x is NaN, element-wise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.layout_transform">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">layout_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">array</span></em>, <em class="sig-param"><span class="n">src_layout</span></em>, <em class="sig-param"><span class="n">dst_layout</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.layout_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the layout according to src_layout and dst_layout</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The source array.</p></li>
<li><p><strong>src_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- the source layout.</p></li>
<li><p><strong>dst_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- the destination layout.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.left_shift">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">left_shift</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.left_shift" title="Permalink to this definition">¶</a></dt>
<dd><p>Left shift with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.less">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">less</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.less" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute (lhs&lt;rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.less_equal">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">less_equal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.less_equal" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute (lhs&lt;=rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.log">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">log</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Take logarithm of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.log10">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">log10</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.log10" title="Permalink to this definition">¶</a></dt>
<dd><p>Take logarithm to the base 10 of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.log2">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">log2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.log2" title="Permalink to this definition">¶</a></dt>
<dd><p>Take logarithm to the base 2 of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.logical_and">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">logical_and</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.logical_and" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute element-wise logical and of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.logical_not">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">logical_not</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.logical_not" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute element-wise logical not of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if the operand are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.logical_or">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">logical_or</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.logical_or" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute element-wise logical or of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.logical_xor">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">logical_xor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.logical_xor" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute element-wise logical xor of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.make_idx">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">make_idx</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">e</span></em>, <em class="sig-param"><span class="n">s</span></em>, <em class="sig-param"><span class="n">z</span></em>, <em class="sig-param"><span class="n">i</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.make_idx" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the array position in the selection that corresponds to an
array position in the full array.</p>
<p>The returned value is only meaningful if within_index() returns True
for the same set of parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>Expr</em>) -- beginning of the index</p></li>
<li><p><strong>e</strong> (<em>Expr</em>) -- end of the index</p></li>
<li><p><strong>s</strong> (<em>Expr</em>) -- strides of index</p></li>
<li><p><strong>z</strong> (<em>Expr</em>) -- size of the indexed dimension</p></li>
<li><p><strong>i</strong> (<em>Expr</em>) -- array position</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>postion</strong> -- int expression that corresponds to an array position in the selection.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.matmul">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">matmul</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">transp_a</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">transp_b</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.matmul" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates an operation that calculates a matrix multiplication (row-major notation):
A(i, k) * B(k, j)
if trans_a == trans_b, the usual transposed combinations, otherwise</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>The matrix A</em>) -- </p></li>
<li><p><strong>b</strong> (<em>The matrix B</em>) -- </p></li>
<li><p><strong>trans_a</strong> (<em>Is A's layout transposed?</em>) -- </p></li>
<li><p><strong>trans_b</strong> (<em>Is B's layout transposed?</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A Tensor whose op member is the matmul operation</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.matrix_set_diag">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">matrix_set_diag</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">diagonal</span></em>, <em class="sig-param"><span class="n">k</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">align</span><span class="o">=</span><span class="default_value">'RIGHT_LEFT'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.matrix_set_diag" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a tensor with the diagonals of input tensor replaced with the provided diagonal values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>relay.Expr</em>) -- Input Tensor.</p></li>
<li><p><strong>diagonal</strong> (<em>relay.Expr</em>) -- Values to be filled in the diagonal.</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>tuple of int</em><em>, </em><em>optional</em>) -- Diagonal Offset(s). The diagonal or range of diagonals to set. (0 by default)
Positive value means superdiagonal, 0 refers to the main diagonal, and
negative value means subdiagonals. k can be a single integer (for a single diagonal)
or a pair of integers specifying the low and high ends of a matrix band.
k[0] must not be larger than k[1].</p></li>
<li><p><strong>align</strong> (<em>string</em><em>, </em><em>optional</em>) -- Some diagonals are shorter than max_diag_len and need to be padded.
align is a string specifying how superdiagonals and subdiagonals should be aligned,
respectively. There are four possible alignments: &quot;RIGHT_LEFT&quot; (default), &quot;LEFT_RIGHT&quot;,
&quot;LEFT_LEFT&quot;, and &quot;RIGHT_RIGHT&quot;. &quot;RIGHT_LEFT&quot; aligns superdiagonals to the right
(left-pads the row) and subdiagonals to the left (right-pads the row). It is the packing
format LAPACK uses. cuSPARSE uses &quot;LEFT_RIGHT&quot;, which is the opposite alignment.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- New tensor with given diagonal values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>relay.Expr</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">]]]</span>

<span class="n">diagonal</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
            <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]</span>

<span class="n">topi</span><span class="o">.</span><span class="n">matrix_set_diag</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">)</span> <span class="o">=</span>
    <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span>
     <span class="p">[[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.max">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">max</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">keepdims</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.max" title="Permalink to this definition">¶</a></dt>
<dd><p>Maximum of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>tuple of int</em>) -- Axis or axes along which the max operation is performed.
The default, axis=None, will find the max element from all of the elements of the input
array. If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.maximum">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">maximum</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.maximum" title="Permalink to this definition">¶</a></dt>
<dd><p>Take element-wise maximum of two tensors with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.meshgrid">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">meshgrid</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a_tuple</span></em>, <em class="sig-param"><span class="n">indexing</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.meshgrid" title="Permalink to this definition">¶</a></dt>
<dd><p>Create coordinate matrices from coordinate vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_tuple</strong> (<em>tuple of tvm.te.Tensor</em>) -- The coordinate vectors or scalars.</p></li>
<li><p><strong>indexing</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Indexing mode, either &quot;ij&quot; or &quot;xy&quot;.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- The resulting grids for each axis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple of tvm.te.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.min">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">min</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">keepdims</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.min" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimum of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>tuple of int</em>) -- Axis or axes along which a minimum operation is performed.
The default, axis=None, will find the minimum element from all of the elements of the
input array. If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.minimum">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">minimum</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.minimum" title="Permalink to this definition">¶</a></dt>
<dd><p>Take element-wise maximum of two tensors with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.mod">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">mod</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.mod" title="Permalink to this definition">¶</a></dt>
<dd><p>Modulus with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.multiply">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">multiply</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.multiply" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiplication with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.ndarray_size">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">ndarray_size</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">array</span></em>, <em class="sig-param"><span class="n">dtype</span><span class="o">=</span><span class="default_value">'int32'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.ndarray_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the number of elements of input array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The source tensor.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The target data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- The resulting tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.negative">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">negative</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.negative" title="Permalink to this definition">¶</a></dt>
<dd><p>Take negation of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.not_equal">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">not_equal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.not_equal" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute (lhs!=rhs) with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.one_hot">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">one_hot</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">indices</span></em>, <em class="sig-param"><span class="n">on_value</span></em>, <em class="sig-param"><span class="n">off_value</span></em>, <em class="sig-param"><span class="n">depth</span></em>, <em class="sig-param"><span class="n">axis</span></em>, <em class="sig-param"><span class="n">dtype</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.one_hot" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a one-hot tensor where the locations repsented by indices take value on_value,
other locations take value off_value.
Final dimension is &lt;indices outer dimensions&gt; x depth x &lt;indices inner dimensions&gt;.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Locations to set to on_value.</p></li>
<li><p><strong>on_value</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Value to fill at indices.</p></li>
<li><p><strong>off_value</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Value to fill at all other positions besides indices.</p></li>
<li><p><strong>depth</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Depth of the one-hot dimension.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Axis to fill.</p></li>
<li><p><strong>dtype</strong> (<em>relay.DataType</em>) -- Data type of the output tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- The one-hot tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>relay.Expr</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="n">relay</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">=</span>
    <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.power">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">power</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.power" title="Permalink to this definition">¶</a></dt>
<dd><p>Power with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.prod">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">prod</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">keepdims</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.prod" title="Permalink to this definition">¶</a></dt>
<dd><p>Product of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>tuple of int</em>) -- Axis or axes along which a prod operation is performed.
The default, axis=None, will get the prod element over all of the elements of the
input array. If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.reinterpret">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">reinterpret</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">dtype</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.reinterpret" title="Permalink to this definition">¶</a></dt>
<dd><p>Reinterpret input to specified data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.repeat">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">repeat</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">repeats</span></em>, <em class="sig-param"><span class="n">axis</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.repeat" title="Permalink to this definition">¶</a></dt>
<dd><p>Repeats elements of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be repeated.</p></li>
<li><p><strong>repeats</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>required</em>) -- Number of repetitions for each element</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- The axis along which to repeat values</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.reshape">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">reshape</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">newshape</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.reshape" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshape the array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be reshaped</p></li>
<li><p><strong>newshape</strong> (<em>tuple of ints</em>) -- The new shape</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.reverse_sequence">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">reverse_sequence</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">seq_lengths</span></em>, <em class="sig-param"><span class="n">seq_axis</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">batch_axis</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.reverse_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>Reverse the tensor for variable length slices.
Input is first sliced along batch axis and then elements are reversed along seq axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be reversed.</p></li>
<li><p><strong>seq_lengths</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- A 1D Tensor with length a.dims[batch_axis]
Must be one of the following types: int32, int64
if seq_lengths[i] &gt; a.dims[seq_axis], it is rounded to a.dims[seq_axis]
if seq_lengths[i] &lt; 1, it is rounded to 1</p></li>
<li><p><strong>seq_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- The axis along which the elements will be reversed. Default is 1.</p></li>
<li><p><strong>batch_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- The axis along which the tensor will be sliced. Default is 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- The computed result of same shape and type as of input.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.right_shift">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">right_shift</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.right_shift" title="Permalink to this definition">¶</a></dt>
<dd><p>Right shift with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.round">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">round</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.round" title="Permalink to this definition">¶</a></dt>
<dd><p>Round elements of x to nearest integer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.rsqrt">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">rsqrt</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.rsqrt" title="Permalink to this definition">¶</a></dt>
<dd><p>Take inverse square root of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.scatter">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">scatter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">indices</span></em>, <em class="sig-param"><span class="n">updates</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.scatter" title="Permalink to this definition">¶</a></dt>
<dd><p>Update data at positions defined by indices with values in updates</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>relay.Expr</em>) -- The input data to the operator.</p></li>
<li><p><strong>indices</strong> (<em>relay.Expr</em>) -- The index locations to update.</p></li>
<li><p><strong>updates</strong> (<em>relay.Expr</em>) -- The values to update.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- The axis to scatter on</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- The computed result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>relay.Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.scatter_add">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">scatter_add</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">indices</span></em>, <em class="sig-param"><span class="n">updates</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.scatter_add" title="Permalink to this definition">¶</a></dt>
<dd><p>Update data by adding values in updates at positions defined by indices</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>relay.Expr</em>) -- The input data to the operator.</p></li>
<li><p><strong>indices</strong> (<em>relay.Expr</em>) -- The index locations to update.</p></li>
<li><p><strong>updates</strong> (<em>relay.Expr</em>) -- The values to update.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- The axis to scatter_add on</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- The computed result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>relay.Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.scatter_nd">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">scatter_nd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">indices</span></em>, <em class="sig-param"><span class="n">shape</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.scatter_nd" title="Permalink to this definition">¶</a></dt>
<dd><p>Scatter elements from a n-dimension array.</p>
<p>Given data with shape (Y_0, ..., Y_{K-1}, X_M, ..., X_{N-1}), indices with shape
(M, Y_0, ..., Y_{K-1}), and output with shape (X_0, X_1, ..., X_{N-1}), scatter_nd computes</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">y_0</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">y_</span><span class="p">{</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">}],</span>
       <span class="o">...</span><span class="p">,</span>
       <span class="n">indices</span><span class="p">[</span><span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">y_0</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">y_</span><span class="p">{</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">}],</span>
       <span class="n">x_M</span><span class="p">,</span>
       <span class="o">...</span><span class="p">,</span>
       <span class="n">x_</span><span class="p">{</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">}</span>
      <span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">y_0</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">y_</span><span class="p">{</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">},</span> <span class="n">x_M</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">x_</span><span class="p">{</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">}]</span>
</pre></div>
</div>
<p>all other entries in the output are 0. Repeated indices are summed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The source array.</p></li>
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The indices of the values to extract.</p></li>
<li><p><strong>shape</strong> (<em>Sequence</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>]</em>) -- The output shape. This must be specified because it cannot be inferred.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.sequence_mask">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">sequence_mask</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">valid_length</span></em>, <em class="sig-param"><span class="n">mask_value</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sequence_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets all elements outside the expected length of the sequence to a constant value.</p>
<p>This function takes an n-dimensional input array of the form [MAX_LENGTH, batch_size, ...] or
[batch_size, MAX_LENGTH, ...] and returns an array of the same shape.</p>
<p><cite>axis</cite> means the axis of the length dimension and can only be 0 or 1. If <cite>axis</cite> is 0,
the data must have shape [MAX_LENGTH, batch_size, ...]. Otherwise (axis=1), the data must have
shape [batch_size, MAX_LENGTH, ...].</p>
<p><cite>valid_length</cite> gives the length of each sequence. <cite>valid_length</cite> should be
a 1D int array with positive ints and has dimension [batch_size,].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- N-D with shape [MAX_LENGTH, batch_size, ...] or [batch_size, MAX_LENGTH, ...]
depending on the value of <cite>axis</cite>.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 1-D with shape [batch_size,]</p></li>
<li><p><strong>mask_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em>) -- The masking value, default 0</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- axis of the length dimension, must be 0 or 1, default 0</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- N-D with shape [MAX_LENGTH, batch_size, ...] or [batch_size, MAX_LENGTH, ...]
depending on the value of <cite>axis</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.shape">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">shape</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">array</span></em>, <em class="sig-param"><span class="n">dtype</span><span class="o">=</span><span class="default_value">'int32'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of input array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The source tensor.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The target data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- The resulting tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.sigmoid">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">sigmoid</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>Take sigmoid tanh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.sign">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">sign</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sign" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns -1, 0, 1 based on sign of x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.sin">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">sin</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sin" title="Permalink to this definition">¶</a></dt>
<dd><p>Take sin of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.sinh">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">sinh</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sinh" title="Permalink to this definition">¶</a></dt>
<dd><p>Take sinh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.sort">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">sort</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">is_ascend</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sort" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs sorting along the given axis and returns an array
in sorted order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input tensor.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- Axis along which to sort the input tensor.
By default the flattened array is used.</p></li>
<li><p><strong>is_ascend</strong> (<em>boolean</em><em>, </em><em>optional</em>) -- Whether to sort in ascending or descending order.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- DType of the output indices.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> -- Sorted index tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.sparse_to_dense">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">sparse_to_dense</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sparse_indices</span></em>, <em class="sig-param"><span class="n">output_shape</span></em>, <em class="sig-param"><span class="n">sparse_values</span></em>, <em class="sig-param"><span class="n">default_value</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sparse_to_dense" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts a sparse representation into a dense tensor.</p>
<p>Example::
-   sparse_to_dense([[0, 0], [1, 1]], [2, 2], [3, 3], 0) = [[3, 0], [0, 3]]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sparse_indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- A 0-D, 1-D, or 2-D tensor of integers containing location of sparse values.</p></li>
<li><p><strong>output_shape</strong> (<em>A list of integers</em>) -- Shape of the dense output tensor.</p></li>
<li><p><strong>sparse_values</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- A 0-D or 1-D tensor containing the sparse values for the sparse indices.</p></li>
<li><p><strong>default_value</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- A 0-D tensor containing the default value for the remaining locations.
Defaults to 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- Dense tensor of shape output_shape. Has the same type as sparse_values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.split">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">split</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ary</span></em>, <em class="sig-param"><span class="n">indices_or_sections</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Split an array into multiple sub-arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ary</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- </p></li>
<li><p><strong>indices_or_sections</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>1-D array</em>) -- </p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple of tvm.te.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.sqrt">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">sqrt</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sqrt" title="Permalink to this definition">¶</a></dt>
<dd><p>Take square root of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.squeeze">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">squeeze</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.squeeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove single-dimensional entries from the shape of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- </p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>tuple of ints</em><em>, </em><em>optional</em>) -- Selects a subset of the single-dimensional entries in the shape.
If an axis is selected with shape entry greater than one, an error is raised.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>squeezed</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.stack">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">stack</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">axis</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.stack" title="Permalink to this definition">¶</a></dt>
<dd><p>Repeats the whole array multiple times.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be stacked.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- The axis in the result array along which the input arrays are stacked.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.strided_set">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">strided_set</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">begin</span></em>, <em class="sig-param"><span class="n">end</span></em>, <em class="sig-param"><span class="n">strides</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.strided_set" title="Permalink to this definition">¶</a></dt>
<dd><p>Set slice of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be sliced.</p></li>
<li><p><strong>v</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The values to set</p></li>
<li><p><strong>begin</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The indices to begin with in the slicing.</p></li>
<li><p><strong>end</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Indicies indicating end of the slice.</p></li>
<li><p><strong>strides</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) -- Specifies the stride values, it can be negative
in that case, the input tensor will be reversed
in that particular axis.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.strided_slice">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">strided_slice</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">begin</span></em>, <em class="sig-param"><span class="n">end</span></em>, <em class="sig-param"><span class="n">strides</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">slice_mode</span><span class="o">=</span><span class="default_value">'end'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.strided_slice" title="Permalink to this definition">¶</a></dt>
<dd><p>Slice of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be sliced.</p></li>
<li><p><strong>begin</strong> (<em>list of int</em>) -- The indices to begin with in the slicing.</p></li>
<li><p><strong>end</strong> (<em>list of int</em>) -- Indicies indicating end of the slice.</p></li>
<li><p><strong>strides</strong> (<em>list of int</em><em>, </em><em>optional</em>) -- Specifies the stride values, it can be negative
in that case, the input tensor will be reversed
in that particular axis.</p></li>
<li><p><strong>slice_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The slice mode [end, size].
end - The ending indices for the slice [default].
size - The input strides will be ignored, input end in this mode indicates
the sizeof a slice starting at the location specified by begin. If end[i]
is -1, all remaining elements in that dimension are included in the slice.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.subtract">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">subtract</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lhs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.subtract" title="Permalink to this definition">¶</a></dt>
<dd><p>Subtraction with auto-broadcasting</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The left operand</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em> or </em><em>Expr</em>) -- The right operand</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> -- Returns Expr if both operands are Expr.
Otherwise returns Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.sum">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">sum</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">keepdims</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sum" title="Permalink to this definition">¶</a></dt>
<dd><p>Sum of array elements over a given axis or a list of axes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input tvm tensor</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>tuple of int</em>) -- Axis or axes along which a sum is performed.
The default, axis=None, will sum all of the elements of the input array.
If axis is negative it counts from the last to the first axis.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- If this is set to True, the axes which are reduced are left in the result as dimensions
with size one.
With this option, the result will broadcast correctly against the input array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.take">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">take</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">indices</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">mode</span><span class="o">=</span><span class="default_value">'clip'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.take" title="Permalink to this definition">¶</a></dt>
<dd><p>Take elements from an array along an axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The source array.</p></li>
<li><p><strong>indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The indices of the values to extract.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- The axis over which to select values. By default,
the flattened input array is used.</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- Specifies how out-of-bound indices will behave.
clip - clip to the range (default)
wrap - wrap around the indices
fast - no clip or wrap around (user must make sure indices are in-bound)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.take_legalize">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">take_legalize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">attrs</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">types</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.take_legalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Legalizes dyn.topk op.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attrs</strong> (<a class="reference internal" href="ir.html#tvm.ir.Attrs" title="tvm.ir.Attrs"><em>tvm.ir.Attrs</em></a>) -- Attributes of current op</p></li>
<li><p><strong>inputs</strong> (<em>list of tvm.relay.Expr</em>) -- The args of the Relay expr to be legalized</p></li>
<li><p><strong>types</strong> (<em>list of types</em>) -- List of input and output types</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- The legalized expr</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tvm.relay.Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.tan">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">tan</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.tan" title="Permalink to this definition">¶</a></dt>
<dd><p>Take tan of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.tanh">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">tanh</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.tanh" title="Permalink to this definition">¶</a></dt>
<dd><p>Take hyperbolic tanh of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.tensordot">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">tensordot</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">axes</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.tensordot" title="Permalink to this definition">¶</a></dt>
<dd><p>A generalization of matrix multiplication to tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>The tensor A</em>) -- </p></li>
<li><p><strong>b</strong> (<em>The tensor B</em>) -- </p></li>
<li><p><strong>axes</strong> (<em>The number of dimensions to reduce over</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A Tensor computing the result</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.tile">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">tile</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">reps</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.tile" title="Permalink to this definition">¶</a></dt>
<dd><p>Repeats the whole array multiple times.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be tiled.</p></li>
<li><p><strong>reps</strong> (<em>tuple of ints</em><em>, </em><em>required</em>) -- The number of times for repeating the tensor</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.topk">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">topk</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">k</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">ret_type</span><span class="o">=</span><span class="default_value">'both'</span></em>, <em class="sig-param"><span class="n">is_ascend</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">dtype</span><span class="o">=</span><span class="default_value">'int64'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.topk" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the top k elements in an input tensor along the given axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input tensor.</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) -- Number of top elements to select. Return all elements if k &lt; 1.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- Axis long which to sort the input tensor.</p></li>
<li><p><strong>ret_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The return type [both, values, indices].
&quot;both&quot;: return both top k data and indices.
&quot;values&quot;: return top k data only.
&quot;indices&quot;: return top k indices only.</p></li>
<li><p><strong>is_ascend</strong> (<em>boolean</em><em>, </em><em>optional</em>) -- Whether to sort in ascending or descending order.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- The data type of the indices output.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> -- The computed result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a> or <a class="reference internal" href="relay/dataflow_pattern.html#tvm.relay.dataflow_pattern.List" title="tvm.relay.dataflow_pattern.List">List</a>[<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.transpose">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">transpose</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">axes</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.transpose" title="Permalink to this definition">¶</a></dt>
<dd><p>Permute the dimensions of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be expanded.</p></li>
<li><p><strong>axes</strong> (<em>tuple of ints</em><em>, </em><em>optional</em>) -- By default, reverse the dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.trunc">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">trunc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.trunc" title="Permalink to this definition">¶</a></dt>
<dd><p>Take truncated value of the input of x, element-wise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.unravel_index">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">unravel_index</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">indices</span></em>, <em class="sig-param"><span class="n">shape</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.unravel_index" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a flat index or array of flat indices into a tuple of coordinate arrays.</p>
<p>Example::
-   unravel_index([22, 41, 37], [7, 6]) = [[3, 6, 6], [4, 5, 1]]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>relay.Expr</em>) -- An integer array containing indices.</p></li>
<li><p><strong>shape</strong> (<em>relay.Expr</em>) -- The shape of the array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- The tuple of coordinate arrays.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>relay.Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.where">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">where</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">condition</span></em>, <em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.where" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the elements, either from x or y, depending on the condition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>condition</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The condition array.</p></li>
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- First array to be selected.</p></li>
<li><p><strong>y</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Second array to be selected.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- A Tensor selected from x or y depending on condition.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.within_index">
<code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">within_index</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">e</span></em>, <em class="sig-param"><span class="n">s</span></em>, <em class="sig-param"><span class="n">i</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.within_index" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a boolean value that indicates if i is within the given index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>Expr</em>) -- beginning of the index</p></li>
<li><p><strong>e</strong> (<em>Expr</em>) -- end of the index</p></li>
<li><p><strong>s</strong> (<em>Expr</em>) -- strides of index</p></li>
<li><p><strong>i</strong> (<em>Expr</em>) -- array position</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>selected</strong> -- bool expression that is True is the array position would be selected
by the index and False otherwise</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py exception">
<dt id="tvm.topi.InvalidShapeError">
<em class="property">exception </em><code class="sig-prename descclassname">tvm.topi.</code><code class="sig-name descname">InvalidShapeError</code><a class="headerlink" href="#tvm.topi.InvalidShapeError" title="Permalink to this definition">¶</a></dt>
<dd><p>Invalid shape for a topi function. i.e. call winograd template for non-3x3 kernel)</p>
</dd></dl>

<div class="section" id="module-tvm.topi.nn">
<span id="tvm-topi-nn"></span><h2>tvm.topi.nn<a class="headerlink" href="#module-tvm.topi.nn" title="Permalink to this headline">¶</a></h2>
<p>Neural network operators</p>
<p><strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Workload</span></code>(in_dtype, out_dtype, height, width, ...)</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p><strong>Functions:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">adaptive_pool</span></code>(data, output_size, pool_type)</p></td>
<td><p>Perform pooling on height and width dimension of data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">adaptive_pool3d</span></code>(data, output_size, pool_type)</p></td>
<td><p>Perform pooling on three dimensional data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_matmul</span></code>(x, y[, oshape, ...])</p></td>
<td><p>Computes batch matrix multiplication of <cite>x</cite> and <cite>y</cite> when <cite>x</cite> and <cite>y</cite> are data in batch.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_to_space_nd</span></code>(data, block_shape, ...)</p></td>
<td><p>Perform space to batch transformation on the data</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">binarize_pack</span></code>(data[, axis, name])</p></td>
<td><p>Binarization and bit-packing along a certain axis.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">binary_dense</span></code>(data, weight)</p></td>
<td><p>Binary matrix multiplication using xor and bit-count.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitpack</span></code>(data, bits, pack_axis, bit_axis, ...)</p></td>
<td><p>Packs data into format necessary for bitserial computation</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitserial_conv2d_legalize</span></code>(attrs, inputs, types)</p></td>
<td><p>Legalizes Bitserial Conv2D op.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitserial_conv2d_nchw</span></code>(data, kernel, stride, ...)</p></td>
<td><p>Bitserial Conv2D operator.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitserial_conv2d_nhwc</span></code>(data, kernel, stride, ...)</p></td>
<td><p>Bitserial Conv2D operator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitserial_dense</span></code>(data, weight, data_bits, ...)</p></td>
<td><p>The default implementation of bitserial dense in topi.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">concatenate</span></code>(a_tuple[, axis])</p></td>
<td><p>Join a sequence of arrays along an existing axis.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv1d</span></code>(data, kernel[, strides, padding, ...])</p></td>
<td><p>1D convolution forward operator.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv1d_ncw</span></code>(data, kernel[, strides, padding, ...])</p></td>
<td><p>1D convolution forward operator for NCW layout.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv1d_nwc</span></code>(data, kernel[, strides, padding, ...])</p></td>
<td><p>1D convolution forward operator for NWC layout.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv1d_transpose_ncw</span></code>(data, kernel, stride, ...)</p></td>
<td><p>Transposed 1D convolution ncw forward operator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d</span></code>(input, filter, strides, padding, dilation)</p></td>
<td><p>Conv2D operator.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_NCHWc</span></code>(data, kernel, stride, padding, ...)</p></td>
<td><p>Conv2D operator for nChw[x]c layout.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_NCHWc_int8</span></code>(data, kernel, stride, ...)</p></td>
<td><p>Conv2D operator for nChw[x]c layout.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_alter_layout</span></code>(attrs, inputs, tinfos, ...)</p></td>
<td><p>Change Conv2D layout.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_gemm_weight_transform</span></code>(kernel, ...)</p></td>
<td><p>Weight transformation for winograd</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_hwcn</span></code>(Input, Filter, stride, padding, ...)</p></td>
<td><p>Convolution operator in HWCN layout.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_infer_layout</span></code>(workload, cfg)</p></td>
<td><p>Infer input/output shapes and layouts from a workload and cfg.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_legalize</span></code>(attrs, inputs, types)</p></td>
<td><p>Legalizes Conv2D op.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_nchw</span></code>(Input, Filter, stride, padding, ...)</p></td>
<td><p>Convolution operator in NCHW layout.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_nhwc</span></code>(Input, Filter, stride, padding, ...)</p></td>
<td><p>Convolution operator in NHWC layout.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_transpose_legalize</span></code>(attrs, inputs, types)</p></td>
<td><p>Legalizes Transposed 2D convolution op.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_transpose_nchw</span></code>(Input, Filter, ...)</p></td>
<td><p>Transposed 2D convolution nchw forward operator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_transpose_nchw_preprocess</span></code>(data, ...)</p></td>
<td><p>Preprocess data and kernel to make the compute pattern of conv2d_transpose the same as conv2d</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_winograd_nhwc</span></code>(data, weight, strides, ...)</p></td>
<td><p>Conv2D Winograd in NHWC layout.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_winograd_nhwc_without_weight_transform</span></code>(...)</p></td>
<td><p>Conv2D Winograd without layout transform in NHWC layout.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_winograd_nnpack_weight_transform</span></code>(...)</p></td>
<td><p>Weight transformation for winograd</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv2d_winograd_weight_transform</span></code>(kernel, ...)</p></td>
<td><p>Weight transformation for winograd</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_alter_layout</span></code>(attrs, inputs, tinfos, ...)</p></td>
<td><p>Change Conv3D layout.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_ncdhw</span></code>(Input, Filter, stride, padding, ...)</p></td>
<td><p>Conv3D operator in NCDHW layout.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_ndhwc</span></code>(Input, Filter, stride, padding, ...)</p></td>
<td><p>Convolution operator in NDHWC layout.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_transpose_legalize</span></code>(attrs, inputs, types)</p></td>
<td><p>Legalizes Transposed 3D convolution op.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_transpose_ncdhw</span></code>(Input, Filter, ...)</p></td>
<td><p>Transposed 3D convolution ncdhw forward operator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_transpose_ncdhw_preprocess</span></code>(data, ...)</p></td>
<td><p>Preprocess data and kernel to make the compute pattern of conv3d_transpose the same as conv3d</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">conv3d_winograd_weight_transform</span></code>(kernel, ...)</p></td>
<td><p>Weight transformation for 3D winograd</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">correlation_nchw</span></code>(data1, data2, kernel_size, ...)</p></td>
<td><p>Correlation operator in NCHW layout.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">declaration_conv2d_transpose_impl</span></code>(data, ...)</p></td>
<td><p>Implementation of conv2d transpose</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">declaration_conv3d_transpose_impl</span></code>(data, ...)</p></td>
<td><p>Implementation of conv3d transpose</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">deformable_conv2d_nchw</span></code>(data, offset, kernel, ...)</p></td>
<td><p>Deformable conv2D operator in NCHW layout.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">deformable_conv2d_nhwc</span></code>(data, offset, kernel, ...)</p></td>
<td><p>Deformable conv2D operator in NHWC layout.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dense</span></code>(data, weight[, bias, out_dtype, ...])</p></td>
<td><p>The default implementation of dense in topi.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">depth_to_space</span></code>(data, block_size[, layout, mode])</p></td>
<td><p>Perform depth to space transformation on the data</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_conv2d_NCHWc</span></code>(Input, Filter, ...[, ...])</p></td>
<td><p>Depthwise convolution NCHW[x]c forward operator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_conv2d_backward_input_nhwc</span></code>(Filter, ...)</p></td>
<td><p>Depthwise convolution nhwc backward wrt input operator.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_conv2d_backward_weight_nhwc</span></code>(Input, ...)</p></td>
<td><p>Depthwise convolution nhwc backward wrt weight operator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_conv2d_infer_layout</span></code>(workload, cfg)</p></td>
<td><p>Infer input/output shapes and layouts from a workload and cfg.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_conv2d_nchw</span></code>(Input, Filter, stride, ...)</p></td>
<td><p>Depthwise convolution nchw forward operator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">depthwise_conv2d_nhwc</span></code>(Input, Filter, stride, ...)</p></td>
<td><p>Depthwise convolution nhwc forward operator.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dilate</span></code>(data, strides[, dilation_value, name])</p></td>
<td><p>Dilate data with given dilation value (0 by default).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">equal_const_int</span></code>(expr, value)</p></td>
<td><p>Returns if expr equals value.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fast_softmax</span></code>(x[, axis])</p></td>
<td><p>Perform softmax activation on the data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fifo_buffer</span></code>(data, buffer, axis)</p></td>
<td><p>FIFO buffer to enable computation reuse in CNNs with sliding indow input</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">flatten</span></code>(data)</p></td>
<td><p>Flattens the input array into a 2-D array by collapsing the higher dimensions.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_const_int</span></code>(expr)</p></td>
<td><p>Verifies expr is integer and get the constant value.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_const_tuple</span></code>(in_tuple)</p></td>
<td><p>Verifies input tuple is IntImm or Var, returns tuple of int or Var.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_pad_tuple</span></code>(padding, kernel)</p></td>
<td><p>Common code to get the pad option</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_pad_tuple1d</span></code>(padding, kernel)</p></td>
<td><p>Common code to get the pad option</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_pad_tuple3d</span></code>(padding, kernel)</p></td>
<td><p>Common code to get the pad option</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_pool</span></code>(data, pool_type[, layout])</p></td>
<td><p>Perform global pooling on height and width dimension of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_conv2d_nchw</span></code>(Input, Filter, stride, ...)</p></td>
<td><p>Group convolution operator in NCHW layout.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_conv2d_nhwc</span></code>(Input, Filter, stride, ...)</p></td>
<td><p>Group convolution operator in NHWC layout.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">leaky_relu</span></code>(x, alpha)</p></td>
<td><p>Take leaky relu of input x.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_softmax</span></code>(x)</p></td>
<td><p>Perform log softmax activation on the data</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">lrn</span></code>(data, size[, axis, alpha, beta, bias])</p></td>
<td><p>Perform the across channels local response normalisation on the input data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">mirror_pad</span></code>(data, pad_before[, pad_after, ...])</p></td>
<td><p>Pad Input with mirroring either symmetric or reflected.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>(typename, field_names, *[, ...])</p></td>
<td><p>Returns a new subclass of tuple with named fields.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pad</span></code>(data, pad_before[, pad_after, ...])</p></td>
<td><p>Pad Input with zeros.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pool</span></code>(data, kernel, stride, padding, pool_type)</p></td>
<td><p>Perform pooling on height and width dimension of data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pool1d</span></code>(data, kernel, stride, padding, pool_type)</p></td>
<td><p>Perform pooling on width dimension of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pool3d</span></code>(data, kernel, stride, padding, pool_type)</p></td>
<td><p>Perform pooling on depth, height and width dimension of data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pool_grad</span></code>(grads, data, kernel, stride, ...)</p></td>
<td><p>Gradient of pooling on height and width dimension of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">prelu</span></code>(x, slope[, axis])</p></td>
<td><p>PReLU.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">relu</span></code>(x)</p></td>
<td><p>Take relu of input x.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale_shift_nchw</span></code>(Input, Scale, Shift)</p></td>
<td><p>Batch normalization operator in inference.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale_shift_nhwc</span></code>(Input, Scale, Shift)</p></td>
<td><p>Batch normalization operator in inference.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">simplify</span></code>(expr)</p></td>
<td><p>Simplify the expression if it is Expr, directly return if it is int.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">softmax</span></code>(x[, axis])</p></td>
<td><p>Perform softmax activation on the data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">softmax_common</span></code>(x, axis, use_fast_exp)</p></td>
<td><p>The common part of softmax and fast_softmax</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">space_to_batch_nd</span></code>(data, block_shape, ...[, ...])</p></td>
<td><p>Perform batch to space transformation on the data</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">space_to_depth</span></code>(data, block_size[, layout])</p></td>
<td><p>Perform space to depth transformation on the data</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse_dense</span></code>(dense_data, sparse_data, ...[, ...])</p></td>
<td><p>Computes sparse-dense matrix multiplication of <cite>data</cite> and <cite>(weight_data, weight_indices, weight_indptr).T</cite>, if sparse_lhs=False or Computes sparse-dense matrix multiplication of <cite>(data_data, data_indices, data_indptr)</cite> and <cite>weight.T</cite>, if sparse_lhs=True</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse_dense_alter_layout</span></code>(_attrs, _inputs, ...)</p></td>
<td><p>Change Sparse Dense layout.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse_dense_v1</span></code>(data_data, data_indices, ...)</p></td>
<td><p>Computes sparse-dense matrix multiplication of <cite>(data_data, data_indices, data_indptr)</cite> and <cite>weight.T</cite></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse_dense_v2</span></code>(data, weight_data, ...)</p></td>
<td><p>Computes sparse-dense matrix multiplication of <cite>data</cite> and <cite>(weight_data, weight_indices, weight_indptr).T</cite></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse_transpose</span></code>(sparse_data, ...)</p></td>
<td><p>Transpose a square sparse matrix, <cite>A</cite> is an n-by-n sparse matrix in the CSR format.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">strided_slice</span></code>(a, begin, end[, strides, ...])</p></td>
<td><p>Slice of an array.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">unpack_NCHWc_to_nchw</span></code>(packed_out, out_dtype)</p></td>
<td><p>Unpack conv2d_NCHWc output from layout NCHWc to NCHW</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">upsampling</span></code>(data, scale_h, scale_w[, layout, ...])</p></td>
<td><p>Perform upsampling on the data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">upsampling3d</span></code>(data, scale_d, scale_h, scale_w)</p></td>
<td><p>Perform upsampling on the data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">winograd_transform_matrices</span></code>(tile_size, ...)</p></td>
<td><p>Compute the A, B, and G transform matrices for <cite>tile_size</cite> as a <cite>tvm.Expr</cite>.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt id="tvm.topi.nn.Workload">
<em class="property">class </em><code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">Workload</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">in_dtype</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em>, <em class="sig-param"><span class="n">height</span></em>, <em class="sig-param"><span class="n">width</span></em>, <em class="sig-param"><span class="n">in_filter</span></em>, <em class="sig-param"><span class="n">out_filter</span></em>, <em class="sig-param"><span class="n">kernel_h</span></em>, <em class="sig-param"><span class="n">kernel_w</span></em>, <em class="sig-param"><span class="n">padt</span></em>, <em class="sig-param"><span class="n">padl</span></em>, <em class="sig-param"><span class="n">padb</span></em>, <em class="sig-param"><span class="n">padr</span></em>, <em class="sig-param"><span class="n">dilation_h</span></em>, <em class="sig-param"><span class="n">dilation_w</span></em>, <em class="sig-param"><span class="n">stride_h</span></em>, <em class="sig-param"><span class="n">stride_w</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.Workload" title="Permalink to this definition">¶</a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dilation_h</span></code></p></td>
<td><p>Alias for field number 12</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dilation_w</span></code></p></td>
<td><p>Alias for field number 13</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">height</span></code></p></td>
<td><p>Alias for field number 2</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">in_dtype</span></code></p></td>
<td><p>Alias for field number 0</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">in_filter</span></code></p></td>
<td><p>Alias for field number 4</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">kernel_h</span></code></p></td>
<td><p>Alias for field number 6</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">kernel_w</span></code></p></td>
<td><p>Alias for field number 7</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">out_dtype</span></code></p></td>
<td><p>Alias for field number 1</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">out_filter</span></code></p></td>
<td><p>Alias for field number 5</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">padb</span></code></p></td>
<td><p>Alias for field number 10</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">padl</span></code></p></td>
<td><p>Alias for field number 9</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">padr</span></code></p></td>
<td><p>Alias for field number 11</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">padt</span></code></p></td>
<td><p>Alias for field number 8</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">stride_h</span></code></p></td>
<td><p>Alias for field number 14</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">stride_w</span></code></p></td>
<td><p>Alias for field number 15</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">width</span></code></p></td>
<td><p>Alias for field number 3</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="tvm.topi.nn.Workload.dilation_h">
<em class="property">property </em><code class="sig-name descname">dilation_h</code><a class="headerlink" href="#tvm.topi.nn.Workload.dilation_h" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 12</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.dilation_w">
<em class="property">property </em><code class="sig-name descname">dilation_w</code><a class="headerlink" href="#tvm.topi.nn.Workload.dilation_w" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 13</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.height">
<em class="property">property </em><code class="sig-name descname">height</code><a class="headerlink" href="#tvm.topi.nn.Workload.height" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.in_dtype">
<em class="property">property </em><code class="sig-name descname">in_dtype</code><a class="headerlink" href="#tvm.topi.nn.Workload.in_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.in_filter">
<em class="property">property </em><code class="sig-name descname">in_filter</code><a class="headerlink" href="#tvm.topi.nn.Workload.in_filter" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.kernel_h">
<em class="property">property </em><code class="sig-name descname">kernel_h</code><a class="headerlink" href="#tvm.topi.nn.Workload.kernel_h" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.kernel_w">
<em class="property">property </em><code class="sig-name descname">kernel_w</code><a class="headerlink" href="#tvm.topi.nn.Workload.kernel_w" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.out_dtype">
<em class="property">property </em><code class="sig-name descname">out_dtype</code><a class="headerlink" href="#tvm.topi.nn.Workload.out_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.out_filter">
<em class="property">property </em><code class="sig-name descname">out_filter</code><a class="headerlink" href="#tvm.topi.nn.Workload.out_filter" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.padb">
<em class="property">property </em><code class="sig-name descname">padb</code><a class="headerlink" href="#tvm.topi.nn.Workload.padb" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 10</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.padl">
<em class="property">property </em><code class="sig-name descname">padl</code><a class="headerlink" href="#tvm.topi.nn.Workload.padl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 9</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.padr">
<em class="property">property </em><code class="sig-name descname">padr</code><a class="headerlink" href="#tvm.topi.nn.Workload.padr" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 11</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.padt">
<em class="property">property </em><code class="sig-name descname">padt</code><a class="headerlink" href="#tvm.topi.nn.Workload.padt" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.stride_h">
<em class="property">property </em><code class="sig-name descname">stride_h</code><a class="headerlink" href="#tvm.topi.nn.Workload.stride_h" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 14</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.stride_w">
<em class="property">property </em><code class="sig-name descname">stride_w</code><a class="headerlink" href="#tvm.topi.nn.Workload.stride_w" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 15</p>
</dd></dl>

<dl class="py method">
<dt id="tvm.topi.nn.Workload.width">
<em class="property">property </em><code class="sig-name descname">width</code><a class="headerlink" href="#tvm.topi.nn.Workload.width" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.adaptive_pool">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">adaptive_pool</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">output_size</span></em>, <em class="sig-param"><span class="n">pool_type</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.adaptive_pool" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Perform pooling on height and width dimension of data.</dt><dd><p>The pooling kernel and stride sizes are automatically chosen for desired
output sizes.
It decides the height and width dimension according to the layout string,
in which 'W' and 'H' means width and height respectively.
Width and height dimension cannot be split.
For example, NCHW, NCHW16c, etc. are valid for pool,
while NCHW16w, NCHW16h are not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D with shape of layout</p></li>
<li><p><strong>output_size</strong> (<em>tuple of int</em>) -- output height and width.</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Pool type, 'max' or 'avg'</p></li>
<li><p><strong>layout</strong> (<em>string</em>) -- Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCHW16c can describe a 5-D tensor of
[batch_size, channel, height, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- n-D in the same layout</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.adaptive_pool3d">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">adaptive_pool3d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">output_size</span></em>, <em class="sig-param"><span class="n">pool_type</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCDHW'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.adaptive_pool3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform pooling on three dimensional data.
See the two dimensional version above for details.</p>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.batch_matmul">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">batch_matmul</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">oshape</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">auto_scheduler_rewritten_layout</span><span class="o">=</span><span class="default_value">''</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.batch_matmul" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes batch matrix multiplication of <cite>x</cite> and <cite>y</cite> when <cite>x</cite> and <cite>y</cite> are
data in batch. Supports broadcasting for batch dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D with shape [batch, M, K]</p></li>
<li><p><strong>y</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D with shape [batch, N, K]</p></li>
<li><p><strong>oshape</strong> (<a class="reference internal" href="relay/dataflow_pattern.html#tvm.relay.dataflow_pattern.List" title="tvm.relay.dataflow_pattern.List"><em>List</em></a><em>[</em><em>Optional</em><em>]</em>) -- Explicit intended output shape of the computation. Can be useful in cases
with dynamic input shapes.</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) -- The layout after auto-scheduler's layout rewrite pass.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 3-D with shape [batch, M, N]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.batch_to_space_nd">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">batch_to_space_nd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">block_shape</span></em>, <em class="sig-param"><span class="n">crop_begin_list</span></em>, <em class="sig-param"><span class="n">crop_end_list</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.batch_to_space_nd" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform space to batch transformation on the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- N-D Tensor with shape [batch, spatial_shape, remaining_shapes],
where spatial_shape has M dimensions.</p></li>
<li><p><strong>block_size</strong> (<em>list of ints</em>) -- list of size [M] where M is number of spatial dims, specifies block
size for each spatial dimension.</p></li>
<li><p><strong>crop_begin_list</strong> (<em>list of ints</em>) -- list of shape [M] where M is number of spatial dims, specifies
begin crop size for each spatial dimension.</p></li>
<li><p><strong>crop_end_list</strong> (<em>list of ints</em>) -- list of shape [M] where M is number of spatial dims, specifies
end crop size for each spatial dimension.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.binarize_pack">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">binarize_pack</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">'PackedInput'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.binarize_pack" title="Permalink to this definition">¶</a></dt>
<dd><p>Binarization and bit-packing along a certain axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D input, can be any layout.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- The axis along which to do binarization and bit-packing,
default is the last axis.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The name prefix operators generate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- n-D, the same layout as input, dtype is uint32.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.binary_dense">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">binary_dense</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">weight</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.binary_dense" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary matrix multiplication using xor and bit-count.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D with shape [batch, in_dim], dtype is uint32.</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D with shape [out_dim, in_dim], dtype is uint32.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D with shape [batch, out_dim], dtype is float32.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.bitpack">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">bitpack</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">bits</span></em>, <em class="sig-param"><span class="n">pack_axis</span></em>, <em class="sig-param"><span class="n">bit_axis</span></em>, <em class="sig-param"><span class="n">pack_type</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">'QuantizeInput'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.bitpack" title="Permalink to this definition">¶</a></dt>
<dd><p>Packs data into format necessary for bitserial computation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pack_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- index of the axis to pack in data</p></li>
<li><p><strong>bit_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- index of axis to place bit axis in resulting packed data</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.bitserial_conv2d_legalize">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">bitserial_conv2d_legalize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">attrs</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">types</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.bitserial_conv2d_legalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Legalizes Bitserial Conv2D op.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attrs</strong> (<a class="reference internal" href="ir.html#tvm.ir.Attrs" title="tvm.ir.Attrs"><em>tvm.ir.Attrs</em></a>) -- Attributes of current convolution</p></li>
<li><p><strong>inputs</strong> (<em>list of tvm.relay.Expr</em>) -- The args of the Relay expr to be legalized</p></li>
<li><p><strong>types</strong> (<em>list of types</em>) -- List of input and output types</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- The legalized expr</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tvm.relay.Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.bitserial_conv2d_nchw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">bitserial_conv2d_nchw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">activation_bits</span></em>, <em class="sig-param"><span class="n">weight_bits</span></em>, <em class="sig-param"><span class="n">pack_dtype</span><span class="o">=</span><span class="default_value">'uint32'</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">'int16'</span></em>, <em class="sig-param"><span class="n">unipolar</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.bitserial_conv2d_nchw" title="Permalink to this definition">¶</a></dt>
<dd><p>Bitserial Conv2D operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [num_filter, in_channel, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two</em><em> or </em><em>four ints</em>) -- padding size, [pad_height, pad_width], [pad_top, pad_left, pad_down, pad_right]</p></li>
<li><p><strong>activation_bits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- number of bits used for activations/input elements</p></li>
<li><p><strong>weight_bits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- number of bits used for weight elements</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- return type of convolution</p></li>
<li><p><strong>pack_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- bit packing type</p></li>
<li><p><strong>unipolar</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- if binarization style is in unipolar 1/0 format, instead of bipolar -1/+1 format</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.bitserial_conv2d_nhwc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">bitserial_conv2d_nhwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">activation_bits</span></em>, <em class="sig-param"><span class="n">weight_bits</span></em>, <em class="sig-param"><span class="n">pack_dtype</span><span class="o">=</span><span class="default_value">'uint32'</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">'int16'</span></em>, <em class="sig-param"><span class="n">unipolar</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.bitserial_conv2d_nhwc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bitserial Conv2D operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two</em><em> or </em><em>four ints</em>) -- padding size, [pad_height, pad_width], [pad_top, pad_left, pad_down, pad_right]</p></li>
<li><p><strong>activation_bits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- number of bits used for activations/input elements</p></li>
<li><p><strong>weight_bits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- number of bits used for weight elements</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- return type of convolution</p></li>
<li><p><strong>pack_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- bit packing type</p></li>
<li><p><strong>unipolar</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- if binarization style is in unipolar 1/0 format, instead of bipolar -1/+1 format</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.bitserial_dense">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">bitserial_dense</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">weight</span></em>, <em class="sig-param"><span class="n">data_bits</span></em>, <em class="sig-param"><span class="n">weight_bits</span></em>, <em class="sig-param"><span class="n">pack_dtype</span><span class="o">=</span><span class="default_value">'uint32'</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">'int16'</span></em>, <em class="sig-param"><span class="n">unipolar</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.bitserial_dense" title="Permalink to this definition">¶</a></dt>
<dd><p>The default implementation of bitserial dense in topi.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D with shape [batch, in_dim]</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D with shape [out_dim, in_dim] or
3-D with shape [out_dim, weight_bits, in_dim]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D with shape [batch, out_dim]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.concatenate">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">concatenate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a_tuple</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.concatenate" title="Permalink to this definition">¶</a></dt>
<dd><p>Join a sequence of arrays along an existing axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_tuple</strong> (<em>tuple of tvm.te.Tensor</em>) -- The arrays to concatenate</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) -- The axis along which the arrays will be joined. Default is 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv1d">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">strides</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">padding</span><span class="o">=</span><span class="default_value">'VALID'</span></em>, <em class="sig-param"><span class="n">dilation</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCW'</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>1D convolution forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D input shape [batch, in_channel, in_width] for layout == 'NCW'
and [batch, in_width, in_channel] for layout == 'NWC'</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D kernel with shape [num_filter, in_channel, filter_size] for layout == 'NCW'
and [filter_size, in_channel, num_filter] for layout == 'NWC'</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- The spatial stride along width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- Dilation rate if convolution should be dilated.</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- How input data is laid out, must be one of ['NCW', 'NWC']</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The output data type. If None then output is same type as input.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv1d_ncw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv1d_ncw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">strides</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">padding</span><span class="o">=</span><span class="default_value">'VALID'</span></em>, <em class="sig-param"><span class="n">dilation</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv1d_ncw" title="Permalink to this definition">¶</a></dt>
<dd><p>1D convolution forward operator for NCW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D with shape [batch, in_channel, in_width]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D with shape [num_filter, in_channel, filter_size]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- The spatial stride along width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em>, or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size can be an integer for equal padding,
a tuple of (left, right) or a string in ['VALID', 'SAME'].</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- Dilation rate if convolution should be dilated.</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The output data type. If None then output is same type as input.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv1d_nwc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv1d_nwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">strides</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">padding</span><span class="o">=</span><span class="default_value">'VALID'</span></em>, <em class="sig-param"><span class="n">dilation</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv1d_nwc" title="Permalink to this definition">¶</a></dt>
<dd><p>1D convolution forward operator for NWC layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D with shape [batch, in_width, in_channel]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D with shape [filter_size, in_channel, num_filter]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- The spatial stride along width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em>, or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size can be an integer for equal padding,
a tuple of (left, right) or a string in ['VALID', 'SAME'].</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- Dilation rate if convolution should be dilated.</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The output data type. If None then output is same type as input.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv1d_transpose_ncw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv1d_transpose_ncw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em>, <em class="sig-param"><span class="n">output_padding</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv1d_transpose_ncw" title="Permalink to this definition">¶</a></dt>
<dd><p>Transposed 1D convolution ncw forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D with shape [batch, in_channel, in_width]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D with shape [in_channel, num_filter, filter_width]</p></li>
<li><p><strong>stride</strong> (<em>ints</em>) -- The spatial stride along width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The output data type. This is used for mixed precision.</p></li>
<li><p><strong>output_padding</strong> (<em>ints</em>) -- Used to recover the actual output shape in case there are more
than one possible shape.  Must be smaller than stride.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 3-D with shape [batch, out_channel, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">filter</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Conv2D operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [num_filter, in_channel, filter_height, filter_width]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of 2</em><em> or </em><em>4 ints</em>) -- padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- layout of data</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_NCHWc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_NCHWc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">layout</span></em>, <em class="sig-param"><span class="n">out_layout</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">'float32'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_NCHWc" title="Permalink to this definition">¶</a></dt>
<dd><p>Conv2D operator for nChw[x]c layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 5-D with shape [batch, in_channel_chunk, in_height, in_width, in_channel_block]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 6-D with shape
[num_filter_chunk, in_channel_chunk, filter_height, filter_width,
in_channel_block, num_filter_block]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of 2</em><em> or </em><em>4 ints</em>) -- padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Input data layout</p></li>
<li><p><strong>out_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Output data layout</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- output data type</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 5-D with shape [batch, out_channel_chunk, out_height, out_width, out_channel_block]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_NCHWc_int8">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_NCHWc_int8</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">layout</span></em>, <em class="sig-param"><span class="n">out_layout</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">'int32'</span></em>, <em class="sig-param"><span class="n">n_elems</span><span class="o">=</span><span class="default_value">4</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_NCHWc_int8" title="Permalink to this definition">¶</a></dt>
<dd><p>Conv2D operator for nChw[x]c layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 5-D with shape [batch, in_channel_chunk, in_height, in_width, in_channel_block]</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 7-D with shape
[num_filter_chunk, in_channel_chunk, filter_height, filter_width, in_channel_block/4,
num_filter_block, 4]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of 2</em><em> or </em><em>4 ints</em>) -- padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Input data layout</p></li>
<li><p><strong>out_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Output data layout</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- output data type</p></li>
<li><p><strong>n_elems</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- numer of int8 elements accumulated</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 5-D with shape [batch, out_channel_chunk, out_height, out_width, out_channel_block]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_alter_layout">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_alter_layout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">attrs</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">tinfos</span></em>, <em class="sig-param"><span class="n">out_type</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_alter_layout" title="Permalink to this definition">¶</a></dt>
<dd><p>Change Conv2D layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attrs</strong> (<a class="reference internal" href="ir.html#tvm.ir.Attrs" title="tvm.ir.Attrs"><em>tvm.ir.Attrs</em></a>) -- Attributes of current convolution</p></li>
<li><p><strong>inputs</strong> (<em>tvm.relay.Expr</em>) -- Grouped input symbols</p></li>
<li><p><strong>tinfos</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) -- Input shape and dtype</p></li>
<li><p><strong>out_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.9)"><em>type</em></a>) -- The output type</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Unlike other TOPI functions, this function operates on both graph level and operator level.</p>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_gemm_weight_transform">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_gemm_weight_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">tile_rows</span></em>, <em class="sig-param"><span class="n">tile_cols</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_gemm_weight_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Weight transformation for winograd</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>Tensor</em></a>) -- The raw kernel tensor with layout &quot;NHWC&quot;.</p></li>
<li><p><strong>tile_rows</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Tile rows of the weight transformation for ConvGemm.</p></li>
<li><p><strong>tile_cols</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Tile columns of the weight transformation for ConvGemm.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D with shape [CI*KH*KW,CO]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_hwcn">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_hwcn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_hwcn" title="Permalink to this definition">¶</a></dt>
<dd><p>Convolution operator in HWCN layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [in_height, in_width, in_channel, batch]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of 2</em><em> or </em><em>4 ints</em>) -- padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [out_height, out_width, out_channel, batch]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_infer_layout">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_infer_layout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">workload</span></em>, <em class="sig-param"><span class="n">cfg</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_infer_layout" title="Permalink to this definition">¶</a></dt>
<dd><p>Infer input/output shapes and layouts from a workload and cfg.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>workload</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- conv2d workload</p></li>
<li><p><strong>cfg</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- tvm.autotvm config</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- Input shapes and layouts, and output shapes and layouts</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>[tuple of tuple and str, tuple of tuple and str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_legalize">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_legalize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">attrs</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">types</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_legalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Legalizes Conv2D op.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attrs</strong> (<a class="reference internal" href="ir.html#tvm.ir.Attrs" title="tvm.ir.Attrs"><em>tvm.ir.Attrs</em></a>) -- Attributes of current convolution</p></li>
<li><p><strong>inputs</strong> (<em>list of tvm.relay.Expr</em>) -- The args of the Relay expr to be legalized</p></li>
<li><p><strong>types</strong> (<em>list of types</em>) -- List of input and output types</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- The legalized expr</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tvm.relay.Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_nchw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_nchw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_nchw" title="Permalink to this definition">¶</a></dt>
<dd><p>Convolution operator in NCHW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [num_filter, in_channel, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of 2</em><em> or </em><em>4 ints</em>) -- padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_nhwc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_nhwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">'float32'</span></em>, <em class="sig-param"><span class="n">auto_scheduler_rewritten_layout</span><span class="o">=</span><span class="default_value">''</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_nhwc" title="Permalink to this definition">¶</a></dt>
<dd><p>Convolution operator in NHWC layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of 2</em><em> or </em><em>4 ints</em>) -- padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<em>str = &quot;float32&quot;</em><em>,</em>) -- The type of output tensor</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) -- The layout after auto-scheduler's layout rewrite pass.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_transpose_legalize">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_transpose_legalize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">attrs</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">types</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_transpose_legalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Legalizes Transposed 2D convolution op.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attrs</strong> (<a class="reference internal" href="ir.html#tvm.ir.Attrs" title="tvm.ir.Attrs"><em>tvm.ir.Attrs</em></a>) -- Attributes of current Transposed 2D convolution</p></li>
<li><p><strong>inputs</strong> (<em>list of tvm.relay.Expr</em>) -- The args of the Relay expr to be legalized</p></li>
<li><p><strong>types</strong> (<em>list of types</em>) -- List of input and output types</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- The legalized expr</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tvm.relay.Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_transpose_nchw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_transpose_nchw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em>, <em class="sig-param"><span class="n">output_padding</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_transpose_nchw" title="Permalink to this definition">¶</a></dt>
<dd><p>Transposed 2D convolution nchw forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [in_channel, num_filter, filter_height, filter_width]</p></li>
<li><p><strong>strides</strong> (<em>tuple of two ints</em>) -- The spatial stride along height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The output data type. This is used for mixed precision.</p></li>
<li><p><strong>output_padding</strong> (<em>tuple of ints</em>) -- Used to get the right output shape for gradients</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_transpose_nchw_preprocess">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_transpose_nchw_preprocess</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em>, <em class="sig-param"><span class="n">output_padding</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_transpose_nchw_preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>Preprocess data and kernel to make the compute pattern
of conv2d_transpose the same as conv2d</p>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_winograd_nhwc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_winograd_nhwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">weight</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em>, <em class="sig-param"><span class="n">pre_computed</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">auto_scheduler_rewritten_layout</span><span class="o">=</span><span class="default_value">''</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_winograd_nhwc" title="Permalink to this definition">¶</a></dt>
<dd><p>Conv2D Winograd in NHWC layout.
This is a clean version to be used by the auto-scheduler for both CPU and GPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>tvm.Tensor</em>) -- 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>weight</strong> (<em>tvm.Tensor</em>) -- 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- padding size, or [pad_height, pad_width]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- Specifies the output data type.</p></li>
<li><p><strong>pre_computed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- Whether the kernel is precomputed</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) -- The layout after auto-scheduler's layout rewrite pass.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tvm.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_winograd_nhwc_without_weight_transform">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_winograd_nhwc_without_weight_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">weight</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em>, <em class="sig-param"><span class="n">auto_scheduler_rewritten_layout</span><span class="o">=</span><span class="default_value">''</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_winograd_nhwc_without_weight_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Conv2D Winograd without layout transform in NHWC layout.
This is a clean version to be used by the auto-scheduler for both CPU and GPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>tvm.Tensor</em>) -- 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>weight</strong> (<em>tvm.Tensor</em>) -- 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- padding size, or [pad_height, pad_width]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- Specifies the output data type.</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) -- The layout after auto-scheduler's layout rewrite pass.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tvm.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_winograd_nnpack_weight_transform">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_winograd_nnpack_weight_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">convolution_algorithm</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_winograd_nnpack_weight_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Weight transformation for winograd</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>Tensor</em></a>) -- The raw kernel tensor with layout &quot;NCHW&quot;. Only 3x3 kernel is supported for now.</p></li>
<li><p><strong>convolution_algorithm</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- The convolution algorithm for Winograd NNPACK.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [alpha, alpha, CO, CI]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv2d_winograd_weight_transform">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv2d_winograd_weight_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">tile_size</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv2d_winograd_weight_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Weight transformation for winograd</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>Tensor</em></a>) -- The raw kernel tensor with layout &quot;NCHW&quot;.</p></li>
<li><p><strong>tile_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Tile size of winograd transform. e.g. 2 for F(2x2, 3x3) and 4 for F(4x4, 3x3)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [alpha, alpha, CO, CI]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv3d_alter_layout">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv3d_alter_layout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">attrs</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">tinfos</span></em>, <em class="sig-param"><span class="n">out_type</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_alter_layout" title="Permalink to this definition">¶</a></dt>
<dd><p>Change Conv3D layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attrs</strong> (<a class="reference internal" href="ir.html#tvm.ir.Attrs" title="tvm.ir.Attrs"><em>tvm.ir.Attrs</em></a>) -- Attributes of current convolution</p></li>
<li><p><strong>inputs</strong> (<em>tvm.relay.Expr</em>) -- Grouped input symbols</p></li>
<li><p><strong>tinfos</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) -- Input shape and dtype</p></li>
<li><p><strong>out_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.9)"><em>type</em></a>) -- The output type</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Unlike other TOPI functions, this function operates on both graph level and operator level.</p>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv3d_ncdhw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv3d_ncdhw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_ncdhw" title="Permalink to this definition">¶</a></dt>
<dd><p>Conv3D operator in NCDHW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 5-D with shape [batch, in_channel, in_depth, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 5-D with shape [num_filter, in_channel, filter_depth, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of three ints</em>) -- Stride size, or [strid_depth, stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of three ints</em>) -- dilation size, or [dilation_depth, dilation_height, dilation_width]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 5-D with shape [batch, out_channel, out_depth, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv3d_ndhwc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv3d_ndhwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">'float32'</span></em>, <em class="sig-param"><span class="n">auto_scheduler_rewritten_layout</span><span class="o">=</span><span class="default_value">''</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_ndhwc" title="Permalink to this definition">¶</a></dt>
<dd><p>Convolution operator in NDHWC layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 5-D with shape [batch, in_depth, in_height, in_width, in_channel]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 5-D with shape [filter_depth, filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of three ints</em>) -- Stride size, or [stride_depth, stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of three ints</em>) -- dilation size, or [dilation_depth, dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<em>str = &quot;float32&quot;</em><em>,</em>) -- The type of output tensor</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) -- The layout after auto-scheduler's layout rewrite pass.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 5-D with shape [batch, out_depth, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv3d_transpose_legalize">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv3d_transpose_legalize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">attrs</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">types</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_transpose_legalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Legalizes Transposed 3D convolution op.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attrs</strong> (<a class="reference internal" href="ir.html#tvm.ir.Attrs" title="tvm.ir.Attrs"><em>tvm.ir.Attrs</em></a>) -- Attributes of current Transposed 3D convolution</p></li>
<li><p><strong>inputs</strong> (<em>list of tvm.relay.Expr</em>) -- The args of the Relay expr to be legalized</p></li>
<li><p><strong>types</strong> (<em>list of types</em>) -- List of input and output types</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- The legalized expr</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tvm.relay.Expr</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv3d_transpose_ncdhw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv3d_transpose_ncdhw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em>, <em class="sig-param"><span class="n">output_padding</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_transpose_ncdhw" title="Permalink to this definition">¶</a></dt>
<dd><p>Transposed 3D convolution ncdhw forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 5-D with shape [batch, in_channel, in_depth, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 5-D with shape [in_channel, num_filter, filter_depth, filter_height, filter_width]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of three ints</em>) -- The spatial stride along depth,height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The output data type. This is used for mixed precision.</p></li>
<li><p><strong>output_padding</strong> (<em>tuple of ints</em>) -- Used to get the right output shape for gradients</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 5-D with shape [batch, out_channel, out_depth, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv3d_transpose_ncdhw_preprocess">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv3d_transpose_ncdhw_preprocess</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em>, <em class="sig-param"><span class="n">output_padding</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_transpose_ncdhw_preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>Preprocess data and kernel to make the compute pattern
of conv3d_transpose the same as conv3d</p>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.conv3d_winograd_weight_transform">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">conv3d_winograd_weight_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">tile_size</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.conv3d_winograd_weight_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Weight transformation for 3D winograd</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>Tensor</em></a>) -- The raw kernel tensor with layout &quot;NCDHW&quot;.</p></li>
<li><p><strong>tile_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Tile size of winograd transform. e.g. 2 for F(2x2, 3x3) and 4 for F(4x4, 3x3)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 5-D with shape [alpha, alpha, alpha, CO, CI]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.correlation_nchw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">correlation_nchw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data1</span></em>, <em class="sig-param"><span class="n">data2</span></em>, <em class="sig-param"><span class="n">kernel_size</span></em>, <em class="sig-param"><span class="n">max_displacement</span></em>, <em class="sig-param"><span class="n">stride1</span></em>, <em class="sig-param"><span class="n">stride2</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">is_multiply</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.correlation_nchw" title="Permalink to this definition">¶</a></dt>
<dd><p>Correlation operator in NCHW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data1</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, channel, height, width]</p></li>
<li><p><strong>data2</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, channel, height, width]</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Kernel size for correlation, must be an odd number</p></li>
<li><p><strong>max_displacement</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Max displacement of Correlation</p></li>
<li><p><strong>stride1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Stride for data1</p></li>
<li><p><strong>stride2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Stride for data2 within the neightborhood centered around data1</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of 2</em><em> or </em><em>4 ints</em>) -- Padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>is_multiply</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- operation type is either multiplication or substraction</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.declaration_conv2d_transpose_impl">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">declaration_conv2d_transpose_impl</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em>, <em class="sig-param"><span class="n">output_padding</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.declaration_conv2d_transpose_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of conv2d transpose</p>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.declaration_conv3d_transpose_impl">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">declaration_conv3d_transpose_impl</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em>, <em class="sig-param"><span class="n">output_padding</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.declaration_conv3d_transpose_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of conv3d transpose</p>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.deformable_conv2d_nchw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">deformable_conv2d_nchw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">offset</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">deformable_groups</span></em>, <em class="sig-param"><span class="n">groups</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.deformable_conv2d_nchw" title="Permalink to this definition">¶</a></dt>
<dd><p>Deformable conv2D operator in NCHW layout.</p>
<p>The deformable convolution operation is described in <a class="reference external" href="https://arxiv.org/abs/1703.06211">https://arxiv.org/abs/1703.06211</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>offset</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, deformable_groups * filter_height * filter_width * 2,
out_height, out_width].</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [num_filter, in_channel, filter_height, filter_width]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- padding size, or [pad_height, pad_width]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>deformable_groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- number of deformable groups</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- number of groups</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.deformable_conv2d_nhwc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">deformable_conv2d_nhwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">offset</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">deformable_groups</span></em>, <em class="sig-param"><span class="n">groups</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.deformable_conv2d_nhwc" title="Permalink to this definition">¶</a></dt>
<dd><p>Deformable conv2D operator in NHWC layout.</p>
<p>The deformable convolution operation is described in <a class="reference external" href="https://arxiv.org/abs/1703.06211">https://arxiv.org/abs/1703.06211</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>offset</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- <dl class="simple">
<dt>4-D with shape [batch, out_height, out_width,</dt><dd><p>deformable_groups * filter_height * filter_width * 2].</p>
</dd>
</dl>
</p></li>
<li><p><strong>kernel</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [filter_height, filter_width, in_channel, num_filter]</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- padding size, or [pad_height, pad_width]</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>deformable_groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- number of deformable groups</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- number of groups</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.dense">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">dense</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">weight</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">auto_scheduler_rewritten_layout</span><span class="o">=</span><span class="default_value">''</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.dense" title="Permalink to this definition">¶</a></dt>
<dd><p>The default implementation of dense in topi.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D with shape [batch, in_dim]</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D with shape [out_dim, in_dim]</p></li>
<li><p><strong>bias</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>]</em>) -- 1-D with shape [out_dim]</p></li>
<li><p><strong>out_dtype</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>]</em>) -- The output type. This is used for mixed precision.</p></li>
<li><p><strong>auto_scheduler_rewritten_layout</strong> (<em>str = &quot;&quot;</em>) -- The layout after auto-scheduler's layout rewrite pass.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D with shape [batch, out_dim]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.depth_to_space">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">depth_to_space</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">block_size</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em>, <em class="sig-param"><span class="n">mode</span><span class="o">=</span><span class="default_value">'DCR'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depth_to_space" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform depth to space transformation on the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D tensor in either NCHW or NHWC layout.</p></li>
<li><p><strong>block_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Size of blocks to compose from channel dimension.</p></li>
<li><p><strong>layout</strong> (<em>string</em>) -- Either NCHW or NHWC, indicating data layout.</p></li>
<li><p><strong>mode</strong> (<em>string</em>) -- Either DCR or CDR, indicates how channels should be accessed.
In DCR, channels are interwoven in the Tensorflow style while
in CDR channels are accessed sequentially as in Pytorch.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- Output of shape [N, C / block_size**2, H * block_size, W * block_size]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.depthwise_conv2d_NCHWc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">depthwise_conv2d_NCHWc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">layout</span></em>, <em class="sig-param"><span class="n">out_layout</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depthwise_conv2d_NCHWc" title="Permalink to this definition">¶</a></dt>
<dd><p>Depthwise convolution NCHW[x]c forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 5-D with shape [batch, in_channel_chunk, in_height, in_width, in_channel_block]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 6-D with shape [out_channel_chunk, 1, filter_height, filter_width, 1, out_channel_block]
In NCHWc depthwise convolution,
we group kernel's in_channel and channel_multiplier together then do the tiling.</p></li>
<li><p><strong>stride</strong> (<em>tuple of two ints</em>) -- The spatial stride along height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Input data layout</p></li>
<li><p><strong>out_layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Output data layout</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- Output data type</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 5-D with shape [batch, out_channel_chunk, out_height, out_width, out_channel_block]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.depthwise_conv2d_backward_input_nhwc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">depthwise_conv2d_backward_input_nhwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">Out_grad</span></em>, <em class="sig-param"><span class="n">oshape</span></em>, <em class="sig-param"><span class="n">ishape</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depthwise_conv2d_backward_input_nhwc" title="Permalink to this definition">¶</a></dt>
<dd><p>Depthwise convolution nhwc backward wrt input operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [filter_height, filter_width, in_channel, channel_multiplier]</p></li>
<li><p><strong>Out_grad</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, out_height, out_width, out_channel]</p></li>
<li><p><strong>stride</strong> (<em>tuple of two ints</em>) -- The spatial stride along height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, in_height, in_width, in_channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.depthwise_conv2d_backward_weight_nhwc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">depthwise_conv2d_backward_weight_nhwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Out_grad</span></em>, <em class="sig-param"><span class="n">oshape</span></em>, <em class="sig-param"><span class="n">fshape</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depthwise_conv2d_backward_weight_nhwc" title="Permalink to this definition">¶</a></dt>
<dd><p>Depthwise convolution nhwc backward wrt weight operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>Out_grad</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, out_height, out_width, out_channel]</p></li>
<li><p><strong>stride</strong> (<em>tuple of two ints</em>) -- The spatial stride along height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [filter_height, filter_width, in_channel, channel_multiplier]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.depthwise_conv2d_infer_layout">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">depthwise_conv2d_infer_layout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">workload</span></em>, <em class="sig-param"><span class="n">cfg</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depthwise_conv2d_infer_layout" title="Permalink to this definition">¶</a></dt>
<dd><p>Infer input/output shapes and layouts from a workload and cfg.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>workload</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- conv2d workload</p></li>
<li><p><strong>cfg</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- tvm.autotvm config</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- Input shapes and layouts, and output shapes and layouts</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>[tuple of tuple and str, tuple of tuple and str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.depthwise_conv2d_nchw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">depthwise_conv2d_nchw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depthwise_conv2d_nchw" title="Permalink to this definition">¶</a></dt>
<dd><p>Depthwise convolution nchw forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [in_channel, channel_multiplier, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<em>tuple of two ints</em>) -- The spatial stride along height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- Output data type</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.depthwise_conv2d_nhwc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">depthwise_conv2d_nhwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.depthwise_conv2d_nhwc" title="Permalink to this definition">¶</a></dt>
<dd><p>Depthwise convolution nhwc forward operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [filter_height, filter_width, in_channel, channel_multiplier]</p></li>
<li><p><strong>stride</strong> (<em>tuple of two ints</em>) -- The spatial stride along height and width</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- Output data type</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.dilate">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">dilate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">dilation_value</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">'DilatedInput'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.dilate" title="Permalink to this definition">¶</a></dt>
<dd><p>Dilate data with given dilation value (0 by default).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D, can be any layout.</p></li>
<li><p><strong>strides</strong> (<em>list / tuple of n ints</em>) -- Dilation stride on each dimension, 1 means no dilation.</p></li>
<li><p><strong>dilation_value</strong> (<em>int/float</em><em>, </em><em>optional</em>) -- Value used to dilate the input.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The name prefix operators generated</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- n-D, the same layout as data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.equal_const_int">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">equal_const_int</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">expr</span></em>, <em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.equal_const_int" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns if expr equals value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>expr</strong> (<em>tvm.Expr</em>) -- The input expression.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>equal</strong> -- Whether they equals.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.fast_softmax">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">fast_softmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">- 1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.fast_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform softmax activation on the data.
Use approximation to compute exponent for faster speed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- can be any dimension</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- channel axis</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- output shape is the same as input</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.fifo_buffer">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">fifo_buffer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">buffer</span></em>, <em class="sig-param"><span class="n">axis</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.fifo_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>FIFO buffer to enable computation reuse in CNNs with sliding indow input</p>
<p>Compute equivalent of</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">concat</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
<span class="o">.</span><span class="n">slice_axis</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
            <span class="n">begin</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">],</span>
            <span class="n">end</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="o">+</span><span class="n">buffer</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">])</span>
</pre></div>
</div>
<p>Useful for</p>
<ul class="simple">
<li><p>Encoding explicit re-use of computation in convolution ops operated on a sliding window input</p></li>
<li><p>Implementing a FIFO queue to cache intermediate results, e.g. as in Fast WaveNet.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The input data</p></li>
<li><p><strong>buffer</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Previous value of the FIFO buffer</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Specify which axis should be used for buffering</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> -- Updated value for the buffer</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.flatten">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">flatten</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.flatten" title="Permalink to this definition">¶</a></dt>
<dd><p>Flattens the input array into a 2-D array by collapsing the higher dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D array with collapsed higher dimensions.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.get_const_int">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">get_const_int</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">expr</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.get_const_int" title="Permalink to this definition">¶</a></dt>
<dd><p>Verifies expr is integer and get the constant value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>expr</strong> (<em>tvm.Expr</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- The input expression.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out_value</strong> -- The output.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.get_const_tuple">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">get_const_tuple</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">in_tuple</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.get_const_tuple" title="Permalink to this definition">¶</a></dt>
<dd><p>Verifies input tuple is IntImm or Var, returns tuple of int or Var.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>in_tuple</strong> (<em>tuple of Expr</em>) -- The input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out_tuple</strong> -- The output.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple of int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.get_pad_tuple">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">get_pad_tuple</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">kernel</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.get_pad_tuple" title="Permalink to this definition">¶</a></dt>
<dd><p>Common code to get the pad option</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>kernel</strong> (<em>tuple of int</em>) -- Conv kernel size</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pad_top</strong> (<em>int</em>) -- Padding size on top</p></li>
<li><p><strong>pad_left</strong> (<em>int</em>) -- Padding size on left</p></li>
<li><p><strong>pad_down</strong> (<em>int</em>) -- Padding size on down.</p></li>
<li><p><strong>pad_right</strong> (<em>int</em>) -- Padding size on right.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.get_pad_tuple1d">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">get_pad_tuple1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">kernel</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.get_pad_tuple1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Common code to get the pad option</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>kernel</strong> (<em>tuple of int</em>) -- Conv kernel size</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pad_left</strong> (<em>int</em>) -- Padding size on left</p></li>
<li><p><strong>pad_right</strong> (<em>int</em>) -- Padding size on right.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.get_pad_tuple3d">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">get_pad_tuple3d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">kernel</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.get_pad_tuple3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Common code to get the pad option</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>kernel</strong> (<em>tuple of int</em>) -- Conv kernel size</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pad_front</strong> (<em>int</em>) -- Padding size on front.</p></li>
<li><p><strong>pad_top</strong> (<em>int</em>) -- Padding size on top</p></li>
<li><p><strong>pad_left</strong> (<em>int</em>) -- Padding size on left</p></li>
<li><p><strong>pad_back</strong> (<em>int</em>) -- Padding size on back.</p></li>
<li><p><strong>pad_down</strong> (<em>int</em>) -- Padding size on down.</p></li>
<li><p><strong>pad_right</strong> (<em>int</em>) -- Padding size on right.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.global_pool">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">global_pool</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">pool_type</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.global_pool" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Perform global pooling on height and width dimension of data.</dt><dd><p>It decides the height and width dimension according to the layout string,
in which 'W' and 'H' means width and height respectively.
Width and height dimension cannot be split.
For example, NCHW, NCHW16c, etc. are valid for pool,
while NCHW16w, NCHW16h are not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D with shape of layout</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Pool type, 'max' or 'avg'</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCHW16c can describe a 5-D tensor of
[batch_size, channel, height, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- n-D in same layout with height and width dimension size of 1.
e.g., for NCHW, the output shape will be [batch, channel, 1, 1]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.group_conv2d_nchw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">group_conv2d_nchw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">groups</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.group_conv2d_nchw" title="Permalink to this definition">¶</a></dt>
<dd><p>Group convolution operator in NCHW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [num_filter, in_channel // groups, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of 2</em><em> or </em><em>4 ints</em>) -- padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- number of groups</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The output type. This is used for mixed precision.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, out_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.group_conv2d_nhwc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">group_conv2d_nhwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilation</span></em>, <em class="sig-param"><span class="n">groups</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.group_conv2d_nhwc" title="Permalink to this definition">¶</a></dt>
<dd><p>Group convolution operator in NHWC layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>Filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [filter_height, filter_width, in_channel // groups, num_filter]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of 2</em><em> or </em><em>4 ints</em>) -- padding size, or
[pad_height, pad_width] for 2 ints, or
[pad_top, pad_left, pad_bottom, pad_right] for 4 ints</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- number of groups</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The output type. This is used for mixed precision.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, out_height, out_width, out_channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.leaky_relu">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">leaky_relu</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">alpha</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.leaky_relu" title="Permalink to this definition">¶</a></dt>
<dd><p>Take leaky relu of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- The slope for the small gradient when x &lt; 0</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.log_softmax">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">log_softmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform log softmax activation on the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D input data</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D output with same shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.lrn">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">lrn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">size</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">beta</span><span class="o">=</span><span class="default_value">0.75</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.lrn" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform the across channels local response normalisation
on the input data.</p>
<p>sum_sqr_up^i{x, y} = (bias+((alpha/size)*                                 {sum_{j=max(0, i-size/2)}^{min(N-1,i+size/2)}                                      (data^j{x,y})^2}))^beta
output^i{x, y} = data^i{x, y}/sum_sqr_up^i{x, y}
N is the number for input channels</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, channel, height, width]</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- normalisation window size</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- input data layout channel axis
default value is 1 for NCHW format</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- offset to avoid dividing by 0</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- to be divided</p></li>
<li><p><strong>beta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- exponent</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D output with same shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.mirror_pad">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">mirror_pad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">pad_before</span></em>, <em class="sig-param"><span class="n">pad_after</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">mode</span><span class="o">=</span><span class="default_value">'SYMMETRIC'</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">'MirrorPadInput'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.mirror_pad" title="Permalink to this definition">¶</a></dt>
<dd><p>Pad Input with mirroring either symmetric or reflected.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D input, can be any layout.</p></li>
<li><p><strong>pad_before</strong> (<em>list / tuple of n ints</em>) -- Pad width on each dimension to pad the before the axis begin.</p></li>
<li><p><strong>pad_after</strong> (<em>list / tuple of n ints</em><em>, </em><em>optional</em>) -- Pad width each dimension to pad the after the axis end.</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- Type of mirror padding to apply. Must be SYMMETRIC or REFLECT</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The name prefix operators generated</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- n-D, the same layout as Input.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.namedtuple">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">namedtuple</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">typename</span></em>, <em class="sig-param"><span class="n">field_names</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rename</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">module</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.namedtuple" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new subclass of tuple with named fields.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Point</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Point&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Point</span><span class="o">.</span><span class="vm">__doc__</span>                   <span class="c1"># docstring for the new class</span>
<span class="go">&#39;Point(x, y)&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Point</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>             <span class="c1"># instantiate with positional args or keywords</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>                     <span class="c1"># indexable like a plain tuple</span>
<span class="go">33</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">p</span>                        <span class="c1"># unpack like a regular tuple</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span>
<span class="go">(11, 22)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">y</span>                       <span class="c1"># fields also accessible by name</span>
<span class="go">33</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">_asdict</span><span class="p">()</span>                 <span class="c1"># convert to a dictionary</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="go">11</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Point</span><span class="p">(</span><span class="o">**</span><span class="n">d</span><span class="p">)</span>                      <span class="c1"># convert from a dictionary</span>
<span class="go">Point(x=11, y=22)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">_replace</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>               <span class="c1"># _replace() is like str.replace() but targets named fields</span>
<span class="go">Point(x=100, y=22)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.pad">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">pad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">pad_before</span></em>, <em class="sig-param"><span class="n">pad_after</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">pad_value</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">'PadInput'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.pad" title="Permalink to this definition">¶</a></dt>
<dd><p>Pad Input with zeros.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D input, can be any layout.</p></li>
<li><p><strong>pad_before</strong> (<em>list / tuple of n ints</em>) -- Pad width on each dimension to pad the before the axis begin.</p></li>
<li><p><strong>pad_after</strong> (<em>list / tuple of n ints</em><em>, </em><em>optional</em>) -- Pad width each dimension to pad the after the axis end.</p></li>
<li><p><strong>pad_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em>) -- The value to be padded.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The name prefix operators generated</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- n-D, the same layout as Input.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.pool">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">pool</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">pool_type</span></em>, <em class="sig-param"><span class="n">ceil_mode</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em>, <em class="sig-param"><span class="n">count_include_pad</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.pool" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Perform pooling on height and width dimension of data.</dt><dd><p>It decides the height and width dimension according to the layout string,
in which 'W' and 'H' means width and height respectively.
Width and height dimension cannot be split.
For example, NCHW, NCHW16c, etc. are valid for pool,
while NCHW16w, NCHW16h are not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D with shape of layout</p></li>
<li><p><strong>kernel</strong> (<em>list/tuple of two ints</em>) -- Kernel size, [kernel_height, kernel_width]</p></li>
<li><p><strong>stride</strong> (<em>list/tuple of two ints</em>) -- Stride size, [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<em>list/tuple of four ints</em>) -- Pad size, [pad_top, pad_left, pad_bottom, pad_right]]</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Pool type, 'max' or 'avg'</p></li>
<li><p><strong>ceil_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- Whether to use ceil when calculating output size.</p></li>
<li><p><strong>layout</strong> (<em>string</em>) -- Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCHW16c can describe a 5-D tensor of
[batch_size, channel, height, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
<li><p><strong>count_include_pad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- Whether include padding in the calculation when pool_type is 'avg'</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- n-D in the same layout</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.pool1d">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">pool1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">pool_type</span></em>, <em class="sig-param"><span class="n">ceil_mode</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCW'</span></em>, <em class="sig-param"><span class="n">count_include_pad</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.pool1d" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Perform pooling on width dimension of data.</dt><dd><p>Width axis is determined according to the layout string.
in which 'w' means width.
Width dimension cannot be split.
For example, NCW, NCW16c, etc. are valid for pool,
while NCW16w is not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D with shape of layout</p></li>
<li><p><strong>kernel</strong> (<em>list/tuple of one int</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Kernel size, [kernel_width]</p></li>
<li><p><strong>stride</strong> (<em>list/tuple of one int</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Stride size, [stride_width]</p></li>
<li><p><strong>padding</strong> (<em>list/tuple of two ints</em>) -- Pad size, [pad_left, pad_right]</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Pool type, 'max' or 'avg'</p></li>
<li><p><strong>ceil_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- Whether to use ceil when calculating output size.</p></li>
<li><p><strong>layout</strong> (<em>string</em>) -- Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCW16c can describe a 4-D tensor of
[batch_size, channel, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
<li><p><strong>count_include_pad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- Whether include padding in the calculation when pool_type is 'avg'</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- n-D in the same layout</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.pool3d">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">pool3d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">pool_type</span></em>, <em class="sig-param"><span class="n">ceil_mode</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCDHW'</span></em>, <em class="sig-param"><span class="n">count_include_pad</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.pool3d" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Perform pooling on depth, height and width dimension of data.</dt><dd><p>It decides the depth, height and width dimension according to the layout string,
in which 'D', 'W' and 'H' means depth, width and height respectively.
Depth, width and height dimension cannot be split.
For example, NCDHW, NCDHW16c, etc. are valid for pool,
while NCDHW16d, NCDHW16w, NCDHW16h are not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D with shape of layout</p></li>
<li><p><strong>kernel</strong> (<em>list/tuple of three ints</em>) -- Kernel size, [kernel_depth, kernel_height, kernel_width]</p></li>
<li><p><strong>stride</strong> (<em>list/tuple of three ints</em>) -- Stride size, [stride_depth, stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<em>list/tuple of six ints</em>) -- Pad size, [pad_front, pad_top, pad_left, pad_back, pad_bottom, pad_right]</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Pool type, 'max' or 'avg'</p></li>
<li><p><strong>ceil_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- Whether to use ceil when calculating output size.</p></li>
<li><p><strong>layout</strong> (<em>string</em>) -- Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCDHW16c can describe a 6-D tensor of
[batch_size, channel, depth, height, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
<li><p><strong>count_include_pad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- Whether include padding in the calculation when pool_type is 'avg'</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- n-D in the same layout</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.pool_grad">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">pool_grad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">grads</span></em>, <em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">kernel</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">pool_type</span></em>, <em class="sig-param"><span class="n">ceil_mode</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em>, <em class="sig-param"><span class="n">count_include_pad</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.pool_grad" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Gradient of pooling on height and width dimension of data.</dt><dd><p>It decides the height and width dimension according to the layout string,
in which 'W' and 'H' means width and height respectively.
Width and height dimension cannot be split.
For example, NCHW, NCHW16c, etc. are valid for pool,
while NCHW16w, NCHW16h are not.
See parameter <cite>layout</cite> for more information of the layout string convention.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>grads</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D with shape of layout</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D with shape of layout</p></li>
<li><p><strong>kernel</strong> (<em>list/tuple of two ints</em>) -- Kernel size, [kernel_height, kernel_width]</p></li>
<li><p><strong>stride</strong> (<em>list/tuple of two ints</em>) -- Stride size, [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<em>list/tuple of four ints</em>) -- Pad size, [pad_top, pad_left, pad_bottom, pad_right]]</p></li>
<li><p><strong>pool_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Pool type, 'max' or 'avg'</p></li>
<li><p><strong>ceil_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- Whether to use ceil when calculating output size.</p></li>
<li><p><strong>layout</strong> (<em>string</em>) -- Layout of the input data.
The layout is supposed to be composed of upper cases, lower cases and numbers,
where upper case indicates a dimension and
the corresponding lower case with factor size indicates the split dimension.
For example, NCHW16c can describe a 5-D tensor of
[batch_size, channel, height, width, channel_block],
in which channel_block=16 is a split of dimension channel.</p></li>
<li><p><strong>count_include_pad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) -- Whether include padding in the calculation when pool_type is 'avg'</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- n-D in the same layout</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.prelu">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">prelu</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">slope</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.prelu" title="Permalink to this definition">¶</a></dt>
<dd><p>PReLU.
It accepts two arguments: an input <code class="docutils literal notranslate"><span class="pre">x</span></code> and a weight array <code class="docutils literal notranslate"><span class="pre">W</span></code>
and computes the output as <span class="math notranslate nohighlight">\(PReLU(x) y = x &gt; 0 ? x : W * x\)</span>,
where <span class="math notranslate nohighlight">\(*\)</span> is an elementwise multiplication for each sample in the
batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p></li>
<li><p><strong>slope</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Channelised slope tensor for prelu</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- The axis where the channel data needs to be applied</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>y</strong> (<em>tvm.te.Tensor</em>) -- The result.</p></li>
<li><p><em>Links</em></p></li>
<li><p><em>-----</em></p></li>
<li><p><strong>[http</strong> (<em>//arxiv.org/pdf/1502.01852v1.pdf]</em>)</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.relu">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">relu</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.relu" title="Permalink to this definition">¶</a></dt>
<dd><p>Take relu of input x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input argument.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> -- The result.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.scale_shift_nchw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">scale_shift_nchw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Scale</span></em>, <em class="sig-param"><span class="n">Shift</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.scale_shift_nchw" title="Permalink to this definition">¶</a></dt>
<dd><p>Batch normalization operator in inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input tensor, layout is NCHW</p></li>
<li><p><strong>Scale</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Scale tensor, 1-D of size channel number</p></li>
<li><p><strong>Shift</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Shift tensor, 1-D of size channel number</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- Output tensor, layout is NCHW</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.scale_shift_nhwc">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">scale_shift_nhwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Input</span></em>, <em class="sig-param"><span class="n">Scale</span></em>, <em class="sig-param"><span class="n">Shift</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.scale_shift_nhwc" title="Permalink to this definition">¶</a></dt>
<dd><p>Batch normalization operator in inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Input tensor, layout is NHWC</p></li>
<li><p><strong>Scale</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Scale tensor, 1-D of size channel number</p></li>
<li><p><strong>Shift</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- Shift tensor, 1-D of size channel number</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- Output tensor, layout is NHWC</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.simplify">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">simplify</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">expr</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.simplify" title="Permalink to this definition">¶</a></dt>
<dd><p>Simplify the expression if it is Expr, directly return if it is int.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>expr</strong> (<em>Expr</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- The input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> -- The simplified output</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Expr or <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.softmax">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">softmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">- 1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform softmax activation on the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- can be any dimension</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- channel axis</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- output shape is the same as input</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.softmax_common">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">softmax_common</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">axis</span></em>, <em class="sig-param"><span class="n">use_fast_exp</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.softmax_common" title="Permalink to this definition">¶</a></dt>
<dd><p>The common part of softmax and fast_softmax</p>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.space_to_batch_nd">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">space_to_batch_nd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">block_shape</span></em>, <em class="sig-param"><span class="n">pad_before</span></em>, <em class="sig-param"><span class="n">pad_after</span></em>, <em class="sig-param"><span class="n">pad_value</span><span class="o">=</span><span class="default_value">0.0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.space_to_batch_nd" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform batch to space transformation on the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- N-D Tensor with shape [batch, spatial_shape, remaining_shapes],
where spatial_shape has M dimensions.</p></li>
<li><p><strong>block_shape</strong> (<em>list of ints</em>) -- list of size [M] where M is number of spatial dims, specifies block
size for each spatial dimension.</p></li>
<li><p><strong>pad_before</strong> (<em>list of ints</em>) -- list of shape [M] where M is number of spatial dims, specifies
zero-padding size before each spatial dimension.</p></li>
<li><p><strong>pad_after</strong> (<em>list of ints</em>) -- list of shape [M] where M is number of spatial dims, specifies
zero-padding size after each spatial dimension.</p></li>
<li><p><strong>pad_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em>) -- The value used for padding.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.space_to_depth">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">space_to_depth</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">block_size</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.space_to_depth" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform space to depth transformation on the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D tensor in either NCHW or NHWC layout.</p></li>
<li><p><strong>block_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Size of blocks to decompose into channel dimension.</p></li>
<li><p><strong>layout</strong> (<em>string</em>) -- Either NCHW or NHWC, indicating data layout.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- Output of shape [N, C * block_size**2, H / block_size, W / block_size]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.sparse_dense">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">sparse_dense</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dense_data</span></em>, <em class="sig-param"><span class="n">sparse_data</span></em>, <em class="sig-param"><span class="n">sparse_indices</span></em>, <em class="sig-param"><span class="n">sparse_indptr</span></em>, <em class="sig-param"><span class="n">sparse_lhs</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.sparse_dense" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes sparse-dense matrix multiplication of <cite>data</cite> and
<cite>(weight_data, weight_indices, weight_indptr).T</cite>, if sparse_lhs=False
or
Computes sparse-dense matrix multiplication of
<cite>(data_data, data_indices, data_indptr)</cite> and <cite>weight.T</cite>, if sparse_lhs=True</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dense_data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D with shape [M, K], float32</p></li>
<li><p><strong>sparse_data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 1-D with shape [nnz] (CSR) or
3-D with shape [num_blocks, bs_r, bs_c] (BSR)</p></li>
<li><p><strong>sparse_indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 1-D with shape [nnz] (CSR) or
1-D with shape [num_blocks] (BSR)</p></li>
<li><p><strong>sparse_indptr</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 1-D with shape [N + 1] (CSR) or
1-D with shape [(N + 1) // bs_r] (BSR)</p></li>
<li><p><strong>sparse_lhs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) -- Indicates whether lhs or rhs matrix is sparse. Default value is False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D with shape [M, N]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.sparse_dense_alter_layout">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">sparse_dense_alter_layout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">_attrs</span></em>, <em class="sig-param"><span class="n">_inputs</span></em>, <em class="sig-param"><span class="n">_tinfos</span></em>, <em class="sig-param"><span class="n">_out_type</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.sparse_dense_alter_layout" title="Permalink to this definition">¶</a></dt>
<dd><p>Change Sparse Dense layout.</p>
<p>This is used for modifying the inputs weights so they are more amenable for
the target.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attrs</strong> (<a class="reference internal" href="ir.html#tvm.ir.Attrs" title="tvm.ir.Attrs"><em>tvm.ir.Attrs</em></a>) -- Attributes of current convolution</p></li>
<li><p><strong>inputs</strong> (<em>tvm.relay.Expr</em>) -- Grouped input symbols</p></li>
<li><p><strong>tinfos</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) -- Input shape and dtype</p></li>
<li><p><strong>out_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.9)"><em>type</em></a>) -- The output type</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Unlike other TOPI functions, this function operates on both graph level and operator level.</p>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.sparse_dense_v1">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">sparse_dense_v1</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data_data</span></em>, <em class="sig-param"><span class="n">data_indices</span></em>, <em class="sig-param"><span class="n">data_indptr</span></em>, <em class="sig-param"><span class="n">weight</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.sparse_dense_v1" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes sparse-dense matrix multiplication of
<cite>(data_data, data_indices, data_indptr)</cite> and <cite>weight.T</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_data</strong> -- 1-D with shape [nnz] (CSR) or
3-D with shape [num_blocks, bs_r, bs_c] (BSR)</p></li>
<li><p><strong>data_indices</strong> -- 1-D with shape [nnz] (CSR) or
1-D with shape [num_blocks] (BSR)</p></li>
<li><p><strong>data_indptr</strong> -- 1-D with shape [M + 1] (CSR) or
1-D with shape [(M + 1) // bs_r] (BSR)</p></li>
<li><p><strong>weight</strong> -- 2-D with shape [N, K], float32</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D with shape [M, N]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.sparse_dense_v2">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">sparse_dense_v2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">weight_data</span></em>, <em class="sig-param"><span class="n">weight_indices</span></em>, <em class="sig-param"><span class="n">weight_indptr</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.sparse_dense_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes sparse-dense matrix multiplication of <cite>data</cite> and
<cite>(weight_data, weight_indices, weight_indptr).T</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D with shape [M, K], float32</p></li>
<li><p><strong>weight_data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 1-D with shape [nnz] (CSR) or
3-D with shape [num_blocks, bs_r, bs_c] (BSR)</p></li>
<li><p><strong>weight_indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 1-D with shape [nnz] (CSR) or
1-D with shape [num_blocks] (BSR)</p></li>
<li><p><strong>weight_indptr</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 1-D with shape [N + 1] (CSR) or
1-D with shape [(N + 1) // bs_r] (BSR)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D with shape [M, N]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.sparse_transpose">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">sparse_transpose</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sparse_data</span></em>, <em class="sig-param"><span class="n">sparse_indices</span></em>, <em class="sig-param"><span class="n">sparse_indptr</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.sparse_transpose" title="Permalink to this definition">¶</a></dt>
<dd><p>Transpose a square sparse matrix,
<cite>A</cite> is an n-by-n sparse matrix in the CSR format.
** Currently only support Square Matrices **</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sparse_data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 1-D with shape [nonzeros], dtype of 'float32'</p></li>
<li><p><strong>sparse_indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 1-D with shape [nonzeros], dtype of 'int32'</p></li>
<li><p><strong>sparse_indptr</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 1-D with shape [n+1], dtype of 'int32'</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>out_data</strong> (<em>tvm.te.Tensor</em>) -- 1-D with shape [nonzeros], dtype of 'float32'</p></li>
<li><p><strong>out_indices</strong> (<em>tvm.te.Tensor</em>) -- 1-D with shape [nonzeros], dtype of 'int32'</p></li>
<li><p><strong>out_indptr</strong> (<em>tvm.te.Tensor</em>) -- 1-D with shape [n+1], dtype of 'int32'</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.strided_slice">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">strided_slice</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">begin</span></em>, <em class="sig-param"><span class="n">end</span></em>, <em class="sig-param"><span class="n">strides</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">slice_mode</span><span class="o">=</span><span class="default_value">'end'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.strided_slice" title="Permalink to this definition">¶</a></dt>
<dd><p>Slice of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The tensor to be sliced.</p></li>
<li><p><strong>begin</strong> (<em>list of int</em>) -- The indices to begin with in the slicing.</p></li>
<li><p><strong>end</strong> (<em>list of int</em>) -- Indicies indicating end of the slice.</p></li>
<li><p><strong>strides</strong> (<em>list of int</em><em>, </em><em>optional</em>) -- Specifies the stride values, it can be negative
in that case, the input tensor will be reversed
in that particular axis.</p></li>
<li><p><strong>slice_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The slice mode [end, size].
end - The ending indices for the slice [default].
size - The input strides will be ignored, input end in this mode indicates
the sizeof a slice starting at the location specified by begin. If end[i]
is -1, all remaining elements in that dimension are included in the slice.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.unpack_NCHWc_to_nchw">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">unpack_NCHWc_to_nchw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">packed_out</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.unpack_NCHWc_to_nchw" title="Permalink to this definition">¶</a></dt>
<dd><p>Unpack conv2d_NCHWc output from layout NCHWc to NCHW</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>packed_out</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- The output tensor of conv2d_NCHWc.</p></li>
<li><p><strong>out_dtype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The output dtype.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>unpacked_out</strong> -- The unpacked output tensor in NCHW layout.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.upsampling">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">upsampling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">scale_h</span></em>, <em class="sig-param"><span class="n">scale_w</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'nearest_neighbor'</span></em>, <em class="sig-param"><span class="n">align_corners</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">output_shape</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.upsampling" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Perform upsampling on the data.</dt><dd><p>Nearest neighbor and bilinear upsampling are supported.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- inputs is a 4-D tensor with shape
[batch, channel, in_height, in_width]
or  [batch, in_height, in_width, channel]</p></li>
<li><p><strong>scale_h</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- Scaling factor for height</p></li>
<li><p><strong>scale_w</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- Scaling factor for width</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) -- either &quot;NCHW&quot; or &quot;NHWC&quot;</p></li>
<li><p><strong>method</strong> (<em>{&quot;bilinear&quot;</em><em>, </em><em>&quot;nearest_neighbor&quot;</em><em>, </em><em>&quot;bicubic&quot;}</em>) -- Method to be used for upsampling.</p></li>
<li><p><strong>output_shape</strong> (<em>tvm.tir.container.Array</em><em>, </em><em>optional</em>) -- Shape to return. If left None will be inferred
(If shape is determined dynamically, pass out_dtype.shape as output_shape)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [batch, channel, in_height*scale_h, in_width*scale_w]
or [batch, in_height*scale, in_width*scale, channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.upsampling3d">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">upsampling3d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">scale_d</span></em>, <em class="sig-param"><span class="n">scale_h</span></em>, <em class="sig-param"><span class="n">scale_w</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCDHW'</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'nearest_neighbor'</span></em>, <em class="sig-param"><span class="n">coordinate_transformation_mode</span><span class="o">=</span><span class="default_value">'half_pixel'</span></em>, <em class="sig-param"><span class="n">output_shape</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.upsampling3d" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Perform upsampling on the data.</dt><dd><p>Nearest neighbor and bilinear upsampling are supported.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- inputs is a 5-D tensor with shape
[batch, channel, in_depth, in_height, in_width]
or  [batch, in_depth, in_height, in_width, channel]</p></li>
<li><p><strong>scale_d</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- Scaling factor for depth</p></li>
<li><p><strong>scale_h</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- Scaling factor for height</p></li>
<li><p><strong>scale_w</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) -- Scaling factor for width</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) -- either &quot;NCDHW&quot; or &quot;NDHWC&quot;</p></li>
<li><p><strong>method</strong> (<em>{&quot;trilinear&quot;</em><em>, </em><em>&quot;nearest_neighbor&quot;}</em>) -- Method to be used for upsampling.</p></li>
<li><p><strong>coordinate_transformation_mode</strong> (<em>string</em><em>, </em><em>optional</em>) -- Describes how to transform the coordinate in the resized tensor
to the coordinate in the original tensor.
Refer to the ONNX Resize operator specification for details.
Available options are &quot;half_pixel&quot;, &quot;align_corners&quot; and &quot;asymmetric&quot;.</p></li>
<li><p><strong>output_shape</strong> (<em>tvm.tir.container.Array</em><em>, </em><em>optional</em>) -- Shape to return. If left None will be inferred
(If shape is determined dynamically, pass out_dtype.shape as output_shape)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 5-D with shape [batch, channel, in_depth*scale, in_height*scale, in_width*scale]
or [batch, in_depth*scale, in_height*scale, in_width*scale, channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.nn.winograd_transform_matrices">
<code class="sig-prename descclassname">tvm.topi.nn.</code><code class="sig-name descname">winograd_transform_matrices</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tile_size</span></em>, <em class="sig-param"><span class="n">kernel_size</span></em>, <em class="sig-param"><span class="n">out_dtype</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.nn.winograd_transform_matrices" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the A, B, and G transform matrices for <cite>tile_size</cite> as a <cite>tvm.Expr</cite>.</p>
</dd></dl>

</div>
<div class="section" id="module-tvm.topi.image">
<span id="tvm-topi-image"></span><h2>tvm.topi.image<a class="headerlink" href="#module-tvm.topi.image" title="Permalink to this headline">¶</a></h2>
<p>IMAGE network operators</p>
<p><strong>Functions:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">affine_grid</span></code>(data, target_shape)</p></td>
<td><p>affine_grid operator that generates 2D sampling grid.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">crop_and_resize</span></code>(data, boxes, box_indices, ...)</p></td>
<td><p>Perform crop and resize operation on the data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dilation2d_nchw</span></code>(input, filter, stride, ...)</p></td>
<td><p>Morphological dilation operator in NCHW layout.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dilation2d_nhwc</span></code>(input, filter, stride, ...)</p></td>
<td><p>Morphological 2d dilation NHWC layout.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_2d_indices</span></code>(indices[, layout])</p></td>
<td><p>Get 2d indices</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_2d_pixel</span></code>(data, layout, boxes, ...)</p></td>
<td><p>Get 2d pixel</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_pad_tuple</span></code>(padding, kernel)</p></td>
<td><p>Common code to get the pad option</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">grid_sample</span></code>(data, grid[, method, layout])</p></td>
<td><p>Applies bilinear sampling to input feature map.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">nchw_pack_layout</span></code>(layout_info)</p></td>
<td><p>Check whether the layout type is NCHWinic</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">nchw_xc_layout</span></code>(layout_info)</p></td>
<td><p>Check whether the layout type is NCHWxc</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pad</span></code>(data, pad_before[, pad_after, ...])</p></td>
<td><p>Pad Input with zeros.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resize</span></code>(data, size[, layout, method, ...])</p></td>
<td><p>Perform resize operation on the data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resize3d</span></code>(data, size[, layout, method, ...])</p></td>
<td><p>Perform resize operation on the data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resize_bicubic</span></code>(indices, data, image_height, ...)</p></td>
<td><p>Perform resize operation with bicubic method on the data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resize_bilinear</span></code>(indices, data, image_height, ...)</p></td>
<td><p>Perform resize operation with bilinear method on the data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resize_nearest_neighbor</span></code>(indices, data, ...)</p></td>
<td><p>Perform resize operation with nearest neighbor method on the data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">simplify</span></code>(expr)</p></td>
<td><p>Simplify the expression if it is Expr, directly return if it is int.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt id="tvm.topi.image.affine_grid">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">affine_grid</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">target_shape</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.affine_grid" title="Permalink to this definition">¶</a></dt>
<dd><p>affine_grid operator that generates 2D sampling grid.</p>
<p>This operation is described in <a class="reference external" href="https://arxiv.org/pdf/1506.02025.pdf">https://arxiv.org/pdf/1506.02025.pdf</a>. It generates a uniform
sampling grid within the target shape and normalizes it to [-1, 1]. The provided affine
transformation is then applied on the sampling grid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>tvm.Tensor</em>) -- 3-D with shape [batch, 2, 3]. The affine matrix.</p></li>
<li><p><strong>target_shape</strong> (<em>list/tuple of two int</em>) -- Specifies the output shape (H, W).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, 2, target_height, target_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tvm.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.crop_and_resize">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">crop_and_resize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">boxes</span></em>, <em class="sig-param"><span class="n">box_indices</span></em>, <em class="sig-param"><span class="n">crop_size</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'bilinear'</span></em>, <em class="sig-param"><span class="n">extrapolation_value</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.crop_and_resize" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform crop and resize operation on the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- inputs is a 4-D tensor with shape
[batch, channel, in_height, in_width]
or  [batch, in_height, in_width, channel]</p></li>
<li><p><strong>boxes</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- A 2-D tensor of shape [num_boxes, 4]. Each row of the tensor specifies
the coordinates of a box.</p></li>
<li><p><strong>box_indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- A 1-D tensor of shape [num_boxes], box_indices[i] specifies the data that
the i-th box refers to.</p></li>
<li><p><strong>crop_size</strong> (<a class="reference internal" href="relay/index.html#tvm.relay.Tuple" title="tvm.relay.Tuple"><em>Tuple</em></a>) -- The target size of each box.</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) -- &quot;NCHW&quot;, &quot;NHWC&quot;</p></li>
<li><p><strong>method</strong> (<em>{&quot;bilinear&quot;</em><em>, </em><em>&quot;nearest_neighbor&quot;}</em>) -- Method to be used for resizing.</p></li>
<li><p><strong>extrapolation_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em>) -- Value used for extrapolation, when applicable.</p></li>
<li><p><strong>out_dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to return. If left None will be same as input type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [num_boxes, channel, crop_height, crop_width]
or [num_boxes, crop_height, crop_width, channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.dilation2d_nchw">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">dilation2d_nchw</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilations</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.dilation2d_nchw" title="Permalink to this definition">¶</a></dt>
<dd><p>Morphological dilation operator in NCHW layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D with shape [ in_channel, filter_height, filter_width]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size</p></li>
<li><p><strong>dilations</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>]</em>) -- Specifies the output data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, in_channel, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.dilation2d_nhwc">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">dilation2d_nhwc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">filter</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">dilations</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.dilation2d_nhwc" title="Permalink to this definition">¶</a></dt>
<dd><p>Morphological 2d dilation NHWC layout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 4-D with shape [batch, in_height, in_width, in_channel]</p></li>
<li><p><strong>filter</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 3-D with shape [filter_height, filter_width, in_channel]</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- Stride size, or [stride_height, stride_width]</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- Padding size</p></li>
<li><p><strong>dilations</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><em>a list/tuple of two ints</em>) -- dilation size, or [dilation_height, dilation_width]</p></li>
<li><p><strong>out_dtype</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>]</em>) -- Specifies the output data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, out_height, out_width, in_channel]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.get_2d_indices">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">get_2d_indices</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">indices</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_2d_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Get 2d indices</p>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.get_2d_pixel">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">get_2d_pixel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">layout</span></em>, <em class="sig-param"><span class="n">boxes</span></em>, <em class="sig-param"><span class="n">image_height</span></em>, <em class="sig-param"><span class="n">image_width</span></em>, <em class="sig-param"><span class="n">n</span></em>, <em class="sig-param"><span class="n">c</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">cc</span></em>, <em class="sig-param"><span class="n">ib</span></em>, <em class="sig-param"><span class="n">ic</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_2d_pixel" title="Permalink to this definition">¶</a></dt>
<dd><p>Get 2d pixel</p>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.get_pad_tuple">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">get_pad_tuple</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">kernel</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.get_pad_tuple" title="Permalink to this definition">¶</a></dt>
<dd><p>Common code to get the pad option</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- Padding size, or ['VALID', 'SAME']</p></li>
<li><p><strong>kernel</strong> (<em>tuple of int</em>) -- Conv kernel size</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pad_top</strong> (<em>int</em>) -- Padding size on top</p></li>
<li><p><strong>pad_left</strong> (<em>int</em>) -- Padding size on left</p></li>
<li><p><strong>pad_down</strong> (<em>int</em>) -- Padding size on down.</p></li>
<li><p><strong>pad_right</strong> (<em>int</em>) -- Padding size on right.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.grid_sample">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">grid_sample</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">grid</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'bilinear'</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.grid_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies bilinear sampling to input feature map.</p>
<p>Given <span class="math notranslate nohighlight">\(data\)</span> and <span class="math notranslate nohighlight">\(grid\)</span>, assuming NCHW layout, then the output is computed by</p>
<div class="math notranslate nohighlight">
\[x_{src} = grid[batch, 0, y_{dst}, x_{dst}] \
y_{src} = grid[batch, 1, y_{dst}, x_{dst}] \
output[batch, channel, y_{dst}, x_{dst}] = G(data[batch, channel, y_{src}, x_{src})\]</div>
<p><span class="math notranslate nohighlight">\(x_{dst}\)</span>, <span class="math notranslate nohighlight">\(y_{dst}\)</span> enumerate all spatial locations in <span class="math notranslate nohighlight">\(output\)</span>, and
<span class="math notranslate nohighlight">\(G()\)</span> denotes the interpolation method.
The out-boundary points will be padded with zeros. The shape of the output will be
(data.shape[0], data.shape[1], grid.shape[2], grid.shape[3]).</p>
<p>The operator assumes that <span class="math notranslate nohighlight">\(grid\)</span> has been normalized to [-1, 1].</p>
<p>grid_sample often cooperates with affine_grid which generates sampling grids for grid_sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>tvm.Tensor</em>) -- 4-D with shape [batch, in_channel, in_height, in_width]</p></li>
<li><p><strong>grid</strong> (<em>tvm.Tensor</em>) -- 4-D with shape [batch, 2, out_height, out_width]</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The interpolation method. Only 'bilinear' is supported.</p></li>
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) -- The layout of input data and the output.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- 4-D with shape [batch, 2, out_height, out_width]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tvm.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.nchw_pack_layout">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">nchw_pack_layout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">layout_info</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.nchw_pack_layout" title="Permalink to this definition">¶</a></dt>
<dd><p>Check whether the layout type is NCHWinic</p>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.nchw_xc_layout">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">nchw_xc_layout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">layout_info</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.nchw_xc_layout" title="Permalink to this definition">¶</a></dt>
<dd><p>Check whether the layout type is NCHWxc</p>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.pad">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">pad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">pad_before</span></em>, <em class="sig-param"><span class="n">pad_after</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">pad_value</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">'PadInput'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.pad" title="Permalink to this definition">¶</a></dt>
<dd><p>Pad Input with zeros.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- n-D input, can be any layout.</p></li>
<li><p><strong>pad_before</strong> (<em>list / tuple of n ints</em>) -- Pad width on each dimension to pad the before the axis begin.</p></li>
<li><p><strong>pad_after</strong> (<em>list / tuple of n ints</em><em>, </em><em>optional</em>) -- Pad width each dimension to pad the after the axis end.</p></li>
<li><p><strong>pad_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em>) -- The value to be padded.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) -- The name prefix operators generated</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Output</strong> -- n-D, the same layout as Input.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.resize">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">resize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">size</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'bilinear'</span></em>, <em class="sig-param"><span class="n">coordinate_transformation_mode</span><span class="o">=</span><span class="default_value">'half_pixel'</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_shape</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.resize" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform resize operation on the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- inputs is a 4-D tensor with shape
[batch, channel, in_height, in_width]
or  [batch, in_height, in_width, channel]</p></li>
<li><p><strong>size</strong> (<a class="reference internal" href="relay/index.html#tvm.relay.Tuple" title="tvm.relay.Tuple"><em>Tuple</em></a>) -- Output resolution scale to</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) -- &quot;NCHW&quot;, &quot;NHWC&quot;, or &quot;NCHWc&quot;.</p></li>
<li><p><strong>coordinate_transformation_mode</strong> (<em>string</em><em>, </em><em>optional</em>) -- Describes how to transform the coordinate in the resized tensor
to the coordinate in the original tensor.
Refer to the ONNX Resize operator specification for details.
Available options are &quot;half_pixel&quot;, &quot;align_corners&quot; and &quot;asymmetric&quot;.</p></li>
<li><p><strong>method</strong> (<em>{&quot;bilinear&quot;</em><em>, </em><em>&quot;nearest_neighbor&quot;</em><em>, </em><em>&quot;bicubic&quot;}</em>) -- Method to be used for resizing.</p></li>
<li><p><strong>out_dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to return. If left None will be same as input type.</p></li>
<li><p><strong>output_shape</strong> (<em>tvm.tir.container.Array</em><em>, </em><em>optional</em>) -- Shape to return. If left None will be inferred
(If shape is determined dynamically, pass out_dtype.shape as output_shape)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 4-D with shape [batch, channel, in_height*scale, in_width*scale]
or [batch, in_height*scale, in_width*scale, channel]
or 5-D with shape [batch, channel-major, in_height*scale, in_width*scale, channel-minor]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.resize3d">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">resize3d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">size</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCDHW'</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'nearest_neighbor'</span></em>, <em class="sig-param"><span class="n">coordinate_transformation_mode</span><span class="o">=</span><span class="default_value">'align_corners'</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.resize3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform resize operation on the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- inputs is a 5-D tensor with shape
[batch, channel, in_depth, in_height, in_width]
or  [batch, in_depth, in_height, in_width, channel]</p></li>
<li><p><strong>size</strong> (<a class="reference internal" href="relay/index.html#tvm.relay.Tuple" title="tvm.relay.Tuple"><em>Tuple</em></a>) -- Output resolution scale to</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) -- &quot;NCDHW&quot;, &quot;NDHWC&quot;, or &quot;NCDHWc&quot;.</p></li>
<li><p><strong>coordinate_transformation_mode</strong> (<em>string</em><em>, </em><em>optional</em>) -- <p>Describes how to transform the coordinate in the resized tensor
to the coordinate in the original tensor.
Refer to the ONNX Resize operator specification for details.</p>
<p>Available options are &quot;half_pixel&quot;, &quot;align_corners&quot; and &quot;asymmetric&quot;.</p>
</p></li>
<li><p><strong>method</strong> (<em>{&quot;trilinear&quot;</em><em>, </em><em>&quot;nearest_neighbor&quot;}</em>) -- Method to be used for resizing.</p></li>
<li><p><strong>out_dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to return. If left None will be same as input type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 5-D with shape [batch, channel, in_depth*scale, in_height*scale, in_width*scale]
or [batch, in_depth*scale, in_height*scale, in_width*scale, channel]
or 5-D with shape [batch, channel-major, in_depth*scale, in_height*scale, in_width*scale,
channel-minor]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.resize_bicubic">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">resize_bicubic</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">indices</span></em>, <em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">image_height</span></em>, <em class="sig-param"><span class="n">image_width</span></em>, <em class="sig-param"><span class="n">target_height</span></em>, <em class="sig-param"><span class="n">target_width</span></em>, <em class="sig-param"><span class="n">boxes</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">box_indices</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">extrapolation_value</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em>, <em class="sig-param"><span class="n">coordinate_transformation_mode</span><span class="o">=</span><span class="default_value">'align_corners'</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.resize_bicubic" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform resize operation with bicubic method on the data.
More details about Bicubic interpolation please refer to
<a class="reference external" href="https://en.wikipedia.org/wiki/Bicubic_interpolation">https://en.wikipedia.org/wiki/Bicubic_interpolation</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- The indices of input data</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- inputs is a 4-D tensor with shape
[batch, channel, in_height, in_width]
or  [batch, in_height, in_width, channel]</p></li>
<li><p><strong>image_height</strong> (<em>integer</em>) -- Input image height</p></li>
<li><p><strong>image_width</strong> (<em>integer</em>) -- Input image width</p></li>
<li><p><strong>target_height</strong> (<em>integer</em>) -- The target resized image height</p></li>
<li><p><strong>target_width</strong> (<em>integer</em>) -- The target resized image width</p></li>
<li><p><strong>boxes</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) -- A 2-D tensor of shape [num_boxes, 4]. Each row of the tensor specifies
the coordinates of a box.</p></li>
<li><p><strong>box_indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) -- A 1-D tensor of shape [num_boxes], box_indices[i] specifies the data that
the i-th box refers to.</p></li>
<li><p><strong>extrapolation_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em>) -- Value used for extrapolation, when applicable.</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) -- &quot;NCHW&quot;, &quot;NHWC&quot;, or &quot;NCHWc&quot;.</p></li>
<li><p><strong>coordinate_transformation_mode</strong> (<em>string</em><em>, </em><em>optional</em>) -- Describes how to transform the coordinate in the resized tensor
to the coordinate in the original tensor.
Refer to the ONNX Resize operator specification for details.
Available options are &quot;half_pixel&quot;, &quot;align_corners&quot; and &quot;asymmetric&quot;.</p></li>
<li><p><strong>out_dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to return. If left None will be same as input type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- The computed result with type out_dtype</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_dtype</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.resize_bilinear">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">resize_bilinear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">indices</span></em>, <em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">image_height</span></em>, <em class="sig-param"><span class="n">image_width</span></em>, <em class="sig-param"><span class="n">target_height</span></em>, <em class="sig-param"><span class="n">target_width</span></em>, <em class="sig-param"><span class="n">boxes</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">box_indices</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">extrapolation_value</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em>, <em class="sig-param"><span class="n">coordinate_transformation_mode</span><span class="o">=</span><span class="default_value">'align_corners'</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.resize_bilinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform resize operation with bilinear method on the data.
For details about Bilinear interpolation please refer to
<a class="reference external" href="https://en.wikipedia.org/wiki/Bilinear_interpolation">https://en.wikipedia.org/wiki/Bilinear_interpolation</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- The indices of input data</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- inputs is a 4-D tensor with shape
[batch, channel, in_height, in_width]
or  [batch, in_height, in_width, channel]</p></li>
<li><p><strong>image_height</strong> (<em>integer</em>) -- Input image height</p></li>
<li><p><strong>image_width</strong> (<em>integer</em>) -- Input image width</p></li>
<li><p><strong>target_height</strong> (<em>integer</em>) -- The target resized image height</p></li>
<li><p><strong>target_width</strong> (<em>integer</em>) -- The target resized image width</p></li>
<li><p><strong>boxes</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) -- A 2-D tensor of shape [num_boxes, 4]. Each row of the tensor specifies
the coordinates of a box.</p></li>
<li><p><strong>box_indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) -- A 1-D tensor of shape [num_boxes], box_indices[i] specifies the data that
the i-th box refers to.</p></li>
<li><p><strong>extrapolation_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em>) -- Value used for extrapolation, when applicable.</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) -- &quot;NCHW&quot;, &quot;NHWC&quot;, or &quot;NCHWc&quot;.</p></li>
<li><p><strong>coordinate_transformation_mode</strong> (<em>string</em><em>, </em><em>optional</em>) -- Describes how to transform the coordinate in the resized tensor
to the coordinate in the original tensor.
Refer to the ONNX Resize operator specification for details.
Available options are &quot;half_pixel&quot;, &quot;align_corners&quot; and &quot;asymmetric&quot;.</p></li>
<li><p><strong>out_dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to return. If left None will be same as input type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- The computed result with type out_dtype</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_dtype</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.resize_nearest_neighbor">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">resize_nearest_neighbor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">indices</span></em>, <em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">image_height</span></em>, <em class="sig-param"><span class="n">image_width</span></em>, <em class="sig-param"><span class="n">target_height</span></em>, <em class="sig-param"><span class="n">target_width</span></em>, <em class="sig-param"><span class="n">boxes</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">box_indices</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">extrapolation_value</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">layout</span><span class="o">=</span><span class="default_value">'NCHW'</span></em>, <em class="sig-param"><span class="n">coordinate_transformation_mode</span><span class="o">=</span><span class="default_value">'align_corners'</span></em>, <em class="sig-param"><span class="n">out_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.resize_nearest_neighbor" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform resize operation with nearest neighbor method on the data.
For details about Nearest-neighbor interpolation please refer to
<a class="reference external" href="https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation">https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) -- The indices of input data</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- inputs is a 4-D tensor with shape
[batch, channel, in_height, in_width]
or  [batch, in_height, in_width, channel]</p></li>
<li><p><strong>image_height</strong> (<em>integer</em>) -- Input image height</p></li>
<li><p><strong>image_width</strong> (<em>integer</em>) -- Input image width</p></li>
<li><p><strong>target_height</strong> (<em>integer</em>) -- The target resized image height</p></li>
<li><p><strong>target_width</strong> (<em>integer</em>) -- The target resized image width</p></li>
<li><p><strong>boxes</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) -- A 2-D tensor of shape [num_boxes, 4]. Each row of the tensor specifies
the coordinates of a box.</p></li>
<li><p><strong>box_indices</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) -- A 1-D tensor of shape [num_boxes], box_indices[i] specifies the data that
the i-th box refers to.</p></li>
<li><p><strong>extrapolation_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em>) -- Value used for extrapolation, when applicable.</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em>) -- &quot;NCHW&quot;, &quot;NHWC&quot;, or &quot;NCHWc&quot;.</p></li>
<li><p><strong>coordinate_transformation_mode</strong> (<em>string</em><em>, </em><em>optional</em>) -- Describes how to transform the coordinate in the resized tensor
to the coordinate in the original tensor.
Refer to the ONNX Resize operator specification for details.
Available options are &quot;half_pixel&quot;, &quot;align_corners&quot; and &quot;asymmetric&quot;.</p></li>
<li><p><strong>out_dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to return. If left None will be same as input type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- The computed result with type out_dtype</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>out_dtype</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.image.simplify">
<code class="sig-prename descclassname">tvm.topi.image.</code><code class="sig-name descname">simplify</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">expr</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.image.simplify" title="Permalink to this definition">¶</a></dt>
<dd><p>Simplify the expression if it is Expr, directly return if it is int.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>expr</strong> (<em>Expr</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- The input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> -- The simplified output</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Expr or <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-tvm.topi.sparse">
<span id="tvm-topi-sparse"></span><h2>tvm.topi.sparse<a class="headerlink" href="#module-tvm.topi.sparse" title="Permalink to this headline">¶</a></h2>
<p>Sparse operators</p>
<p><strong>Functions:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.sparse.csrmv" title="tvm.topi.sparse.csrmv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">csrmv</span></code></a>(a, x[, y])</p></td>
<td><p>The <cite>csrmv</cite> routine performs a matrix-vector operation defined as <span class="math notranslate nohighlight">\(y := A*x + y\)</span>, where <cite>x</cite> and <cite>y</cite> are vectors, <cite>A</cite> is an m-by-k sparse matrix in the CSR format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tvm.topi.sparse.csrmm" title="tvm.topi.sparse.csrmm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">csrmm</span></code></a>(a, b[, c])</p></td>
<td><p>The <cite>csrmm</cite> routine performs a matrix-matrix operation defined as <span class="math notranslate nohighlight">\(C := A*B + C\)</span>, where <cite>B</cite> and <cite>C</cite> are dense matrices, <cite>A</cite> is an m-by-k sparse matrix in the CSR format.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tvm.topi.sparse.dense" title="tvm.topi.sparse.dense"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dense</span></code></a>(data, weight[, bias])</p></td>
<td><p>Applies a linear transformation: <span class="math notranslate nohighlight">\(Y = XW^T + b\)</span>.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt id="tvm.topi.sparse.csrmv">
<code class="sig-prename descclassname">tvm.topi.sparse.</code><code class="sig-name descname">csrmv</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sparse.csrmv" title="Permalink to this definition">¶</a></dt>
<dd><p>The <cite>csrmv</cite> routine performs a matrix-vector operation defined as <span class="math notranslate nohighlight">\(y := A*x + y\)</span>,
where <cite>x</cite> and <cite>y</cite> are vectors, <cite>A</cite> is an m-by-k sparse matrix in the CSR format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="contrib.html#tvm.contrib.sparse.CSRNDArray" title="tvm.contrib.sparse.CSRNDArray"><em>tvm.contrib.sparse.CSRNDArray</em></a>) -- 2-D sparse matrix with shape [m, k]</p></li>
<li><p><strong>x</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D dense matrix with shape [k, 1]</p></li>
<li><p><strong>y</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) -- 1-D dense vector with shape [1]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D dense matrix with shape [m, 1]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.sparse.csrmm">
<code class="sig-prename descclassname">tvm.topi.sparse.</code><code class="sig-name descname">csrmm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">c</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sparse.csrmm" title="Permalink to this definition">¶</a></dt>
<dd><p>The <cite>csrmm</cite> routine performs a matrix-matrix operation defined as <span class="math notranslate nohighlight">\(C := A*B + C\)</span>,
where <cite>B</cite> and <cite>C</cite> are dense matrices, <cite>A</cite> is an m-by-k sparse matrix in the CSR format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference internal" href="contrib.html#tvm.contrib.sparse.CSRNDArray" title="tvm.contrib.sparse.CSRNDArray"><em>tvm.contrib.sparse.CSRNDArray</em></a>) -- 2-D sparse matrix with shape [m, k]</p></li>
<li><p><strong>b</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a>) -- 2-D dense matrix with shape [k, n]</p></li>
<li><p><strong>c</strong> (<a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor"><em>tvm.te.Tensor</em></a><em>, </em><em>optional</em>) -- 1-D dense vector with shape [n]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D with shape [m, n]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvm.topi.sparse.dense">
<code class="sig-prename descclassname">tvm.topi.sparse.</code><code class="sig-name descname">dense</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">weight</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvm.topi.sparse.dense" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a linear transformation: <span class="math notranslate nohighlight">\(Y = XW^T + b\)</span>.
Either data or weight should be tvm.contrib.sparse.CSRNDArray.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="contrib.html#tvm.contrib.sparse.CSRNDArray" title="tvm.contrib.sparse.CSRNDArray"><em>tvm.contrib.sparse.CSRNDArray</em></a><em> or </em><em>te.tensor.Tensor</em>) -- 2-D with shape [batch, in_dim]</p></li>
<li><p><strong>weight</strong> (<em>te.tensor.Tensor</em><em> or </em><a class="reference internal" href="contrib.html#tvm.contrib.sparse.CSRNDArray" title="tvm.contrib.sparse.CSRNDArray"><em>tvm.contrib.sparse.CSRNDArray</em></a>) -- 2-D with shape [out_dim, in_dim]</p></li>
<li><p><strong>bias</strong> (<em>te.tensor.Tensor</em><em>, </em><em>optional</em>) -- 1-D with shape [out_dim]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output</strong> -- 2-D with shape [batch, out_dim]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="te.html#tvm.te.Tensor" title="tvm.te.Tensor">tvm.te.Tensor</a></p>
</dd>
</dl>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="vta/index.html" class="btn btn-neutral float-right" title="vta" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="graph_runtime.html" class="btn btn-neutral float-left" title="tvm.contrib.graph_runtime" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static//img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <ul class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <li class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2020 Apache Software Foundation | All right reserved</h5>
        </li>
      </ul>

    </div>

    <ul>
      <li class="footernote">Copyright © 2020 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</li>
    </ul>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>