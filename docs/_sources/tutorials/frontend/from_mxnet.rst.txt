
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorials/frontend/from_mxnet.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_tutorials_frontend_from_mxnet.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorials_frontend_from_mxnet.py:


.. _tutorial-from-mxnet:

Compile MXNet Models
====================
**Author**: `Joshua Z. Zhang <https://zhreshold.github.io/>`_,             `Kazutaka Morita <https://github.com/kazum>`_

This article is an introductory tutorial to deploy mxnet models with Relay.

For us to begin with, mxnet module is required to be installed.

A quick solution is

.. code-block:: bash

    pip install mxnet --user

or please refer to offical installation guide.
https://mxnet.apache.org/versions/master/install/index.html

.. GENERATED FROM PYTHON SOURCE LINES 38-44

.. code-block:: default

    # some standard imports
    import mxnet as mx
    import tvm
    import tvm.relay as relay
    import numpy as np








.. GENERATED FROM PYTHON SOURCE LINES 45-48

Download Resnet18 model from Gluon Model Zoo
---------------------------------------------
In this section, we download a pretrained imagenet model and classify an image.

.. GENERATED FROM PYTHON SOURCE LINES 48-85

.. code-block:: default

    from tvm.contrib.download import download_testdata
    from mxnet.gluon.model_zoo.vision import get_model
    from PIL import Image
    from matplotlib import pyplot as plt

    block = get_model("resnet18_v1", pretrained=True)
    img_url = "https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true"
    img_name = "cat.png"
    synset_url = "".join(
        [
            "https://gist.githubusercontent.com/zhreshold/",
            "4d0b62f3d01426887599d4f7ede23ee5/raw/",
            "596b27d23537e5a1b5751d2b0481ef172f58b539/",
            "imagenet1000_clsid_to_human.txt",
        ]
    )
    synset_name = "imagenet1000_clsid_to_human.txt"
    img_path = download_testdata(img_url, "cat.png", module="data")
    synset_path = download_testdata(synset_url, synset_name, module="data")
    with open(synset_path) as f:
        synset = eval(f.read())
    image = Image.open(img_path).resize((224, 224))
    plt.imshow(image)
    plt.show()


    def transform_image(image):
        image = np.array(image) - np.array([123.0, 117.0, 104.0])
        image /= np.array([58.395, 57.12, 57.375])
        image = image.transpose((2, 0, 1))
        image = image[np.newaxis, :]
        return image


    x = transform_image(image)
    print("x", x.shape)




.. image:: /tutorials/frontend/images/sphx_glr_from_mxnet_001.png
    :alt: from mxnet
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    File /home/sunchul/.tvm_test_data/data/cat.png exists, skip.
    File /home/sunchul/.tvm_test_data/data/imagenet1000_clsid_to_human.txt exists, skip.
    x (1, 3, 224, 224)




.. GENERATED FROM PYTHON SOURCE LINES 86-91

Compile the Graph
-----------------
Now we would like to port the Gluon model to a portable computational graph.
It's as easy as several lines.
We support MXNet static graph(symbol) and HybridBlock in mxnet.gluon

.. GENERATED FROM PYTHON SOURCE LINES 91-97

.. code-block:: default

    shape_dict = {"data": x.shape}
    mod, params = relay.frontend.from_mxnet(block, shape_dict)
    ## we want a probability so add a softmax operator
    func = mod["main"]
    func = relay.Function(func.params, relay.nn.softmax(func.body), None, func.type_params, func.attrs)








.. GENERATED FROM PYTHON SOURCE LINES 98-99

now compile the graph

.. GENERATED FROM PYTHON SOURCE LINES 99-103

.. code-block:: default

    target = "cuda"
    with tvm.transform.PassContext(opt_level=3):
        lib = relay.build(func, target, params=params)



.. rst-class:: sphx-glr-script-out

.. code-block:: pytb

    Traceback (most recent call last):
      File "/home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/tutorials/frontend/from_mxnet.py", line 101, in <module>
        lib = relay.build(func, target, params=params)
      File "/home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/docs/../python/tvm/relay/build_module.py", line 275, in build
        graph_json, mod, params = bld_mod.build(mod, target, target_host, params)
      File "/home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/docs/../python/tvm/relay/build_module.py", line 138, in build
        self._build(mod, target, target_host)
      File "/home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/docs/../python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
        raise get_last_ffi_error()
    tvm._ffi.base.TVMError: Traceback (most recent call last):
      [bt] (6) /home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/build/libtvm.so(TVMFuncCall+0x65) [0x7f14f98ff845]
      [bt] (5) /home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/build/libtvm.so(std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::relay::backend::RelayBuildModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)+0x3a0) [0x7f14f9750130]
      [bt] (4) /home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/build/libtvm.so(tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::NDArray, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tvm::runtime::NDArray> > > const&)+0x1d0e) [0x7f14f974f02e]
      [bt] (3) /home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/build/libtvm.so(tvm::build(tvm::Map<tvm::runtime::String, tvm::IRModule, void, void> const&, tvm::Target const&)+0xdf) [0x7f14f91f708f]
      [bt] (2) /home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/build/libtvm.so(tvm::build(tvm::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)+0x584) [0x7f14f91f6764]
      [bt] (1) /home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/build/libtvm.so(tvm::codegen::Build(tvm::IRModule, tvm::Target)+0xe62) [0x7f14f9292f92]
      [bt] (0) /home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/build/libtvm.so(+0xba1e42) [0x7f14f9291e42]
      File "/home/sunchul/workspace/gitproj/tvmdoc.multilingual.io/desk/src/target/codegen.cc", line 58
    TVMError: 
    ---------------------------------------------------------------
    An internal invariant was violated during the execution of TVM.
    Please read TVM's error reporting guidelines.
    More details can be found here: https://discuss.tvm.ai/t/error-reporting/7793.
    ---------------------------------------------------------------
      Check failed: bf != nullptr == false: target.build.cuda is not enabled




.. GENERATED FROM PYTHON SOURCE LINES 104-107

Execute the portable graph on TVM
---------------------------------
Now, we would like to reproduce the same forward computation using TVM.

.. GENERATED FROM PYTHON SOURCE LINES 107-121

.. code-block:: default

    from tvm.contrib import graph_runtime

    ctx = tvm.gpu(0)
    dtype = "float32"
    m = graph_runtime.GraphModule(lib["default"](ctx))
    # set inputs
    m.set_input("data", tvm.nd.array(x.astype(dtype)))
    # execute
    m.run()
    # get outputs
    tvm_output = m.get_output(0)
    top1 = np.argmax(tvm_output.asnumpy()[0])
    print("TVM prediction top-1:", top1, synset[top1])


.. GENERATED FROM PYTHON SOURCE LINES 122-126

Use MXNet symbol with pretrained weights
----------------------------------------
MXNet often use `arg_params` and `aux_params` to store network parameters
separately, here we show how to use these weights with existing API

.. GENERATED FROM PYTHON SOURCE LINES 126-141

.. code-block:: default

    def block2symbol(block):
        data = mx.sym.Variable("data")
        sym = block(data)
        args = {}
        auxs = {}
        for k, v in block.collect_params().items():
            args[k] = mx.nd.array(v.data().asnumpy())
        return sym, args, auxs


    mx_sym, args, auxs = block2symbol(block)
    # usually we would save/load it as checkpoint
    mx.model.save_checkpoint("resnet18_v1", 0, mx_sym, args, auxs)
    # there are 'resnet18_v1-0000.params' and 'resnet18_v1-symbol.json' on disk


.. GENERATED FROM PYTHON SOURCE LINES 142-143

for a normal mxnet model, we start from here

.. GENERATED FROM PYTHON SOURCE LINES 143-147

.. code-block:: default

    mx_sym, args, auxs = mx.model.load_checkpoint("resnet18_v1", 0)
    # now we use the same API to get Relay computation graph
    mod, relay_params = relay.frontend.from_mxnet(mx_sym, shape_dict, arg_params=args, aux_params=auxs)
    # repeat the same steps to run this model using TVM


.. _sphx_glr_download_tutorials_frontend_from_mxnet.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: from_mxnet.py <from_mxnet.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: from_mxnet.ipynb <from_mxnet.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
